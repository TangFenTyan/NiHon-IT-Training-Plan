# 软件工程基础

## 软件工程和计算机科学的区别
前者关注点在通过设计软件以解决实际问题，后者则是偏向理论研究；前者的工作内容通常需要团队协作，也因此会涉及到科学的管理方法等，而后者则能够独立进行研究

## 敏捷开发
建立能解决不可预测性的过程

## 敏捷开发代表工具
Jira, OnTime, UML, Together Tool Set

## Sprint
* Sprint Planning: 安排工作以启动
* Daily Scrum: 检视进展，调整适应Sprint Backlog及计划
* Sprint Review: 检视成果，确定未来适应性，展示工作结果，讨论Product Goal进展情况
* Retrospective: 规划提高质量和效能的方法

## Scrum工件
* Product Backlog: 涌现的和有序的清单，列出改进产品所需的内容，为承担工作的唯一来源
  * Product Goal: 描述产品未来状态，可作为制定计划的目标
* Sprint Backlog: 
  * Sprint Goal: 目标
* Increment:
  * Definition of Done

## 计算机网络
* OSI 7层划分：物理层，数据链路层，网络层(ip协议，icmp协议)，传输层(TCP，UDP)，会话层，表示层，应用层(http，ftp，smtp)
* TCP/IP 4层划分：网络接口层，网络层，传输层，应用层

# Linux

## Linux ls
	  > bin: 二进制可执行文件 \
	  > dev: 设备文件 \
	  > home: 用户文件 \
	  > root: 超级用户目录 \
	  > usr: 共享系统资源 \
	  > boot: 系统引导时所使用的文件 \
	  > etc: 系统配置 \
	  > mnt: 系统管理员安装临时文件 \
	  > tmp: 临时文件 \
	  > var: 运行时需要改变数据的文件

## Linux drw
	  > d: 目录 \
	  > r: 读权限 \
	  > w: 写权限 \
	  > x: 可执行 \
	  > r-x: 可读可执行不可写 \
	  (文件所有者权限，文件所属组权限，其他用户权限)

# Git

## Git
* HEAD: 指向当前分支当前版本的游标
* Index: 暂存区，当修改了git仓库里的一个文件时，这些变化一开始是unstaged状态，为了提交这些修改，需要使用git add把它加入到index，使它成为staged状态。当提交一个commit时，index里面的修改被提交。
* Working tree: 当前的工作目录。

# Web

## JavaWeb架构
* C/S: Client/Server
* B/S: Browser/Server

## B/S架构资源分类
* 动态资源：使用动态网页及时发布的资源
* 静态资源：
  * HTML: 用于搭建基础网页，展示页面的内容
  * CSS: 用于美化页面，布局页面
  * JavaScript: 控制页面的元素，有动态的效果

## Web资源分类
* 静态web技术：HTML+CSS+JavaScript
* 动态web技术：servlet, jsp, php, .net, ruby, python等

# HTML

## HTML(Hyper Text Markup Language 超文本标记语言)文件标签
	> html: html文档的根标签 \
	> head: 头标签，用于指定html文档的一些属性，引入外部的资源 \
	> title: 标题标签 \
	> body: 体标签 \
	> `<!DOCTYPE html>`: html5中定义该文档是html文档

## HTML文本标签
	> 注释：`<!-- 注释内容 -->` \
	> `<h1>` to `<h6>`: 标题标签，h1~h6字体大小逐渐递减 \
	> `<p>`: 段落标签 \
	> `<br>`: 换行标签 \
	> `<hr>`: 展示一条水平线

	属性：
	> color: 颜色 \
	> width: 宽度 \
	> size: 高度 \
	> align: 对齐方式 (center, left, right)
	
	> `<b>`: 字体加粗 \
	> `<i>`: 字体斜体 \
	> `<font>`: 字体标签 \
	> `<center>`: 文本居中

	属性：
	> color: 颜色 \
	> size: 大小 \
	> face: 字体
 
# JavaScript

## JavaScript数据类型
* number, string, boolean, null, undefined
  * string转number：按照字面值转换，如果字面值不是数字，则转为NaN
  * 字符串比较：按位按照字典顺序比较，越靠后越大，直到得出大小为止
  * `===`: 全等于，在比较之前，先判断类型，如果类型不一样则直接返回false
  * `&&`: 与前false则不会再计算与后的部分
	
* 其他类型转boolean:
  > number: 0 \
  > string: 除了空字符串("")，其他都是true \
  > null&undefined: false \
  > 对象：所有对象都会true
	
* 防止空指针异常：`if(obj != null && obj.length>0)`或直接`if(obj)`

## JavaScript函数
* 函数对象：
 	> `arguments`: 会把传递到函数中的实参封装成数组，可利用如`arguments.length`来判断输出实参数量
* 数组对象：
	> `join(...)`: 将数组转化为字符串并用输入的参数作为连接，如`arr.join("-")` \
  	> `filter(...)`: 遍历后返回符合条件的值，如`arr.filter((num)=>{return num>0})` \
 	> `map(...)`: 进行遍历计算，如`arr.map((num)=>{return ++num})`
* 日期对象：
	> 创建: `var date = new Date()` \
 	> `toLocaleString()`: 返回当前date对象对应的时间本地字符串格式，如`date.toLocaleString()` \
 	> `getTime()`: 获取毫秒值，返回当前如期对象描述的时间到1970年1月1日零点的毫秒值差，如`date.getTime()`
* 数学对象：
	> `random()`: 返回 0 ~ 1 之间的随机数，含0不含1 \
	> `ceil(x)`: 对数进行上舍入 \
	> `floor(x)`: 对数进行下舍入 \
 	> `round(x)`: 把数四舍五入为最接近的整数。
* 全局对象：
	> `parseInt(string)`:将字符串转为数字，逐一判断每一个字符是否是数字，直到不是数字为止，将前边数字部分转为number \
	> `isNaN(...)`:判断一个值是否是NaN，NaN六亲不认，连自己都不认，NaN参与的==比较全部问false \
	> `eval(string)`:将字符串转化为JavaScript语句，并把它作为脚本代码来执行。

## JavaScript正则表达式
* 创建
	> `var reg = new RegExp("正则表达式")` \
	> `var reg = /正则表达式/`
* 方法
	> `test(...)`:验证指定的字符串是否符合正则定义的规范
* 简单的正则表达式符号
	> `^`: 字符串开始 \
	> `$`: 字符串结束 \
	> `\s`: 空白，大写为取反，即匹配除空白之外的所有字符 \
	> `\w`: 匹配数字、字母和下划线或汉字，大写为取反 \ 
	> `\b`: 匹配单词的开始或结束，大写为取反 \
	> `\d`: 匹配数字，大写为取反 \
	> `.`: 匹配除换行符以外的任意字符 \
	> `*`: 0\~N次 \
	> `+`: 1\~N次 \
	> `?`: 0或1次 \
	> `{3}`: 3次 \
	> `{3,}`: 3\~N次 \
	> `{3,5}`: 3\~5次 \
	> `(a|b)`: a或b \
	> `[a-z]`: a到z \
	> `[^abc]`: 不是abc \
	> 用户名正则表达式示例: `var regExp = new RegExp("^[a-zA-Z0-9]{6,14}$")` \
	> 邮箱示例: `var regExpEmail = new RegExp("^[a-z0-9A-Z]+[-|a-z0-9A-Z._]+@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\.)+[a-z]{2,}$")`

## JavaScript三部分
* ECMAScript: JS的核心语法(ES规范/ECMA-262标准)
* DOM: Document Object Model(文档对象模型：对网页当中的节点进行增删改的过程)HTML文档被当做一棵DOM树来看待，如`var domObj = document.getElementById("id")`
* BOM: Browser Object Model(浏览器对象模型)。关闭浏览器窗口、打开一个新的浏览器窗口、后退、前进、浏览器地址栏上的地址等，都是BOM编程
  (BOM的顶级对象是：window，DOM的顶级对象是：document，实际上BOM是包括DOM的)

## JavaScript DOM函数
 	> `onclick`: 点击 \
	> `onblur`: 失去焦点 \
	> `onfocus`: 获取焦点 \
  	> `getElementById(...)`, `getElementByName(...)`, `getElementByTagName(...)`: 获取文本框内容 \
	> `innerHTML`, `innerTEXT`: 对div标签内容赋值，其中前者被视为HTML语句而后者仅为纯文本 \
	> `check`: 如`check.onclick = () => {if(check.checked){...} else{...}}`

## JavaScript 子节点及属性
 	> `removeAttribute(string)`: 去除样式 \
	> `setAttribute(string)`: 改变元素的属性 \
	> `createElement(string)`: 创建子节点 \
	> `createTextNode(string)`: 创建文本节点 \
	> `appendChild(textNode)`: 添加新节点 \
	> `insertBefore(...)`: 插入新节点 \
	> `removeChild(...)`: 移除 \
	> `replaceChild(...)`: 替换 \

## JavaScript BOM组成

	> Window: 窗口对象 \
	> Navigator：浏览器对象 \
	> Screen：显示器屏幕对象 \
	> History：历史记录对象 \
	> Location：地址栏对象

## JavaScript BOM函数

	> `window.open(pageURL, name, parameters)`: 打开新窗口 \
	> `window.close()`: 关闭当前窗口 \
	> `prompt(msg, defaultText)`: 弹出输入提示框 \
	> `confirm(msg)`: 弹出确认删除提示框 \
	> `setTimeout(code)`: 设置定时器 \
	> `clearTimeout(setTimeout)`: 取消定时器 \
	> `setInterval(code)`: 设置周期定时器 \
	> `clearInterval(setInterval)`: 取消周期定时器 \
	> `window.location(...)`: 对浏览器地址进行操作 \
	> `window.history(...)`: 历史记录的前进或后退 \

# CSS

## CSS 基础知识
* Cascading Style Sheets: 层叠样式表
* 层叠：多个样式可以作用在同一个html的元素上，同时生效
* 好处：功能强大，将内容展示和样式控制分离
* CSS与html结合方式:
	> **内联样式:** 在标签内使用style属性指定css代码，如`<div style="property: value;">...</div>` \
	> **内部样式:** 在head标签内，定义style标签，style标签的标签体内容就是css代码，如`<style>div{property: value;}</style><div>...</div>` \
	> **外部样式:** 定义css资源文件，在head标签内，定义link标签，引入外部的资源文件，如`<link rel="stylesheet" href="XXX.css">`
* 选择器分类：
	> `#id{property: value;}`: id选择器 \
	> `.class{property: value;}`: 类选择器 \
	> `div{property: value;}`: 元素选择器 \
	> `*{property: value;}`: 扩展选择器 \
	> `XXX, XXX{property: value;}`: 并集选择器 \
	> `XXX1 XXX2{property: value;}`: 后代选择器：筛选选择器1元素下的选择器2元素 \
	> `XXX1>XXX2{property: value;}`: 子选择器：筛选选择所有父类是选择器1的选择器2 \
	> `XXX[attr=value]{property: value;}`: 属性选择器：选择元素名称，属性名=属性值的元素 \
	> `selector:pseudo-class{property: value;}`: 伪类选择器：选择一些元素具有的状态
* 属性：https://www.w3school.com.cn/cssref/index.asp

# Jquery

## Jquery
* 导入：`<script src="js/jquery-3.X.X.min.js"></script>`
* JQuery对象和JS对象转换：`jq -- > js : jq对象[索引]`或者`jq对象.get(索引)`, `js -- > jq : $(js对象)`
* 选择器分类：
  * 基本选择器：
	> 标签选择器(元素选择器)：`$("html标签名")`获得所有匹配标签名称的元素 \
	> id选择器：`$("#id的属性值")`获得与指定id属性值匹配的元素 \
	> 类选择器：`$(".class的属性值")`获得与指定的class属性值匹配的元素 \
	> 并集选择器：`$("选择器1,选择器2....")`获取多个选择器选中的所有元素
  * 层级选择器
	> 后代选择器：`$("A B")`选择A元素内部的所有B元素 \
	> 子选择器：`$("A > B")`选择A元素内部的所有B子元素
  * 属性选择器：
	> 属性名称选择器：`$("A[属性名]")`包含指定属性的选择器 \
	> 属性选择器：`$("A[属性名='值']")`包含指定属性等于指定值的选择器 \
	> 复合属性选择器：`$("A[属性名='值'][]...")`包含多个属性条件的选择器
  * 过滤选择器：
	> 首元素选择器：`:first`获得选择的元素中的第一个元素 \
	> 尾元素选择器：`:last`获得选择的元素中的最后一个元素 \
	> 非元素选择器：`:not(selector)`不包括指定内容的元素 \
	> 偶数选择器：`:even`偶数，从0开始计数 \
	> 奇数选择器：`:odd`奇数，从0开始计数 \
	> 等于索引选择器：`:eq(index)`指定索引元素 \
	> 大于索引选择器：`:gt(index)`大于指定索引元素 \
	> 小于索引选择器：`:lt(index)`小于指定索引元素 \
	> 标题选择器：`:header`获得标题(h1~h6)元素，固定写法
  * 表单过滤选择器：
	> 可用元素选择器：`:enabled`获得可用元素 \
	> 不可用元素选择器：`:disabled`获得不可用元素 \
	> 选中选择器：`:checked`获得单选/复选框选中的元素 \
	> 选中选择器：`:selected`获得下拉框选中的元素
* DOM操作：
  * 内容操作：
	> `html()`: 获取/设置元素的标签体内容，如`<a><font>内容</font></a> --> <font>内容</font>` \
	> `text()`: 获取/设置元素的标签体纯文本内容，如`<a><font>内容</font></a> --> 内容` \
	> `val()`: 获取/设置元素的value属性值
  * (通用)属性操作：
	> `attr()`: 获取/设置元素的**自定义**属性 \
	> `removeAttr()`: 删除属性 \
	> `prop()`: 获取/设置元素的**固有**属性 \
	> `removeProp()`: 删除属性
  * (class)属性操作：
	> `addClass()`: 添加class属性值 \
	> `removeClass()`: 删除class属性值 \
	> `toggleClass()`: 切换class属性，如`toggleClass("one")`判断如果元素对象上存在`class="one"`，则将属性值one删除；反之则添加
  * CRUD操作：
	> `append()`: 父元素将子元素追加到末尾，如`对象1.append(对象2)`将对象2添加到对象1元素内部，并且在末尾 \
	> `prepend()`: 父元素将子元素追加到开头，如`对象1.prepend(对象2)`将对象2添加到对象1元素内部，并且在开头 \
	> `appendTo()`: `对象1.appendTo(对象2)`将对象1添加到对象2内部，并且在末尾 \
	> `prependTo()`: 如`对象1.prependTo(对象2)`将对象1添加到对象2内部，并且在开头 \
	> \
	> `after()`: 添加元素到元素后边，如`对象1.after(对象2)`将对象2添加到对象1后边。对象1和对象2是兄弟关系 \
	> `before()`: 添加元素到元素前边，如`对象1.before(对象2)`将对象2添加到对象1前边。对象1和对象2是兄弟关系 \
	> `insertAfter()`: 如`对象1.insertAfter(对象2)`将对象1添加到对象2后边。对象1和对象2是兄弟关系 \
	> `insertBefore()`: 如`对象1.insertBefore(对象2)`将对象1添加到对象2前边。对象1和对象2是兄弟关系 \
	>  \
	> `remove()`: 移除元素，如`对象.remove()`将对象删除掉 \
	> `empty()`: 清空元素的所有后代元素，如`对象.empty()`将对象的后代元素全部清空，但是保留当前对象以及其属性节点
* 动画：
  * 三种方式显示和隐藏元素：
	> `show([speed,[easing],[fn]])` \
	>> speed：动画的速度。三个预定义的值("slow","normal", "fast")或表示动画时长的毫秒数值(如：1000) \
	>> easing：用来指定切换效果，默认是"swing"，动画执行时效果是 先慢，中间快，最后又慢；可用参数"linear"，动画执行时速度是匀速的 \
	> `hide([speed,[easing],[fn]])` \
	> `toggle([speed],[easing],[fn])`
  * 滑动显示和隐藏方式：
	> `slideDown([speed],[easing],[fn])` \
	> `slideUp([speed,[easing],[fn]])` \
	> `slideToggle([speed],[easing],[fn])`
  * 淡入淡出显示和隐藏方式：
	> `fadeIn([speed],[easing],[fn])` \
	> `fadeOut([speed],[easing],[fn])` \
	> `fadeToggle([speed,[easing],[fn]])`
* 遍历：
	> `jquery对象.each(function(index,element){})` \
	> `$.each(object, [callback])` \
	> `for(元素对象 of 容器对象)`
* 事件绑定：
	> `jq对象.事件方法(回调函数)`: jquery标准的绑定方式 \
	> `jq对象.on("事件名称",回调函数)`, `jq对象.off("事件名称")`: on绑定事件/off解除绑定 \
	> `jq对象.toggle(fn1,fn2...)`: 事件切换
* 插件：增强JQuery的功能
	> `$.fn.extend(object)`: 增强通过JQuery获取的对象的功能 `$("#id")` \
	> `$.extend(object)`: 增强JQuery对象自身的功能 `$/jQuery`

# EL

## JSP
  * 格式: `<%@ 指令名称 属性名1=属性值1 属性名2=属性值2 …​ %>`
  * 分类
    * page：配置JSP页面
      > `contentType`: 等同于`response.setContentType()`，设置响应体的mime类型以及字符集；设置当前jsp页面的编码 \
      > `import`：导包 \
      > `errorPage`：当前页面发生异常后，会自动跳转到指定的错误页面 \
      > `isErrorPage`：标识当前页面是否是错误页面
    * `include`: 页面包含的。导入页面的资源文件，如`<%@include file="....jsp"%>`
    * `taglib`: 导入资源，如`<%@ taglib prefix="c" uri="http://....com/jsp/jstl/core" %>`
  * 注释
    * `<!-- — >`: html注释，只能注释html代码片段
    * `<%-- --%>`: jsp注释，可以注释所有
  * 内置对象(在jsp页面中不需要创建，直接使用的对象)
    > 变量名 | 真实类型 | 作用 \
    > pageContext | PageContext | 当前页面共享数据，还可以获取其他八个内置对象 \
    > request | HttpServletRequest | 一次请求访问的多个资源(转发) \
    > session | HttpSession | 一次会话的多个请求间 \
    > application | ServletContext | 所有用户间共享数据 \
    > response | HttpServletResponse | 响应对象 \
    > page | Object | 当前页面(Servlet)的对象  this \
    > out | JspWriter | 输出对象，数据输出到页面上 \
    > config | ServletConfig | Servlet的配置对象 \
    > exception | Throwable | 异常对象

## JSP文件运行原理
* 客户端→(请求页面)→JSP文件→(转换)→Servlet文件→(编译)→class文件→(执行)→Servlet实例→(返回响应)→客户端

## MVC开发模式
  * **M(Model):** 模型，JavaBean，完成具体的业务操作，如：查询数据库，封装对象
  * **V(View):** 视图，JSP，展示数据
  * **C(Controller):** 控制器，Servlet，获取用户的输入，调用模型，将数据交给视图进行展示

## EL表达式(Expression Language)
* 语法：`${表达式}`
* jsp默认支持el表达式的，如果要忽略el表达式
  * 设置jsp中page指令中：`isELIgnored="true"`忽略当前jsp页面中所有的el表达式
  * `\${表达式}`: 忽略当前这个el表达式
* 空运算符: `${empty list}`, `${not empty str}`
* 获取值
  > `${域名称.键名}`: 从指定域中获取指定键的值 \
  > `${键名}`: 表示依次从最小的域中查找是否有该键对应的值，直到找到为止 \
  > `${域名称.键名.属性名}`: 获取对象的值 \
  > `${域名称.键名[索引]}`: 获取List集合 \
  > `${域名称.键名.key名称}`或`${域名称.键名["key名称"]}`: 获取Map集合
* 隐式对象
  > `${pageContext.request.contextPath}`：动态获取虚拟目录

# JSTL

## JSTL(Java Server Pages Standarded Tag Library, JSP标准标签库)
* 使用步骤
  > 导入jstl相关jar包
  > 引入标签库：taglib指令 `<%@ taglib %>`
  > 使用标签
* 常用标签
  > `if`: `if` (`c:if`标签没有else情况，想要else情况，则可以在定义一个`c:if`标签) \
  > `choose`: `switch` \
  > `when`: `case` \
  > `otherwise`: `default` \
  > `foreach`: `for`

## 三层软件设计架构
* 界面层(表示层)：用户看的得界面，用户可以通过界面上的组件和服务器进行交互
* 业务逻辑层：处理业务逻辑的
* 数据访问层：操作数据存储文件

# AJAX

## AJAX
* ASynchronous JavaScript And XML: 异步的JavaScript和XML
  * XML: Extensible Markup Language，可扩展标记语言
  * 声明：如`<?xml version="1.0" encoding="utf-8"?>`
* 异步和同步：客户端和服务器端相互通信的基础上
  * 客户端必须等待服务器端的响应。在等待的期间客户端不能做其他操作。
  * 客户端不需要等待服务器端的响应。在服务器处理请求的过程中，客户端可以进行其他的操作。
* Ajax 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。提升用户的体验
* 通过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。
* 传统的网页（不使用 Ajax）如果需要更新内容，必须重载整个网页页面。

## Ajax的特点
* AJAX 的优点
  1) 可以无需刷新页面而与服务器端进行通信。
  2) 允许你根据用户事件来更新部分页面内容。
* Ajax的缺点
  1) 没有浏览历史，不能回退
  2) 存在跨域问题(同源)
  3) SEO 不友好

## JQeury实现方式
```
1. $.ajax()
  * 语法：$.ajax({键值对});
  //使用$.ajax()发送异步请求
  $.ajax({
      url:"ajaxServlet1111" , // 请求路径
      type:"POST" , //请求方式
      //data: "username=jack&age=23",//请求参数
      data:{"username":"jack","age":23},
      success:function (data) {
          alert(data);
      },//响应成功后的回调函数
      error:function () {
          alert("出错啦...")
      },//表示如果请求响应出现错误，会执行的回调函数
      dataType:"text"//设置接受到的响应数据的格式
  });

2. $.get()：发送get请求
  * 语法：$.get(url, [data], [callback], [type])
    * 参数：
      * url：请求路径
      * data：请求参数
      * callback：回调函数
      * type：响应结果的类型

3. $.post()：发送post请求
  * 语法：$.post(url, [data], [callback], [type])
    * 参数：
      * url：请求路径
      * data：请求参数
      * callback：回调函数
      * type：响应结果的类型
```

## HTTP简介
* HTTP（hypertext transport protocol）协议『超文本传输协议』，协议详细规定了浏览器和万维网服务器之间互相通信的规则、约定,、规则

## 原生Ajax
* XMLHttpRequest，AJAX 的所有操作都是通过该对象进行的。
* 当你前端想设置自定义的请求头时,需要如此后端设置响应头
```
//表示接收任意类型的请求
app.all('/server', (request, response) => { //响应头 允许跨域     运行自定义响应头
response.setHeader('Access-Control-Allow-Origin', '*'); response.setHeader('Access-Control-Allow-Headers', '*');}
```
* ajax请求状态:xhr.readyState 0：请求未初始化，还没有调用 open()。
​  1：请求已经建立，但是还没有发送，还没有调用 send()。
​  2：请求已发送，正在处理中（通常现在可以从响应中获取内容头）。
​  3：请求在处理中；通常响应中已有部分数据可用了，没有全部完成。
​  4：响应已完成；您可以获取并使用服务器的响应了

## 解决ie缓存问题
* 问题：在一些浏览器中(IE),由于`缓存机制`的存在，ajax 只会发送的第一次请求，剩余多次请求不会再发送给浏览器而是直接加载缓存中的数据。
* 解决方式：浏览器的缓存是根据 url地址来记录的，所以我们只需要修改 url 地址 即可避免缓存问题 xhr.open("get","/testAJAX?t="+Date.now());

## 常见三种Ajax请求方式
* jQuery发送AJAX请求（jQuery有三种发送请求方法。当你只是简单的请求数据,可以直接使用前两种方式请求,当你需要设置的东西较多的时候,可以使用 $.ajax() 方法）
  * `$.get()`
  * `$.post()`
  * `$.ajax`
* Axios发送AJAX请求
* Fetch发送AJAX请求

## 跨域与解决
* 什么是跨越？
  * 一个网页向另一个不同域名/不同协议/不同端口的网页请求资源，这就是跨域。
  * 跨域原因产生：在当前域名请求网站中，默认不允许通过ajax请求发送其他域名。
* 为什么会产生跨域请求？
  * 因为浏览器使用了同源策略
* 什么是同源策略？
  * 同源策略是Netscape提出的一个著名的安全策略，现在所有支持JavaScript的浏览器都会使用这个策略。同源策略是浏览器最核心也最基本的安全功能，如果缺少同源策略，浏览器的正常功能可能受到影响。可以说web是构建在同源策略的基础之上的，浏览器只是针对同源策略的一种实现。
  * 同源： 协议、域名、端口号 必须完全相同。 违背同源策略就是跨域。
* 为什么浏览器要使用同源策略？
  * 是为了保证用户的信息安全，防止恶意网站窃取数据，如果网页之间不满足同源要求，将不能:
    * 共享Cookie、LocalStorage、IndexDB
    * 获取DOM
    * AJAX请求不能发送
* 跨域的五个解决方式:
  * 前端使用jsonp （不推荐使用）
  * 后台Http请求转发
  * 后台配置同源Cors （推荐）
  * 使用SpringCloud网关
  * 使用nginx做转发 (推荐)

## JSONP
* JSONP 是什么?
  * JSONP(JSON with Padding)，是一个非官方的跨域解决方案，纯粹凭借程序员的聪明 才智开发出来，只支持 get 请求。
* JSONP 怎么工作的？
  * 在网页有一些标签天生具有跨域能力，比如：img link iframe script。 JSONP 就是利用 script 标签的跨域能力来发送请求的。

## CORS
* CORS是什么?
  * CORS（Cross-Origin Resource Sharing），跨域资源共享。CORS 是官方的跨域解决方 案，它的特点是不需要在客户端做任何特殊的操作，完全在服务器中进行处理，支持 get 和 post 请求。跨域资源共享标准新增了一组 HTTP 首部字段，允许服务器声明哪些 源站通过浏览器有权限访问哪些资源
* CORS是怎么工作的?
  * CORS 是通过设置一个响应头来告诉浏览器，该请求允许跨域，浏览器收到该响应 以后就会对响应放行。

# JSON

## JSON
* JavaScript Object Notation: JavaScript对象表示法
* 语法：
```
 1. 基本规则
  * 数据在名称/值对中：json数据是由键值对构成的
    * 键用引号(单双都行)引起来，也可以不使用引号
    * 值得取值类型：
      1. 数字（整数或浮点数）
      2. 字符串（在双引号中）
      3. 逻辑值（true 或 false）
      4. 数组（在方括号中）	{"persons":[{},{}]}
      5. 对象（在花括号中） {"address":{"province"："陕西"....}}
      6. null
  * 数据由逗号分隔：多个键值对由逗号分隔
  * 花括号保存对象：使用{}定义json 格式
  * 方括号保存数组：[]
2. 获取数据:
  1. json对象.键名
  2. json对象["键名"]
  3. 数组对象[索引]
  4. 遍历
   //1.定义基本格式
      var person = {"name": "张三", age: 23, 'gender': true};

      var ps = [{"name": "张三", "age": 23, "gender": true},
          {"name": "李四", "age": 24, "gender": true},
          {"name": "王五", "age": 25, "gender": false}];

      //获取person对象中所有的键和值
      //for in 循环
     /* for(var key in person){
          //这样的方式获取不行。因为相当于  person."name"
          //alert(key + ":" + person.key);
          alert(key+":"+person[key]);
      }*/

     //获取ps中的所有值
      for (var i = 0; i < ps.length; i++) {
          var p = ps[i];
          for(var key in p){
              alert(key+":"+p[key]);
          }
      }
```

## JSON数据和Java对象的相互转换
* JSON解析器：
* 常见的解析器：Jsonlib，Gson，fastjson，jackson
* JSON转为Java对象
  1. 导入jackson的相关jar包
  2. 创建Jackson核心对象 ObjectMapper
  3. 调用ObjectMapper的相关方法进行转换
    * readValue(json字符串数据,Class)
* Java对象转换JSON
  * 使用步骤：
  1. 导入jackson的相关jar包
  2. 创建Jackson核心对象 ObjectMapper
  3. 调用ObjectMapper的相关方法进行转换
    1. 转换方法：
      * writeValue(参数1，obj):
        参数1：
        File：将obj对象转换为JSON字符串，并保存到指定的文件中
        Writer：将obj对象转换为JSON字符串，并将json数据填充到字符输出流中
        OutputStream：将obj对象转换为JSON字符串，并将json数据填充到字节输出流中
        * writeValueAsString(obj):将对象转为json字符串
    2. 注解：
      1. @JsonIgnore：排除属性。
      2. @JsonFormat：属性值得格式化
        * @JsonFormat(pattern = "yyyy-MM-dd")
    3. 复杂java对象转换
      1. List：数组
      2. Map：对象格式一致

# Axios

## axios 是什么?
* 前端最流行的 ajax 请求库
* react/vue 官方都推荐使用 axios 发 ajax 请求

## axios 特点
* 基于 xhr + promise 的异步 ajax 请求库
* 浏览器端/node 端都可以使用
* 支持请求／响应拦截器
* 支持请求取消
* 请求/响应数据转换
* 批量发送多个请求

## axios 常用语法
* axios(config): `通用/最本质`的发任意类型请求的方式
* axios(url[, config]): 可以只指定 url 发 get 请求
* axios.request(config): 等同于 axios(config)
* axios.get(url[, config]): 发 get 请求
* axios.delete(url[, config]): 发 delete 请求
* axios.post(url[, data, config]): 发 post 请求
* axios.put(url[, data, config]): 发 put 请求
* axios.defaults.xxx: 请求的默认全局配置
* axios.interceptors.request.use(): 添加请求拦截器
* axios.interceptors.response.use(): 添加响应拦截器
* axios.create([config]): 创建一个新的 axios(它没有下面的功能)
* axios.Cancel(): 用于创建取消请求的错误对象
* axios.CancelToken(): 用于创建取消请求的 token 对象
* axios.isCancel(): 是否是一个取消请求的错误
* axios.all(promises): 用于批量执行多个异步请求
* axios.spread(): 用来指定接收所有成功数据的回调函数的方法

# Promise

## Promise
* 状态
  * pending: 未决定的
  * resolved/fullfilled: 成功，结果为value
  * rejected: 失败，结果为reason
* async&await
  * Promise: 异步
  * await: 异步转同步
    * 可以理解为是async wait的简写。await必须出现在async函数内部，不能单独使用
    * 后面可以跟任何的JS表达式。虽然说await可以等很多类型的东西，但是它最主要的意图是用来等待Promise对象的状态被resolved。如果await的是promise对象会造成异步函数停止执行并且等待promise的解决,如果等的是正常的表达式则立即执行
    * await右侧的表达式一般为promise对象, 但也可以是其它的值
    * 如果表达式是promise对象, await返回的是promise成功的值
    * 如果表达式是其它值, 直接将此值作为await的返回值
    * 如果await的promise失败了, 就会抛出异常, 需要通过try…​catch捕获处理
  * async: 同步转异步
    * 方法体内部的某个表达式使用await修饰，那么这个方法体所属方法必须要用async修饰所以使用awit方法会自动升级为异步方法
    * 函数的返回值为promise对象
    * promise对象的结果由async函数执行的返回值决定

https://github.com/warrenlucky/zerostart/blob/main/java/React/React%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/Promise.adoc

# React

## React搭建与代码使用
> `yarn install`: 创建node_modules \
> `yarn start`或`npm start`: 运行src案例 \
> `Ctrl+C`: 退出脚手架或服务器，刷新后无法再次进入原网页(无需看到`^C`显示，只要`path>`弹出即可) \
> `node server.js`: 开启服务器(可通过创建多个终端来运行多个服务器)

## React介绍
* 用于构建用户界面的JavaScript库
* 使用：引入几个react包
  > `<script src="../js/react.development.js"></script>`: React核心库 \
  > `<script src="../js/react-dom.development.js"></script>`: 操作DOM的React扩展库 \
  > `<script src="../js/babel.min.js"></script>`: 将JSX转为JS的babel库
* JS创建虚拟DOM
  > `const VDOM=React.createElement('h1', {id:'title'}, React.createElement('span', {}, 'hello,React'))`: 创建虚拟DOM，创建嵌套格式的DOM \
  > `ReactDOM.render(VDOM, document.getElementById('test'))`: 渲染虚拟DOM到页面
* JSX创建虚拟DOM
  > `const VDOM = (<h1><span>Hello, React</span></h1>)`: 创建虚拟DOM \
  > `ReactDOM.render(VDOM, document.getElementById('test'))`: 渲染虚拟DOM到页面
* **JSX语法** (JSX: 基于JavaScript+XML的扩展语法)
  * 标签中混入JS表达式的时候使用`{}`
  * 样式的类名指定不能使用class，使用className
  * 内联样式要使用`{{}}`包裹
  * 不能有多个根标签，只能有一个根标签
  * 标签必须闭合(`< ></ >`)，自闭合(`< />`)也行
  * 如果小写字母开头，就将标签转化为html同名元素，如果html中无该标签对应的元素，就报错；如果是大写字母开头，React就去渲染对应的组件，如果没有定义就报错
  * **注释**必须写在**花括号**里，如`{/*注释...*/}`
  * JSX 允许在模板中插入数组，数组自动展开全部成员

## JSX语法补充
* 内联样式要使用`{{}}`包裹；注释必须写在花括号里：外面的大括号是用来告诉JSX解析器，括号中的内容是JavaScript，而不是一个字符串；而里面的大括号用来初始化一个对象
* 不能有多个根标签，只能有一个根标签：可使用`<></>`或`<div></div>`标签将所有的内容包裹

## React组件
* 注意
  * 组件名必须是首字母大写
  * 虚拟DOM元素只能有一个根元素
  * 虚拟DOM元素必须有结束标签`</>`
* 渲染类组件标签的基本流程
  1. React内部会创建组件实例对象
  2. 调用render()得到虚拟DOM ,并解析为真实DOM
  3. 插入到指定的页面元素内部
* 函数式组件(只有props)
  1. `function Demo(){return <h2>用函数定义的组件</h2>}`: 先创建函数，函数可以有参数，也可以没有，但是必须要有返回值，返回一个虚拟DOM
  2. `ReactDOM.render(<Demo/>, document.getElementById('test'))`: 进行渲染
* 类式组件
  1. `class Demo2 extends React.Component {render(){console.log(this)return <h2>用类定义的组件</h2>}`
  2. `ReactDOM.render(<Demo2/>, document.getElementById('test'))`
* 组件实例三大属性
  * **state**
    * 使用的时候通过this.state调用state里的值
    * 在类式组件中定义state
    * 在构造器中初始化state
    * 在类中添加属性state来初始化
    > `this.setState(partialState, [callback])`: partialState是需要更新的状态的部分对象，callback是更新完状态后的回调函数；状态必须通过setState进行更新,且更新是一种合并，不是替换
    * 在执行 setState操作后，React 会自动调用一次`render()`
    * `render()`的执行次数是1+n(1为初始化时的自动调用，n为状态更新的次数)
  * **props**
    * 外部传入的数据在类式组件中使用
    * 通过在组件标签上传递值，在组件中就可以获取到所传递的值
    * 在构造器里的props参数里可以获取到props
    * 可以分别设置propTypes和defaultProps两个属性来分别操作props的规范和默认值，两者都是直接添加在类式组件的原型对象上的(所以需要添加static)
    * 同时可以通过`...`​运算符来简化
    > `<script src="../js/prop-types.js"></script>`: 引入库 \
    > `static propTypes`: 属性限制 \
    > `static defaultProps`: 属性默认值
    * 函数组件的props定义:
      * 在组件标签中传递props的值
      * 组件函数的参数为props
      * 对props的限制和默认值同样设置在原型对象上
  * **refs**
    * 允许我们访问DOM节点或在render方法中创建的React元素，而不需要采用DOM API来查找元素
    * 字符串形式：
    ```JavaScript
    myFunc = () => {
      const {myInput} = this
      alert(myInput.value)}
    render(){return(<input onBlur={this.myFunc} ref="myInput" type="text"/>)}
    ```
    * 回调形式：
    ```JavaScript
    myFunc = () => {
      const {myInput} = this
      alert(myInput.value)}
    render(){return(<input onBlur={this.myFunc} ref={c=>this.myInput=...} type="text"/>)}
    ```
    * createRef形式：
    ```JavaScript
    myRef = React.createRef() //创建ref容器
    myFunc = () => {
      alert(this.myRef.current.value)}
    render(){return(<input onBlur={this.myFunc} ref={this.myRef} type="text"/>)}
    ```
    * 事件处理：建议不要过度的使用ref，如果发生事件的元素刚好是需要操作的元素，就可以使用事件对象(event)去替代
    ```JavaScript
    myRef = React.createRef() //创建ref容器
    myFunc = (event) => {
      alert(event.target.value)}
    render(){return(<input onBlur={this.myFunc} ref={this.myRef} type="text"/>)}
    ```

## React受控组件与非受控组件
* 受控组件：React中，可变状态通常保存在组件的状态属性中，并且只能使用`setState()`更新，而呈现表单的React组件也控制着在后续用户输入时该表单中发生的情况，以这种由React控制的输入表单元素而改变其值的方式
  ```JavaScript
  state = {myContent:''}
  saveMyContent = (event) => {
    this.setState({MyContent:event.target.value})}
  render(){return(<input onChange={this.myContent} type="text"/>)}
  ```
* 非受控组件：表单数据由DOM本身处理。即不受`setState()`的控制，与传统的HTML表单输入相似，input输入值即显示最新值(使用 ref从DOM获取表单值)
  ```JavaScript
  render(){return(<input ref={c => this.myContent = c} type="text"/>)}
  ```

## 高阶函数
* 如果一个函数符合下面2个规范中的任何一个，那该函数就是高阶函数
  * 若A函数，接收的参数是一个函数，那么A就可以称之为高阶函数
  * 若A函数，调用的返回值依然是一个函数，那么A就可以称之为高阶函数
  * 常见的高阶函数有：Promise、setTimeout、arr.map()等等
* 函数的柯里化：通过函数调用继续返回函数的方式，实现多次接收参数最后统一处理的函数编码形式
* 使用函数柯里化实现
  ```JavaScript
  state = {myContent:''}
  saveMyContent = (dataType) => {
    return (event)=>{
      this.setState({[dataType]:event.target.value})}}
  render(){return(<input onChange={this.myContent} type="text"/>)}
  ```
* 不使用函数柯里化实现
  ```JavaScript
  state = {myContent:''}
  saveMyContent = (dataType, event) => {
      this.setState({[dataType]:event.target.value})}
  render(){return(<input onChange={event => this.myContent} type="text"/>)}
  ```

## React组件旧生命周期
* 三个阶段：初始化阶段，更新阶段，卸载组件
* **初始化阶段:** 由ReactDOM.render()触发---初次渲染
  1. **constructor执行:** 在组件初始化的时候只会执行一次。通常它用于做这两件事：1.初始化函数内部state；2.绑定函数；现在通常不会使用constructor，而是改用类加箭头函数的方法来替代，如`state = {count: 0}`
  2. **componentWillMount执行:** 该方法只在挂载的时候调用一次，表示组件将要被挂载，并且在render方法之前调用(将要被废弃)
  3. **render执行:** 组件中必须实现的方法，用于渲染DOM，但是它不会真正的操作DOM，它的作用是把需要的东西返回出去。实现渲染DOM操作的是`ReactDOM.render()`(注意：避免在 render 中使用 setState ，否则会死循环)
  4. **componentDidMount执行:** 意味着初始化挂载操作已经基本完成，它主要用于组件挂载完成后做某些操作。这个挂载完成指的是：组件插入DOM tree
* **更新阶段:** 由组件内部`this.setSate()`或父组件render触发
  1. **shouldComponentUpdate执行:** 在组件更新之前调用，可以通过返回值来控制组件是否更新，允许更新返回true，反之不更新
  2. **componentWillUpdate执行:** 在render之前执行，表示组件将要更新
  3. **render执行:** 在控制是否更新的函数中，如果返回true才会执行render,得到最新的 React element
  4. **componentDidUpdate执行:** 组件在更新完毕后会立即被调用，首次渲染不会调用
  5. **(特殊)componentWillReceiveProps:** 表示组件将要接收新的props的钩子
* **卸载组件:** 由`ReactDOM.unmountComponentAtNode()`触发
  1. **componentWillUnmount执行:** 在组件即将被卸载或销毁时进行调用

## React组件新生命周期
* 在旧生命周期的基础上，废弃三个生命周期，新增两个生命周期
* **初始化阶段:** 由ReactDOM.render()触发---初次渲染
  1. **constructor执行:** 在组件初始化的时候只会执行一次
  2. **(新)static getDerivedStateFromProps执行:** 在初始化和更新中都会被调用，并且在render方法之前调用，它返回一个对象用来更新state；是类上直接绑定的静态（static）方法，它接收两个参数props和state；props是即将要替代state的值，而state是当前未替代前的值(注意：`return props`而非'return null`时，state的值在任何时候都取决于传入的props，不会再改变)
  3. **render执行:** 组件中必须实现的方法，用于渲染DOM，但是它不会真正的操作DOM，它的作用是把需要的东西返回出去。
  4. **componentDidMount执行:** 意味着初始化挂载操作已经基本完成，它主要用于组件挂载完成后做某些操作
* **更新阶段:** 由组件内部`this.setSate()`或父组件render触发
  1. **(新)getDerivedStateFromProps执行:** 执行生命周期，返回的值用于合并state，生成新的state
  2. **shouldComponentUpdate执行:** 在组件更新之前调用，可以通过返回值来控制组件是否更新，允许更新返回 true ，反之不更新
  3. **render执行:** 在控制是否更新的函数中，如果返回true才会执行render ,得到最新的React element
  4. **(新)getSnapshotBeforeUpdate执行:** 在最近一次的渲染输出之前被提交之前调用，也就是即将挂载时调用。相当于淘宝购物的快照，会保留下单前的商品内容，在React中就相当于是即将更新前的状态。它可以使组件在DOM真正更新之前捕获一些信息(例如滚动位置)，此生命周期返回的任何值都会作为参数传递给`componentDidUpdate()` 。如不需要传递任何值，那么请返回null
  5. **componentDidUpdate执行:** 组件在更新完毕后会立即被调用，首次渲染不会调用
* **卸载组件:** 由`ReactDOM.unmountComponentAtNode()`触发
  1. **componentWillUnmount执行:** 在组件即将被卸载或销毁时进行调用

## React diffing算法
* 概念和作用：React提升渲染性能的一种优化算法，计算出Virtual DOM中真正变化的部分，并只针对该部分进行原生DOM操作，而非重新渲染整个页面
* Virtual DOM(虚拟 DOM): 在React中，render执行的结果得到的并不是真正的DOM节点，而是JavaScript对象。虚拟DOM只保留了真实DOM节点的一些基本属性，和节点之间的层次关系，它相当于建立在JavaScript和DOM之间的一层“缓存”
* 对于一个节点必备的三个属性
  * tag: 指定元素的标签类型，如li, div
  * props: 指定元素身上的属性，如class, style, 自定义属性
  * children: 指定元素是否有子节点，参数以数组形式传入 \
    而我们在 render 中编写的 JSX 代码就是一种虚拟 DOM 结构
* 传统diff算法：通过循环递归对节点进行依次对比，算法复杂度达到O(n^3)，其中n是树的节点数
* React的diff算法：O(n)复杂度
  * tree diff策略：Web UI中DOM节点跨层级的移动操作特别少，可以忽略不计
    * React通过updateDepth对Virtual DOM树进行层级控制
    * 对树分层比较(分层求异)，两棵树只对同一层次节点进行比较。如果该节点不存在时，则该节点及其子节点会被完全删除，不会再进一步比较
    * 只需遍历一次，就能完成整棵DOM树的比较
    * 由于React只会简单的进行同层级节点位置变化，对于不同层级的节点，只有创建和删除操作
  * component diff策略：拥有相同类的两个组件生成相似的树形结构；拥有不同类的两个组件生成不同的树形结构。
    * 如果是同一类型的组件，则按照原策略（层级比较)继续比较虚拟DOM tree
    * 如果不是，则将这个组件记为dirty component(脏组件)，从而替换整个组件下的所有子节点
    * 同时对于同一类型的组件，有可能其Virtual DOM没有任何变化，如果能够确切的知道这点就可以节省大量的diff运算的时间，因此React允许用户通过shouldComponentUpdate()判断该组件是否需要进行diff算法分
    * 总的来说，如果两个组件结构相似，但被认定为了不同类型的组件，则不会比较二者的结构，而是直接删除
  * element diff策略：对于同一层级的一组子节点，通过唯一id区分
    * 是专门针对同一层级的所有节点的策略。当节点在同一层级时，diff提供了3个节点操作方法：插入，移动，删除
    * 允许添加唯一值key来区分节点，且不能用index作为key值
    * 在 React 中只允许节点右移，则只需要对移动的节点进行更新渲染，不移动的则不需要更新渲染
      ```JavaScript
      render(){return(<ul>{this.state.XXX.map((XXX) => {return <li key={XXX.xxx}>{XXX.xxx}<input type="text"/></li>})}</ul>)}
      ```

## React 脚手架
* __, 启动!
  * 安装：`npm i create-react-app -g`
  * 快速搭建项目：`create-react-app hello-react`
  * 启动项目：`npm start`
* 脚手架项目结构
  ```
  hello-react
  ├─ .gitignore               // 自动创建本地仓库
  ├─ package.json             // 相关配置文件
  ├─ public                   // 公共资源
  │  ├─ favicon.ico           // 浏览器顶部的icon图标
  │  ├─ index.html            // 应用的 index.html入口
  │  ├─ logo192.png           // 在 manifest 中使用的logo图
  │  ├─ logo512.png           // 同上
  │  ├─ manifest.json         // 应用加壳的配置文件
  │  └─ robots.txt            // 爬虫协议文件
  ├─ src                      // 源码目录
  │  ├─ App.css               // App组件的样式
  │  ├─ App.js                // App组件
  │  ├─ App.test.js           // 用于给APP做测试
  │  ├─ index.css             // 样式
  │  ├─ index.js              // 入口文件
  │  ├─ logo.svg              // logo图
  │  ├─ reportWebVitals.js    // 页面性能分析文件(需要web-vitals库的支持)
  │  └─ setupTests.js         // 组件单元测试文件(需要jest-dom库的支持)
  └─ yarn.lock                // 包管理工具
  ```

## React 脚手架ToDoList案例
  1. 拆分组件
  2. 实现静态组件
    * 打好注释
    * 每个部分的CSS要写在一个地方，不要随意写
    * 命名一定要规范
    * CSS 选择器不要关联太多层级
    * 在写 HTML 时就要划分好布局
    然后我们将每个组件，对应的HTML结构CV到对应组件的`index.jsx`文件中`return`出来，再将CSS样式添加到`index.css`文件中。注意，在`index.jsx`中一定要引入`index.css`文件。
  3. 实现动态组件
     1. 动态展示列表
        * 对于复选框的选中状态，这里采用的是`defaultChecked = {done}`，相比于checked属性，这个设定的是默认值，能够更改
     2. 添加事项功能
        * 保证id的唯一性：`import { nanoid } from 'nanoid';`后`nanoid()`，每一次调用都会返回一个唯一的值
        * 回车键触发：`if(keyCode != 13) return`
        * 判断去除空格后非空：`if(target.value.trim() === '') return`, 其中`trim()`方法去除了左右空格，`===`要求数据的值和数据类型都要完全一样才返回true
        * 以目前的知识，兄弟组件没有办法进行直接的数据传递，因此可以将数据传递给父组件再由父组件转发给兄弟组件
     3. 实现鼠标悬浮效果
     4. 复选框状态维护
     5. 限制参数类型
     6. 删除按钮
     7. 获取完成数量
     8. 全选按钮
        * 使用`checked`全程受状态控制，不可以切换；使用`defaultchecked`只在初始渲染时由状态控制，之后更新不再跟状态有关系
        * `defaulChecked`只有第一次会起作用，所以我们需要将前面写的改成`checked`添加`onChange`事件即可
     9. 删除已完成
  5. 总结
     * 父组件给子组件传递数据，采用`props`
     * 子组件给父组件传递数据，通过`props`，同时提前给子组件传递一个函数

## React脚手架配置代理
* React本身只关注于页面，并不包含发送Ajax请求的代码，所以一般都是集成第三方的包，或者自己封装的。自己封装的话，比较麻烦，而且也可能考虑不全。常用的有两个库，一个是JQuery，一个是axios
  * JQuery比较重，因为Ajax服务也只是它这个库里的一小块功能，它主要做的还是DOM操作，而这不利于React，不推荐使用
  * axios就比较轻，而且采用Promise风格，代码的逻辑会相对清晰，推荐使用
* 配置代理方式解决跨域问题
  * **全局代理**
    * 直接将代理配置在配置文件`package.json`中，如`"proxy":"http://localhost:5000" // "proxy":"请求的地址"`
    * 这样配置代理时，首先会在原请求地址上访问，如果访问不到文件，就会转发到这里配置的地址上去请求
    * 但是这样会有一些问题，它会先向我们请求的地址，也就是这里的 3000 端口下请求数据，如果在 3000 端口中存在我们需要访问的文件，会直接返回，不会再去转发，因此这就会出现问题；同时因为这种方式采用的是全局配置的关系，导致只能转发到一个地址，不能配置多个代理
  * **setupProxy方式**
    * 可以给多个请求配置代理；工作原理和全局配置是一样的，但是写法不同
      1. 首先需要在src目录下，创建代理配置文件`setupProxy.js`(只能叫这个名字)
      2. 引入`http-proxy-middleware`中间件，然后需要导出一个对象，这里建议使用函数，使用对象的话兼容性不大好
      3. 在`app.use`中配置我们的代理规则；接收的第一个参数是需要转发的请求，当有这个标志的时候，预示着我们需要采用代理，所有添加了该前缀的请求都会转发到这
      4. `target`属性：用于配置转发目标地址，也就是我们数据的地址
      5. `changeOrigin`属性：用于控制服务器收到的请求头中`host`字段，可以理解为一个伪装效果，为`true`时，收到的`host`就为请求数据的地址
      6. `pathRewrite`属性：用于去除请求前缀
      ```JavaScript
      const { createProxyMiddleware } = require('http-proxy-middleware');
      module.exports = function(app) {
      app.use("/api",createProxyMiddleware({
          target:'http://127.0.0.1:5001', //配置转发目标地址
          changeOrigin:true, //控制服务器接收到的请求头中host字段的值
          pathRewrite:{
              "^/api":""     //去除请求前缀址(必须配置)
          }
      }))
      ```

## React_Github案例
1. 实现静态组件
  * class需要改成`className`
  * style的值需要使用双花括号的形式
  * `img`标签，一定要添加`alt`属性表示图片加载失败时的提示
  * 'a'标签(超链接)要添加`rel="noreferrer"`属性，不然会有大量的警告出现
2. axios发送请求
  > `<input ref={c => this.keyWordElement = c} type="text" />`: 通过`this.keyWordElement`属性来获取到这个当前节点，也就是这个`input`框 \
  > `const { keyWordElement: { value: keyWord } } = this`: 再通过`value`值，即可获取到当前`input`框中的值
3. 渲染数据
4. 增加交互
  > `isFrist`来判断页面是否第一次启动，初始值给`true`，点击搜索后改为`false` \
  > `isLoading`来判断是否应该显示`Loading`动画，初始值给`false`，在点击搜索后改为`true`，在拿到数据后改为`false` \
  > `err`来判断是否渲染错误信息，当报错时填入报错信息，初始值给空 \
  `state = { users: [], isFirst: true, isLoading: false, err: '' }`

## React消息订阅与发布
* 利用消息订阅与发布机制来解决兄弟组件间的通信
1. 安装库：`npm i pubsub-js`
2. 引入库：`import PubSub from 'pubsub-js'`
3. 订阅消息：`PubSub.subscribe('search',(msg,data)=>{console.log(msg,data);})`；subscribe会返回一个token，这个就类似于定时器的编号的存在，我们可以通过这个token值，来取消对应的订阅：`  PubSub.unsubscribe(this.token)`
4. 发布消息：`PubSub.publish('search',{name:'tom',age:18})`
* 扩展—Fetch发送请求
  ```JavaScript
    fetch('http://xxx')
      .then(response => response.json())
      .then(json => console.log(json))
      .catch(err => console.log('Request Failed', err));
  ```
  fetch 关注分离(Separation of Concerns)，它在第一次请求时，不会直接返回数据，会先返回联系服务器的状态，在第二步中才能够获取到数据。我们需要在第一次`then`中返回`response.json()`因为这个返回的是包含数据的 promise 对象，再调用一次`then`方法即可实现。但是这么多次的调用`then`并不是我们所期望的。所以可以利用`async`和`await`配合使用，来简化代码
  ```JavaScript
    search = async() => {
      const {keywordelement:{value:keyword}} = this
      PubSub.publish('lvjiahao',{isFirst:false,isLoading:true})
      try {
          const response = await fetch(`/api/search/users?q=${keyword}`)
          const data = await response.json()
          PubSub.publish('lvjiahao',{isLoading:false,users:data.items})
      } catch (error) {
          PubSub.publish('lvjiahao',{isLoading:false,err:error.reason})
      }
    }
  ```

## React路由组件基本使用 (V6)**
* SPA: 单页应用程序。它比传统的Web应用程序更快，因为它们在Web浏览器本身而不是在服务器上执行逻辑。在初始页面加载后，只有数据来回发送，而不是整个HTML，这会降低带宽。它们可以独立请求标记和数据，并直接在浏览器中呈现页面
* 路由：根据不同的URL地址展示不同的内容或页面。在SPA应用中，大部分页面结果不改变，只改变部分内容的使用
  * 前端路由的优点：用户体验好，不需要每次都从服务器全部获取整个HTML，快速展现给用户
  * 前端路由的缺点：SPA无法记住之前页面滚动的位置，再次回到页面时无法记住滚动的位置；使用浏览器的前进和后退键会重新请求，没有合理利用缓存
* 路由的原理：前端路由主要依靠history，也就是浏览器的历史记录，且历史记录上可以采用`listen`来监听请求路由的改变，从而判断是否改变路径；在H5中新增了`createBrowserHistory`的API，用于创建一个history栈，允许我们手动操作浏览器的历史记录；新增API：`pushState`，`replaceState`
* 路由的基本使用
  1. 引入库：`import { Link, BrowserRouter, Route } from 'react-router-dom'`
  2. 导航区的a标签改为Link标签：`<Link className="list-group-item" to="/about">About</Link>`
  3. Route标签进行路径的匹配：`<Route path='/home' element={<Home/>} />`
  4. 添加路由器管理路由：`<BrowserRouter>< App /></BrowserRouter>`
* 路由组件和一般组件
  * 一般组件：`<Demo/>`，放在`components`文件夹
  * 路由组件：`<Route path="/demo" element={<Demo/>}/>`，放在`pages`文件夹，且`props`为空
* NavLink标签：
  * 选中某个NavLink标签时，就会自动的在类上添加一个`active`属性：`<NavLink className={({isActive}) => "list-group-item" + (isActive ? " light" : "")} to="/about" >About</NavLink>`(注意`" light"`前的空格)
* NavLink封装
  * 新建一个`MyNavLink`一般组件，对`NavLink`进行封装：`<NavLink className={({isActive}) => "list-group-item" + (isActive ? " light" : "")} {...this.props}/>`，`<MyNavLink to="/home">home</MyNavLink>`

## React路由组件传参**
* 相同路径问题：先从`react-router-dom`中暴露出`Switch`/`Routes`组件，再采用`Switch`(V5)/`Routes`(V6)组件进行包裹
* 二级路由样式丢失
  * 将样式引入的路径改成绝对路径`%PUBLIC_URL%`
  * 引入样式文件时不带`.`
  * 使用`HashRouter`
* 路由的精准匹配和模糊匹配
  * V6版本默认开启精准匹配
  * 会根据先后顺序匹配路由；如果第一个没有匹配上，那就会失败
  * 开启精准匹配采用的是`exact`来实现
* 重定向路由
  * 默认就能匹配到一个组件；页面找不到指定路径时，就会重定向
  > V5: `<Redirect to="/about" />`
  > V6: `<Route path='*' element={<Navigate to='/about'/>} />`
* 嵌套路由
* 传递参数
  * **传递params参数**
    * 通过将数据拼接在路由地址末尾来实现数据的传递：`<Link to={`detail/${MessageObj.id}/${MessageObj.title}`}>{MessageObj.title}</Link>`
    * 在注册路由时，我们可以通过`:数据名`来接收数据：`<Route path='detail/:id/:title' element={<Detail/>}/>`
    * 更改Detail组件为函数式组件，在`react-router-dom`中取出`useParams`
  * **传递search参数**
    * 在Link中采用`?`符号的方式来表示后面的为可用数据：`<Link to={`detail/?id=${MessageObj.id}&title=${MessageObj.title}`}>{MessageObj.title}</Link>`
    * 更改Detail组件为函数式组件，在`react-router-dom`中取出`useSearchParams`
  * **传递state参数**
    * 需要在Link中注册跳转时，传递一个路由对象，包括一个跳转地址名，一个state数据，这样我们就可以在Detail组件中获取到这个传递的state数据：`<Link to='detail' state={{ id:MessageObj.id,title:MessageObj.title }}>{MessageObj.title}</Link>`
    * 采用这种方式传递，无需声明接收，可以在Detail组件中的location对象下的state中取出我们所传递的数据：`const { id, title } = this.props.location.state`
    * 解决清除缓存造成报错的问题，我们可以在获取不到数据的时候用空对象来替代，更改Detail组件为函数式组件，在`react-router-dom`中取出`useLocation`(`||{}`)

## React路由跳转**
* 默认`push`；在需要开启的链接上加上`replace`: `<Link replace to='detail' state={{ id:MessageObj.id,title:MessageObj.title }}>{MessageObj.title}</Link>`
编程式路由导航
* 编程式路由导航
  * 采用绑定事件的方式实现路由的跳转，在按钮上绑定一个`onClick`事件，当事件触发时，执行一个回调`replaceShow`
  * `useNavigate`，在回调中，调用`navigate`实现模拟跳转和传递是否为`replace`模式：`const replaceShow = (id,title) => {navigate(`detail`,{state:{id,title},replace:true})}`
* withRouter(V5)
  * 只有路由组件才能获取到`history`对象
  * V6调用`navigate`实现跳转
    ```JavaScript
    import { useNavigate } from 'react-router-dom'
    <button onClick={() => navigate(-1)}>go back</button>
    <button onClick={() => navigate(1)}>go forward</button>
    ```
* `BrowserRouter`和`HashRouter`的区别
  * 它们的底层实现原理不一样
    * `对于BrowserRouter`来说它使用的是React为它封装的history API，这里的history和浏览器中的history有所不同 通过操作这些API来实现路由的保存等操作，但是这些 API 是 H5 中提出的，因此不兼容IE9以下版本
    * 对于`HashRouter`而言，它实现的原理是通过URL的哈希值。可以理解为是锚点跳转，因为锚点跳转会保存历史记录，从而让`HashRouter`有了相关的前进后退操作，`HashRouter`不会将`#`符号后面的内容请求。兼容性更好
  * 地址栏的表现形式不一样
    * `BrowserRouter`的路径中不包含`#`，例如`localhost:3000/demo/test`，更为美观
    * `HashRouter`的路径中包含`#`，例如`localhost:3000/#/demo/test`
  * 刷新后路由state参数改变
    * 在`BrowserRouter`中，`state`保存在`history`对象中，刷新不会丢失
    * `HashRouter`刷新会丢失`state`

## React_antd组件库**
* 在需要使用的文件下引入：`import { Button } from 'antd'`
* 还需要引入antd的CSS文件：`@import '/node_modules/antd/dist/antd.less';`

## React_redux基本使用**
* Redux三个核心概念
  * store
    * 在`src`目录下的redux文件夹中新增一个`store.js`文件，在这个文件中，创建一个`store`对象，并暴露它
    * `import { createStore } from "redux"`
    * 引入为count组件服务的reducer：`import countReducer from './count_reducer'`
    * 暴露`store`：`export default createStore(countReducer)`
    * 获取当前时刻的`store`：`const state = store.getState();`
    * 通过`store`中的`dispatch`方法来派生一个`action`对象给`store`：`store.dispatch('action对象')`
    * 直接将`subscribe`函数用来监听整个`App`组件的变化：`store.subscribe(() => {ReactDOM.render( < App /> , document.getElementById('root'))})`
  * action
    * `action`是`store`中唯一的数据来源，通过调用`store.dispatch`将`action`传到 `store`：`export const createIncrementAction = data => ({type:INCREMENT,data})`会返回一个`action`对象
  * reducer
    * `reducer`会根据`action`的指示，对`state`进行对应的操作，然后返回操作后的`state`
* 创建constant文件
  * 在redux目录下创建，用于定义我们代码中常用的一些变量：` export const INCREMENT = 'increment'`
* 实现异步action
  * 如果需要实现传入函数，就引入中间件，在原生的`redux`中暴露出`applyMiddleware`中间件执行函数：`import thunk from 'redux-thunk'`并通过第二个参数传递`export default createStore(countReducer, applyMiddleware(thunk))`
* Redux三大原则
  * **单向数据流:** UI组件→action→store→reducer→store
  * **state 只读:** 如果想要改变`state`，则需要触发一次`action`。通过`action`执行`reducer`
  * **纯函数执行:** 每一个`reducer`都是一个纯函数，不会有任何副作用，返回是一个新的 `state`，`state`改变会触发`store`中的`subscribe`

## React-Redux基本使用**
* 容器组件和UI组件
  * 所有的UI组件都需要有一个容器组件包裹
  * 容器组件来负责和Redux打交道，可以随意使用Redux的API
  * UI组件无任何Redux API
  * 容器组件用于处理逻辑，UI组件只会负责渲染和交互，不处理逻辑
* Provider: 把`Provider`注册在根部组件
* connect
  * `mapStateToProps`: 打通UI组件和容器组件间的状态传递
  * `mapDispatchToProps`: 建立UI组件的参数到`store.dispacth`方法的映射
* 完整开发

## React数据共享**
* 纯函数：不改变参数的函数，也就是说，传入的参数是不能被改变的；如果采用`push`或`unshift`等数组方法，原数组发生改变，也就是传入的参数会被改变
* 利用对象的简写方法，将键名和键值同名，从而只写一个名即可
* 合并`reducer`，我们可以将多个`reducer`文件写在一个`index`文件当中，需要采用`combineReducers`来合并
* 项目打包：执行`npm run build`命令，即可打包项目，打包完成后，会生成一个`build`文件，这个文件我们需要部署到服务器上运行

## React拓展**
* **setState**
  * React状态更新是异步的
  * `setState`调用的第二个参数，可以接收一个函数，这个函数会在状态更新完毕并且界面更新之后调用
  * 函数式的`setState`也是接收两个参数
     * 第一个参数是`updater`，它是一个能够返回 stateChange 对象的函数
     * 第二个参数是一个回调函数，用于在状态更新完毕，界面也更新之后调用
     * 与对象式`setState`不同的是，我们传递的第一个参数`updater`可以接收到2个参数`state`和`props`
   * 对象式的`setState`是函数式`setState`的语法糖
* **LazyLoad**
  * 从`react`库中暴露一个`lazy`函数：`import React, { Component ,lazy } from 'react'`
  * loading包裹：`<Suspense fallback={<Loading/>}>... </Suspense>`，必须提前引入，不能懒加载
* **Hooks**
  * **useState**
    * 函数式组件没有自己的`this`
    * `const [state, setState] = React.useState(defaultValue)`: 初始值只有第一次有效；返回一个数组，第一个元素是`state`，第二个是更新`state`的函数
  * **useEffect**
    * 第一个参数的函数体相当于`componentDidMount`
    * 第一个参数的返回体相当于`componentDidUnmount`
    * 第二个参数表示它要监测的数据，也就是他要监视哪个数据的变化；当我们不需要监听任何状态变化的时候，可以传递一个空数组`, []`，相当于`componentMidMount`
  * **useRef**
    * 创建一个`ref`容器，这和`createRef`很类似
* **Fragment**
  * 内容能直接挂在`root`标签下
  * 空标签也能实现，但是它不能接收任何值，而`Fragment`能够接收1个值`key`
* **Context**
  * 给子组件的子组件传递数据
  * 在函数式组件中使用，需要引入`Consumer`
* **PureComponent**
  * 只有组件的`state`或者`props`数据发生改变的时候，再调用`render`
  * `PureComponent`会对比当前对象和下一个状态的`prop`和`state`，属于浅比较，比较的是它的引用地址是否相同，这个比较与内容无关
* **render props**
  * 在组件标签中传入一个`render`方法，又属于`props`
  * 当在一个组件标签中填写内容时，这个内容会被定义为`children props`，可以通过`this.props.children`来获取
* **ErrorBoundary**
  * 要对容易出错的组件的父组件做手脚，而不是组件本身
  * 在父组件中通过`getDerivedStateFromError`来配置子组件出错时的处理函数
    ```JavaScript
    static getDerivedStateFromError(error) {
      console.log(error);
      return { hasError: error }
    }
    {this.state.hasErr ? <h3>当前网络错误，稍后再试</h3> : <Child/>}
    ```
  * 可以在`componentDidCatch`中统计错误次数

## React富文本渲染+轮播图案例**
* `dangerouslySetHTM`: 允许我们动态设置`innerHTML`
  ```JavaScript
  state = {MYTHML:`<...>...</...>`}
  render(){return(<div dangerouslySetInnerHTML={{__html:this.state.MYTHML}}></div>);}
  ```
* 模糊搜索：在`componentDidMount`生命周期直接发送AJAX请求并携带请求验证信息
  ```JavaScript
  componentDidMount() {
    axios({url:'URL',method:'GET',headers:{'X-Client-Info':'{...}','X-Host': 'mall.film-ticket.cinema.list'
  }}).then((response)=>{this.setState({STATE:response.data.data....})},(reason) => {console.log(reason.message)})}
  ```
* React+自定义Swiper组件+插槽：自定义组件Swiper
  1. ` import Swiper, { Navigation, Pagination } from "swiper";`: 暴露出相应组件
  2. `<div className="swiper"><div className='swiper-wrapper'>{this.props.children}//预留插槽</div><div className="swiper-pagination"></div></div>`: `render`中预留`children`插槽
  3.  `export default Kswiper;`: 将此模版一般组件暴露出去
  4.  `<div className="swiper-slide">{this.props.children}</div>`: 为渲染细项定义SwiperItem自定义组件
  5.  `export default KSwiperItem;`: 将此一般组件暴露出去
  6.  `import KSwiper from "./.../KSwiper"; import KSwiperItem from "./.../KSwiperItem";`: 需要使用Swiper组件时，可以引入自定义Swiper组件（高复用，自定义程度高）

## ReactReact Hooks补充**
* useCallback(记忆函数)
  * `const XXX = useCallback((event) => {settext(event.target.value)},[...])`
  * 防止因为组件重新渲染，导致方法被重新创建，起到缓存作用；只有第二个参数变化了，才重新声明一次
* useMemo(记忆组件)
  * `const XXX1 = useMemo(() => XXX2.XXX3(item => {return ...}),[...])`
  * `useCallback`的功能完全可以由`useMemo`所取代；唯一的区别是，`useCallback`不会执行第一个参数函数，而是将它返回给你，而`useMemo`会执行第一个函数并且将函数执行结果返回；所以`useCallback`常用记忆事件函数，生成记忆后的事件函数并传递给子组件使用。而`useMemo`更适合经过函数计算得到一个确定的值，比如记忆组件
* useRef(保存引用值)
  * 相当于`React.createRef()`使用,作用为创建一个容器，可以保存某一节点数据；也可用于保存引用值
* useContext(减少组件层级)
  * 当想要给子组件的子组件传递数据时(生产者消费者模式)，可以通过Context；同样也可以在函数式组件中使用`useContext`
* useReducer(React引入经典思想)
  ```JavaScript
  const reducer = (prevstate,actions) => {
    const newstate = {...prevstate}
    switch (actions.type) {
      case "add":
        newstate.count++
        return newstate
      case "minus":
        newstate.count--
        return newstate
      default :
        return prevstate
      }
  }
  ```
  * reducer比setState更加擅长描述“如何更新状态”。比如，reducer能够读取相关的状态、同时更新多个状态
  * useReducer总是返回相同的dispatch函数：状态更新逻辑可以任意变化，而发起actions的渠道始终不变
  * useReducer+useContext
* 自定义hooks
  * 想在两个函数之间共享逻辑时，我们会把它提取到第三个函数中

## [React中的样式策略](https://zhuanlan.zhihu.com/p/445762944?utm_id=0&wd=&eqid=a4fa8e4500075e1f000000046466fcc4)
* **内联样式:** 在JSX元素中，直接定义行内的样式
* **CSS样式表:** 这也是我们最常用的样式策略，使用单独的样式表，使用CSS或者SCSS等来为元素设置样式
* **CSS模块:** 一个文件，默认情况下所有类名和动画名都在本地范围
* **styled-components:** 用于React和React Native的样式组件库，它允许我们早应用中使用组件级样式，这些样式就是使用CSS-in-JS的技术来编写的
* **JSS:** CSS创作工具，它允许我们使用JavaScript以声明式、无冲突和可重复的方式来描述样式

## key
* key帮助React识别哪些元素改变了，因此应当给数组中的每一个元素赋予一个确定的标识，使得之前的低效转换变得高效
* 设置key
  > `<li key = {xxx.id}>`: 通常使用数据中的id作为元素的key \
  > `<li key = {index}>`: 当元素没有确定id时，可以使用元素索引index作为key
* key不是全局唯一的，但兄弟节点不能用相同的key
* key会传递信息给React，但不会传递给组件；如果组件中需要使用key属性的值，则必须用其他属性名显式传递这个值，例如id
* 在`map()`方法中的元素需要设置key属性，如`data.map((item, index) => {return <li key = {index}>{item}</li>})`

## 组件实例三大属性
* `this.props`表示那些一旦定义，就不再改变的特性，而`this.state`是会随着用户互动而产生变化的特性
* 用React开发class组件时，constructor中一定要调用`super(props)`：在JavaScript子类的构造函数中super指的是父类(即超类)的构造函数。子类中显式定义了constructor的方法中必须在其最顶层调用super，否则新建实例时会报错。这是因为子类自己的this对象，必须先通过父类的构造函数完成塑造，得到与父类同样的实例属性和方法，然后再对其进行加工，加上子类自己的实例属性和方法。如果不调用super方法，子类就得不到this对象。所以必须先调用super才可以使用this。如果子类没有定义constructor方法，这个方法会被默认添加

## ES6:
* ECMAScript 6，于2015年6月正式发布的JavaScript语言的标准

## Extends
* Class之间可以通过extends关键字实现继承
* super关键字表示父类的构造函数，用来新建父类的this对象。子类必须在constructor方法中调用super方法，否则新建实例时会报错。这是因为子类没有自己的this对象，而是继承父类的this对象，然后对其进行加工。如果不调用super方法，子类就得不到this对象

## `bind()`
* 在JSX中传递的事件不是一个字符串，而是一个函数(如：`onClick = {this.handleClick}`)，此时onClick即是中间变量，所以处理函数中的this指向会丢失
* 解决这个问题就是给调用函数时`bind(this)`，从而使得无论事件处理函数如何传递，this指向都是当前实例化对象。或者使用箭头函数声明一个函数，这样函数内的this也是指向当前实例

## `=>`
* 语法：`(param1, param2, …, paramN) => {statements}`
* 箭头函数是匿名函数，无法使用函数名进行递归调用
* 箭头函数没有自己的this和arguments，它们继承自父作用域
* 箭头函数不能使用new关键字调用，因为它没有自己的this对象
* 箭头函数不能使用yield关键字，因为它不是生成器函数

## `...`
* ES6的扩展运算符，用于取出参数对象的所有可遍历属性，然后拷贝到当前对象之中。

## `event.preventDefault()`
* 取消事件的默认动作；如果event对象的cancelable属性是false，那么就没有默认动作或不能阻止默认动作，无论哪种情况，调用该方法都没有作用

## onchange事件
* 只在表单元素的焦点离开时触发
* 对于单选框和复选框来说，只有当用户点击了一个不同的选项时，才会触发onchange事件
* 对于select元素，只有当用户点击下拉列表并选择一个选项时，才会触发onchange事件。如果用户点击下拉列表但并没有选择任何选项，onchange事件不会触发

## `event.target.value`
* 是事件监听器调用时的事件对象中的属性之一，该属性保存用户输入表单时的实际值，也可以作为选择框中用户选择的值。当表单元素产生值改变事件时，该值将会被更新。在某些情况下，比如文本框里的文本被改变或下拉列表选择的选项被更改时，都会触发这个事件
* input元素是最常见的表单元素，根据不同的type属性可以显示文本框、单选框、多选框等等。在文本框中，`event.target.value`属性保存的是输入的实际值。

## input标签的type属性
    > text: 输入文本 \
    > password: 输入密码，输入的内容会被隐藏 \
    > checkbox: 创建复选框 \
    > radio: 创建单选按钮 \
    > submit: 提交表单 \
    > reset: 重置表单 \
    > button: 创建普通按钮 \
    > file: 选择上传文件 \
    > date: 选择日期 \
    > time: 选择时间 \
    > range: 选择范围内的数值 \
    > color: 选择颜色 \
    > 此外，还有一些较少使用的类型，如email、tel、url等，用于限制用户输入的内容格式。

## hooks
* hooks不能使用在if语句和for语句中，来保持hooks按顺序执行
* [未读](https://www.jianshu.com/p/76901410645a/)
* [未读](https://zhuanlan.zhihu.com/p/597987053)

## SPA: single page web application, 单页Web应用
* 是一种网页应用或网站的设计模式，它在浏览器中仅加载一个HTML页面，并动态地更新该页面，而不是为每个新页面加载新的HTML。这使得应用能够与用户交互，无需重新加载整个页面
* 主要特点
  * 动态重写：SPA 在用户与应用交互时动态地重写当前页面，而不是加载新页面
  * 速度：由于大部分资源（如 HTML、CSS、JavaScript）只加载一次，因此 SPA 通常比传统的多页应用有更快的响应
  * 浏览器历史记录：虽然 SPA 只有一个页面，但它们可以使用浏览器的历史API来创建可导航的  * URL，使用户可以使用浏览器的前进和后退按钮
  * 与后端交互：SPA 通常会与后端的 Web API 进行数据交互，获取所需的数据并更新视图
  * 前端路由：SPA 使用前端路由来管理应用中的不同视图，而不是依赖服务器端的路由

## 安装React包的诸多问题参考
* 下载开始后没有变化，显示为`idealTree:npm: sill idealTree buildDeps`
* [参考链接](https://blog.csdn.net/weixin_38203411/article/details/128812182)
* Windows下CMD可以记得以管理员身份启动，但我这里不是这个问题；通过将node的仓库地址改成淘宝镜像的仓库地址后成功下载

## 加壳
* 全称是可执行程序资源压缩，压缩后的程序可以直接运行
* 另一种常用的方式是在二进制的程序中植入一段代码，在运行的时候优先取得程序的控制权，之后再把控制权交还给原始代码，这样做的目的是隐藏程序真正的OEP（入口点，防止被破解）。大多数病毒就是基于此原理
* 加壳的程序需要阻止外部程序或软件对加壳程序本身的反汇编分析或者动态分析，以达到保护壳内原始程序以及软件不被外部程序破坏，保证原始程序正常运行。这种技术也常用来保护软件版权，防止软件被破解。但对于病毒，加壳可以绕过一些杀毒软件的扫描，从而实现它作为病毒的一些入侵或破坏的一些特性
* 应用加壳时的配置文件：`<link rel="manifest" href="%PUBLIC_URL%/manifest.json" />`

## 严格模式(strict mode)
* 目的
  * 消除 JavaScript 语法的一些不合理、不严谨之处，减少一些怪异行为;
  * 消除代码运行的一些不安全之处，保证代码运行的安全；
  * 提高编译器效率，增加运行速度；
  * 为未来新版本的 JavaScript 做好铺垫
* 开启：'use strict'
  ```JavaScript
  root.render(
    <React.StrictMode>
      <App />
    </React.StrictMode>
  );
  ```

## VS Code插件
* JS JSX Snippets: React快捷输入，例如输入rcc，快速创建类组件
* Auto Import - ES6, TS, JSX, TSX: 自动导入
* Simple React Snippets: 提供了一组精心挑选的React代码片段，可以通过输入几个字母轻松地将其添加到代码中，如输入`imr`会将React导入到组件中
* ES7+ React/Redux/React-Native snippets: 提供了许多速记前缀来加速开发并帮助开发人员为React、Redux和React Native创建代码片段和语法

## Chrome插件
* React Developer Tools: 开发者工具审查React组件的浏览器扩展

## React解构(`const { xxx, xxx } = this.props`)
* JavaScript的一个特性，它用于从数组或对象中取出部分数据，我们可以将它们分配给开发人员创建的新变量
* 在解构中，它不会改变数组或任何对象，它通过将所需的对象或数组元素分配给自己的新变量来复制所需的对象或数组元素，稍后我们可以在React(类或函数)中使用这个新变量组件
* 它使代码更清晰。当我们使用`this`关键字访问`props`时，我们必须在整个程序中使用`this/this.props`，但是通过使用重组，我们可以丢弃`this/this.props` 通过将它们分配到新变量中
* 这很难在复杂的应用程序中监控`props`，因此通过将这些`props`分配到新的自己的变量中，我们可以使代码更具可读性
* 使用提取方法：Destructuring中提取的值很多时候都不存在了，那么在这种情况下我们可以使用 Destructuring 的默认行为，在这种情况下，对Destructuring新声明的属性应用一个默认值，未定义则将其设置为true
* 使用Re-assigning方法：可以使用不是被解构属性的副本的变量名。这是通过重新分配来实现的

## `className="btn btn-danger"`:
* 弹出框和警告框插件

## 空标签`<></>`
* 用在React中，相当于标签的语法糖，表示一个DOM片段，可以在内存里创建一个DOM节点，但是并不在DOM模版上渲染，进而提升性能

## 语法糖(Syntactic sugar)
* 指计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。通常来说使用语法糖能够增加程序的可读性，从而减少程序代码出错的机会

## CSS样式模块化
    > `index.module.css`: 给CSS文件添加module关键字 \
    > `import xxx from './index.module.css'`: 引入 \
    > `className`={xxx.title}
* 通过导入样式文件并将其绑定到组件上，实现样式与组件的一对一关系。这样，每个组件的样式规则都只对当前组件生效，不会影响其他组件
* Css Module只能作用于类选择器和ID选择器
* `compose: xxx;`: 一个选择器可以组合其他选择器

## 引入CSS
* 引入CSS的方法有2种，import与link
  * `@import url('地址')`: 这种方式可以放在页面也可以放在css文件中；@import只能加载CSS；需要页面网页完全载入以后加载CSS；低版本浏览器不支持；不支持使用JS控制DOM改变样式
  * `<link href="地址" rel="stylesheet" type="text/css" />`: link是XHTML标签，除了加载CSS外，还可以定义RSS等其他事务；页面载入时同时加载CSS；无兼容问题；支持使用JS控制DOM改变样式

## 连续解构赋值+重命名
如果在jsx中写着`<input ref={c => this.keyWordElement = c} type="text" />`， 那么在获取输入值的时候，如果使用连续解构赋值+重命名的形式，就要这样获取:`const {keyWordElement:{value:keyWord}} = this`这时候获取到的`keyWord`就是用户输入的值

## `createProxyMiddleware`
    ```JavaScript
    // Search/index.jsx
    axios.get(`http://localhost:3000/api1/search/users?q=${keyWord}`).then(
      response => {this.props.updateAppState({ isLoading: false, users: response.data.items })},
      error => {this.props.updateAppState({ isLoading: false, err: error.message })}
    )
    ```

    ```JavaScript
    // setupProxy.js
    module.exports = function(app) {
      app.use("/api",createProxyMiddleware({
        target:'http://localhost:5001',
        changeOrigin:true,
        pathRewrite:{"^/api":""}
      }))
    }
    ```

    ```JavaScript
    // server.js
    app.get("/search/users", function (req, res) {
      const {q} = req.query
      axios({
        url: 'https://api.github.com/search/users',
        params: {q}
      }).then(response => {
        res.json(response.data)
      })
    })
    ```
* `get`传参：仅仅支持params
* `post`传参: 支持data和params
* data是放在body里的，在url中看不见参数，但使用params的话，说明参数在url里面是能够看见的
* `params: params`等价于`params`; `data: data`等价于`data`
* 通过创建一个代理中间件类，并将createProxyMiddleware应用于该类，从而实现对网络请求的代理处理

## `localhost`
* 给回路网络接口(loopback)的一个标准主机名，相对应的IP地址为127.0.0.1(IPv4)和[::1](IPv6)

## 端口
* 虚拟端口：虚拟端口指计算机内部或交换机路由器内的端口，不可见
* 物理端口：又称为接口，是可见端口，计算机背板的RJ45网口，交换机路由器集线器等RJ45端口等
* 一个IP地址的端口有65536(即：2^16)个之多，端口是通过端口号来标记的，端口号只有整数，范围是从0到65535
* 在Internet上，各主机间通过TCP/IP协议发送和接收数据包，各个数据包根据其目的主机的ip地址来进行互联网络中的路由选择,把数据包顺利的传送到目的主机。大多数操作系统都支持多程序(进程)同时运行；本地操作系统会给那些有需求的进程分配协议端口(protocol port，即常说的端口)，当目的主机接收到数据包后，将根据报文首部的目的端口号，把数据发送到相应端口
* 不光接受数据包的进程需要开启它自己的端口，发送数据包的进程也需要开启端口，这样，数据包中将会标识有源端口，以便接受方能顺利地回传数据包到这个端口

## CSS `float`
* 会使元素向左或向右移动，其周围的元素也会重新排列
* 元素的水平方向浮动，意味着元素只能左右移动而不能上下移动
* 浮动元素之前的元素将不会受到影响

## React插槽
* 用于组件的分发；为了复用，如轮播图
* 具名插槽
  * 使用具体名字的`props`传递一个react元素，实现组件分发
* `props.children`
  * 可任意分发组件内容
  * `props.children`的值有四种可能情况
    > `undefined`: 无内容 \
    > `object`: 当只有一个组件时，即组件实例 \
    > `array`: 当有多个组件时，返回数组，即存放每个组件实例的数组 \
    > `string`: 当传入不是react元素为字符串
  * 处理方法
    > `React.Children.map(childrenArr, fn)`: 为多组件数组每个组件实例执行一次fn函数，可返回
    > `React.Children.forEach(childrenArr, fn)`: 为多组件数组每个组件实例执行一次fn函数，无返回
    > `React.Children.count(childrenArr, fn)`: 返回组件实例个数
    > `React.Children.only(childrenArr)`: 返回唯一的子组件、
  * [示例代码链接](https://blog.csdn.net/m0_55173487/article/details/128497369)

## 127.0.0.1 (127.x.x.x)
* 回送地址(Loopback Address)，指本地机，一般用来测试使用，即主机IP堆栈内部的IP地址，主要用于网络软件测试以及本地机进程间通信，无论什么程序，一旦使用回送地址发送数据，协议软件立即返回，不进行任何网络传输

## CSS `cursor: pointer`: 鼠标由箭头形状改为手的形状

## CSS 列表
* `ul`: 表示无序列表的整体，用于包裹`li`标签
* `ol`: 表示有序列表的整体，用于包裹`li`标签
* `li`: 表示无序列表的每一项，用于包含每一行的内容
* `ul`, `ol`标签中只允许包含`li`标签，`li`标签可以包含任意内容
* 去掉无序列表前的圆点：`list-style-type:none;`

## 深拷贝
* JS中，数组和对象的复制如果使用`=`，则只是浅拷贝，如`let arr2 = arr`，`arr`的修改会影响`arr2`的值
* 一层深拷贝
  * 拓展运算符: `let arr2 = [...arr1]`
  * 封装函数，遍历数组元素，返回新数组
  * 截取：`slice(start, end)`
  * 拼接：`concat()`
*多层深拷贝
  * 手写递归
  * `JSON.stringify()`及`JSON.parse()`
  * lodash

## `let`
* 存在块级作用域，使用`let`声明变量就会和当前的花括号绑定，只在当前花括号内有效，花括号外不能使用此变量，因此很适合用在for循环中
* [参考链接](https://blog.csdn.net/zhangawei123/article/details/127738330)

## [Flux](https://github.com/voronianski/flux-comparison)
* Facebook Flux是用来构建客户端Web应用的应用架构。它利用单向数据流的方式来组合React中的视图组件
* Redux最主要是用作应用状态的管理。简言之，Redux用一个单独的常量状态树(state对象)保存这一整个应用的状态，这个对象不能直接被改变。当一些数据变化了，一个新的对象就会被创建(使用actions和reducers)，这样就可以进行数据追踪，实现时光旅行

## Redux持久化存储
* store状态树的state并不是持久保存的，在浏览器端刷新之后数据会消失，需要重新获取。这个时候就需要Redux store数据的持久化
* [redux-persist插件](https://github.com/rt2zz/redux-persist): 把Redux的store中的数据缓存到浏览器的localStorage中
  1. 在store页面中引用redux-persist
      ```JavaScript
      // configureStore.js
      import { createStore } from 'redux'
      import { persistStore, persistReducer } from 'redux-persist'
      import storage from 'redux-persist/lib/storage' // defaults to localStorage for web
      import rootReducer from './reducers'
      ```
  2. 改造store
      ```JavaScript
      const persistConfig = {
        key: 'root',
        storage,
      }

      const persistedReducer = persistReducer(persistConfig, rootReducer)

      export default () => {
        let store = createStore(persistedReducer)
        let persistor = persistStore(store)
        return { store, persistor }
      }
      ```

  3. 改造`index.js`入口文件
      ```JavaScript
      import { PersistGate } from 'redux-persist/integration/react'
      
      // ... normal setup, create store and persistor, import components etc.
      
      const App = () => {
        return (
          <Provider store={store}>
            <PersistGate loading={<Loading />} persistor={persistor}>
              <RootComponent />
            </PersistGate>
          </Provider>
        );
      };
      ```

## Immutable
* 深拷贝与浅拷贝
  * `Object.assign()`: 只是一级属性复制，比浅拷贝多拷贝了一层而已
  * `const obj1 = JSON.parse(JSON.stringify(obj))`: 数组或对象都好用的方法，但不能有undefined
* 一旦创建，就不能更改的数据，对immutable对象的任何修改或删除添加都会返回一个新的immutable对象
  * 原理是Persistent Data Structure(持久化数据结构)，也就是使用旧数据创建新数据时，要保证旧数据同时可用且不变
  * 使用了Structural Sharing(结构共享)，避免deepCopy把所有节点都复制一遍带来的性能损耗
  * 如果对象树中一个节点发生变化，只修改这个节点和受它影响的父节点
* Immutable中常用类型(`Map`, `List`)
  * `Map`:
    ```JavaScript
    import { Map } from 'immutable'
    const obj2 = Map(obj1)
    ```
  * `List`
    ```JavaScript
    import {List} from "immutable"
    const arr1 = List([1,2,3])
    const arr2 = arr1.xxx(x)
    ```
* `fromJS`: 自动分析数据并转化为`immutable`对象，而无需再分层`Map`: `state = {info:XXX({...})}`

## [MobX](https://cn.mobx.js.org/)
* 任何源自应用状态的东西都应该自动地获得。利用`getter`和`setter`来收集组件的数据依赖关系，从而在数据发生变化的时候精确知道哪些组件需要重绘，在界面的规模变大的时候，往往会有很多细粒度更新
  * Actions: 事件调用Actions，是唯一可以修改State的东西，并且可能有其它副作用，`@action onClick = () => {this.props.todo.done = true;}`
  * State: 可观察和最低限度定义的，不应包含冗余或推导数据，`@observable todos = [{title: "learn MobX", done: false}]`
  * Computed values: 可以使用pure function从State中推导出的值，会自动更新它并在其不再使用时优化掉，`@computed get completedTodos() {return this.todos.filter(todo => todo.done)}`
  * Reactions: 会对State的变化做出反应，但不产生值，而是产生副作用，像是更新UI，`const Todos = observer({todos} => <ul>todos.map(todo => <TodoView ... />)</ul>)`
* MobX与redux的区别:
  * MobX写法上更偏向于OOP
  * 对一份数据直接进行修改操作，不需要始终返回一个新的数据
  * 并非单一store，可以多store
  * Redux默认以JavaScript原生对象形式存储数据，而MobX使用可观察对象
* `observable`和`autorun`
  * `import { observable , autorun } from 'mobx'`
  * `observable`
    * 只有在它可以被制作成可观察的数据结构时才会成功。其他值，不会执行转换
    * 值可以是JS基本数据类型、引用类型、普通对象、类实例、数组和映射
    * `observable.box`创建一个`observable`的盒子，它用来存储value的`observable`引用。使用`get()`方法可以得到盒子中的当前value，而使用`set()`方法可以更新value
  * `autorun`
    * 所提供的函数总是立即被触发一次，然后每次它的依赖关系改变时会再次被触发
* `action`, `runInAction`与严格模式
  * `import {observable, configure, action,runInAction} from 'mobx'`
  * `configure(options)`: 对活动的MobX实例进行全局行为设置，`configure({enforceActions:'always'})`，如果是never，可以不写action
  * `action`: 任何应用都有动作。动作是任何用来修改状态的东西，使用MobX可以在代码中显式地标记出动作所在的位置
  * `unInAction`工具函数
    * 非严格模式下，store数据操作可以不用runInAction包裹
    * 严格模式下，异步数据操作需要用runInAction包裹：`setTimeout(() => runInAction(() => ...), 1000)`
* mobx-react
  * React组件里使用`@observer`：`observer`函数/装饰器可以用来将React组件转变成响应式组件
  * 可观察的局部组件状态：`@observable`装饰器在React组件上引入可观察属性。而不需要通过React的冗长和强制性的`setState`机制来管理
  1. 创建`.babelrc`
  2. 创建`config-overrides.js`
  3. 修改`package.json`
  4. `import {observable, configure, action,runInAction} from 'mobx' // store.jsx`
  5. `import {inject,observer} from "mobx-react"; // App.jsx`
  * `inject`(mobx-react包): 相当于Provider 的高阶组件。可以用来从 React 的context中挑选 store 作为 prop 传递给目标组件
  * `observer`: 可以用作包裹React组件的高阶组件。在组件的`render`函数中的任何已使用的`observable`发生变化时，组件都会自动重新渲染

## TS基本语法
* 声明文件：`npm i --save @types/{依赖包名称} //编译器需要通过这个声明文件，进行类型检查工作`

## JS `{}`
* 命名导出：允许导出多个具有特定名称的值。导入时需要使用花括号，并确保名称与导出时相匹配。例如，`import { createApp } from 'vue';`来导入特定的`createApp`函数
* 默认导出：只允许导出一个值，导入时可以自由命名，不需要花括号`{}`

## JS模块规范
* JS模块化编程分了两种规范：CommonJS模块规范和ES6模块规范。
  * **CommonJS模块规范:** 每个js文件就是一个模块，有自己的作用域。在一个文件里面定义的变量、函数、类，都是私有的，对其他文件不可见。如果要暴露给其他程序，需要以`module.exports`导出接口，以`require`引入模块
  * **ES6模块规范:** 以export指令导出接口，以import引入模块。在Node.js编程中，Node模块系统遵循的是CommonJS规范
  * 导出关键字
    > `module.exports`: 导入用require,返回模块对象本身，返回的是一个类；需要new对象之后才可以调用；可以导出所有的类型。对象，函数，字符串、数值等；`moudle.exports= [function name]`；只有node支持的导出 \
    > `exports`: 导入用require,返回的是模块函数；方法可以直接调用；`exports.[function name] = [function name]`；只有node支持的导出 \
    > `export`: 导入用import，接受一对大括号，里面指定要从其他模块导入的变量名。大括号里面的变量名，必须与被导入模块对外接口的名称相同；如果想为输入的变量重新取一个名字，import命令要使用as关键字，将输入的变量重命名；只有es6支持的导出 \
    > `export default`: 导入用import，其他模块加载该模块时，import命令可以为该匿名函数指定任意名字；其实只是输出一个叫做default的变量，所以它后面不能跟变量声明语句，是别名的语法糖
  * 导入关键字
    > `require`: 导入exports和module.exports导出的模块；node和es6都支持的引入 \
    > `import`: 导入export、export default导出的模块；只有es6支持的引入
  * 注意：详见[链接](https://codeleading.com/article/82156125909/)
  * 总结：CommonJS规范中，建议尽量都用 module.exports 导出，然后用require导入；ES6规则中，大部分风格建议，模块中最好在末尾用一个export导出所有的接口，参考[链接](https://blog.csdn.net/LlanyW/article/details/130216645)

## `Object.assign()`
  * 用于将所有可枚举属性的值从一个或多个源对象复制到目标对象，它将返回目标对象
  * 当对象中只有一级属性，没有二级属性的时候，此方法为深拷贝；但是对象中有对象的时候，此方法在二级属性以后就是浅拷贝
  * 如果目标对象中的属性和原对象有相同的键，则属性被源对象中的属性覆盖
  * 只会拷贝源对象自身的并且可枚举的属性到目标对象
  * 针对深拷贝，因为`Object.assign()`拷贝的是属性值，假如源对象的属性值是一个对象的引用，那么它也只指向那个引用

## `var`, `let`和`const`
  * `var`定义的变量，没有块作用域的概念，可以跨块访问；可以在全局范围声明或函数/局部范围内声明，当在函数中声明var时，作用域是局部的；变量可以重新声明和修改；变量提升，var声明的变量会被提升到其作用域的顶部，并使用`undefined`值对其进行初始化
  * `let`声明的变量可以改变，值和类型都可以改变，没有限制；块级作用域，在作用域内有效
  * `const`声明的变量不能改变值，const一单声明变量，就必须初始化，不能留到以后赋值；块级作用域，在作用域内有效；对于复合类型的变量，如数组和对象，变量名不指向数据，而是指向数据所在的地址。`const`命令只是保证变量名指向的地址不变，并不保证该地址的数据不变，所以将一个对象声明为常量必须非常小心

## JS `...`
  * 扩展运算符(spread): 把数组或类数组对象展开成一系列用逗号隔开的值；在等号右边，或者放在实参上，在赋值一方式
  * 剩余运算符(rest): 把逗号隔开的值序列组合成一个数组；在等号左边，或者放在形参上，在被赋值一方

## JS 变量提升
  * JavaScript引擎的工作方式是，先解析代码，获取所有被声明的变量，然后再一行一行的运行，这造成的结果，就是所有的变量的声明语句，都会被提升到代码的头部

## `JSON.parse()`:
* 将JSON字符串转为javascript对象

## immutable.js `toJS()`
* 用于将不可变的Map或List对象转换成JavaScript普通对象或数组。这对于数据从immutable.js向其他API迁移非常有用。我们只需使用toJS方法将不可变数据转换为普通JavaScript对象后，即可将其传递给其他API，以与现有的代码或其他JavaScript库无缝集成，而不需要担心类型出错或不一致的问题
* 递归地将一个(observable)对象转换为javascript结构。 支持observable数组、对象、映射和原始类型。 计算值和其他不可枚举的属性不会成为结果的一部分。 默认情况下可以正确支持检测到的循环，但也可以禁用它来获得性能上的提升
* toJS 接收两个选项
  > `exportMapsAsObjects`: 是否将observable映射序列化为对象(true)或JavaScript Map对象(false)。默认为true \
  > `detectCycles`: 如果检测到循环，则重新使用已经序列化的对象。这可以防止无限递归。默认为true

## JS数组常用方法及[示例]
(https://blog.csdn.net/weixin_64530670/article/details/131560914)
  > `push()`: 在数组最后添加一个或者多个新元素，并且返回新数组的长度 \
  > `pop()`: 删除数组最后一个元素，并返回数组末尾删除元素\
  > `unshift()`: 在数组前面添加一个或多个元素，并返回新元素的长度\
  > `shift()`: 删除数组首部元素，并返回被删除的元素\
  > `splice()`: 对数组进行删除和修改操作，返回被删除元素组成的数组\
  > `slice()`: 剪切(截取)数组，并返回一个包含剪切值的新数组，不会改变原数组，也可以截取字符串；负参数会将负的参数加上字符串的长度\
  > `concat()`: 合并两个或多个数组，返回新数组，不会改变原数组\
  > `join()`: 将数组转化为字符串，不会改变原有数组，此方法会返回转换后的字符串，默认以','分隔，会改变原数组\
  > `revres()`: 颠倒数组元素，会改变原数组\
  > `indexOf()`: 返回数组元素首次在数组中出现的索引，没找到返回-1\
  > `sort()`: 对数组进行排序，a-b从小到大排序，b-a从大到小\
  > `filter()`: 返回数组中满足条件的元素组成新数组，元素只能做布尔类型判断，不会改变原数组组\
  > `map()`: 创建一个新数组，这个新数组由原数组中的每个元素都调用一次提供的函数后的返回值组成，可以做运算，不能过滤原素组元素，不会改变原数组\
  > `every()`: 用于判断数组中的元素是否都满足条件，当每个元素都满足条件时，返回ture，否则false，不会改变原数组\
  > `some()`: 判断数组是否至少有一个满足条件，一旦找到一个就立即停止并返回true，否则false，不会改变原数组；当some的数组为空时返回false，当every的数组为空时返回true；every只要有一个失败就返回失败，some只要有一个成功就返回成功\
  > `forEach()`: 遍历整个数组，中途不能用break中断\
  > `reduce()`: 给数组做四则运算，第二个参数一般设为0，不会改变原数组\
  > `includes()`: 判断数组中是否存在，若存在返回true，不存在即返回false\
  > `findIndex()`: 返回传入一个测试条件(函数)符合条件的数组第一个元素位置。如果没有符合条件的元素返回-1\
  > `form()`: 伪数组转换成真数组\
  > `split('分隔符')`: 把字符串转换为数组，使用和join方法相反\
  > `字符串.substring(开始下标，结束下标)`: 返回被截取的字符串，不包含结束下标对应的字符；不写结束下标，即从开始截取到字符串结尾

## 字符串截取的方法`slice()`, `substring()`, `substr()`
* 相同点：三者皆返回一个新字符串，原字符串不做改变；传入一个正参数时，三者返回的字符串相同，返回的新字符串都是从参数位置到原字符串长度位置的
* 传入两个正参数时，`slice()`和`substring()`返回的字符串相同，第二个参数都表示结束位置，但`substr()`的表示字符串的个数
* `substring()`不接受负参数，若传入负参数,将被转换成0
* `substr()`传入一个负参数时，与slice()相同,转换成参数+字符串长度
* `substr()`传入两个负参数时，与substring()相同，转换成0。但`substring()`会将参数从小到大排序，`substr()`不会
* 截取字符串的后几位之前的字符串`slice()``substring()`括号内的第二个参数为`str.length`(需要几位数就写几)

## `immutable-list`不可变操作
  > `push`: 在列表末尾插入一个元素 \
  > `pop`: 弹出列表末尾的元素 \
  > `shift`: 移除列表的第一个元素 \
  > `unshift`: 在列表的开头插入一个元素 \
  > `update`: 用给定的值更新列表中的某个元素 \
  > `splice`: 移除并/或插入列表中的元素 \
  > `concat`: 将另一个列表附加到当前列表的末尾 \
  > `slice`: 返回一个包含指定元素的新列表 \
  > `filter`: 返回一个包含指定条件的元素的新列表 \
  > `map`: 将每个元素映射到一个新的值并返回一个新列表 \
  > `reduce`: 依次将列表元素应用于 reducer 并返回单个值

## 引用赋值、浅拷贝和深拷贝
* 引用赋值：将一个对象赋值给另一个变量时，实际上是将对象的引用地址赋值给了另一个变量，即两个变量指向同一块内存地址的对象。这意味着，对其中一个变量所指向的对象进行修改，另一个变量也会受到影响
* 浅拷贝：复制对象时，只复制对象中的基本类型属性和对象引用地址，而不复制对象的子对象或数组的引用地址。这样，当对复制后的对象进行修改时，不会影响原始对象，但如果原始对象中包含的子对象或数组的引用地址发生改变，复制后的对象和原始对象都会受到影响
* 深拷贝：复制对象时，完整复制对象中的所有属性和子属性，包括嵌套对象和数组。这样，当对复制后的对象进行修改时，不会影响原始对象和原始对象中的子对象或数组

## Set, Map, Object比较及转化
* set
  * 类似于数组，但成员值是唯一的，没有重复的(可以接受一个数组作为参数，进行初始化)
  * 本身是一个构造函数(要new)，用来生成Set数据结构
  * Set对象允许你储存任何类型的唯一值，无论是原始值或者是对象引用
  * 向Set加入值的时候，不会发生类型转换，所以5和"5"是两个不同的值
* Object
  * 本质上是键值对的集合(Hash结构)
  * 只能用字符串当作键
* map
  * 它类似于对象，也是键值对的集合，但是“键”的范围不限于字符串，各种类型的值(包括对象）都可以当作键
  * 本身是一个构造函数(要new)，接受数组作为参数(原理上`Array.forEach`)
  * 如果对同一个键多次赋值，后面的值将覆盖前面的值，如果读取一个未知的键，则返回undefined
  * Map的键实际上是跟内存地址绑定的，只要内存地址不一样，就视为两个键
  * 继承自Object

## JS 定义
* class：定义类
* interface：定义接口
* extends：类继承类或者接口继承接口
* implements：类实现接口
* throws：方法需要往上抛出异常
* 注意：上面的哪个地方加s哪个地方不加都是有讲究的，比如class和interface都是单个类和接口的定义，所以不加s；而extends可能考虑到接口是多继承，因此加了s，虽然类是单继承，可能为了方便，所以没有做两份；由于类是多实现，所以加了s；由于可以抛出多个异常，异常中间用逗号`,`隔开

## JS Class `implements`和`extends`
* 相同点：两者都可以实现父类，减少代码，而且面向对象特征
* 区别：`implements`实现父类，子类不可以覆盖父类的方法或者变量。即使子类定义与父类相同的变量或者函数，也会被父类取代掉；`extends`可以实现父类，也可以调用父类初始化`this.parent()`。而且会覆盖父类定义的变量或者函数。这样的好处是：架构师定义好接口，让工程师实现就可以了

## TS断言
* `as`: `let 变量 = 值 as 类型`
* `!`: 非空断言

## `typeof`和`keyof`
* `typeof`: 用来获取变量或属性类型，`type 变量 = typeof 常量`
* `keyof`: 获取对象类型的属性名 , 得到新的类型，`type 类型 = keyof 类型/对象常量`

## 泛型
* 泛型函数：`function 函数名<类型参数> (形参:类型参数):类型参数{}`
* 默认情况下，泛型函数的类型变量可以代表多个类型，这导致在泛型函数内部无法访问任何属性
* 泛型约束
  * 指定更加具体的类型
  * 添加约束
* 泛型接口
  * 接口的类型变量，对接口中所有其他成员可见，也就是接口中所有成员都可以使用类型变量
  * 使用泛型接口时，需要显式指定具体的类型
* 泛型工具类型
 > `Partial`: 把已有的类型属性,变成一个新类型的可选属性，`type 新类型 = partial<老类型>` \
 > `Readonly`: 把已有类型全部转换为只读类型，`type 新类型 = Readonly<老类型>` \
 > `Pick`: 从已有类型中选一些属性来构造新的类型，`type 新类型 = partial<老类型,属性|属性2>`

## Git
* `git status`: 查看工作区代码相对于暂存区的差别
* `git add .`: 将当前目录下修改的所有代码从工作区添加到暂存区`.`代表当前目录
* `git commit -m`: ‘注释’ 将缓存区内容添加到本地仓库
* `git pull origin master`: 先将远程仓库master中的信息同步到本地仓库master中
* `git push origin master`: 将本地版本库推送到远程服务器
* `origin`:是远程主机，`master`表示是远程服务器上的master分支和本地分支重名的简写，分支名是可以修改的

## `<script type="text/...">`
* `text/babel`: 将React语句写在script标签中，且babel类型会将其中的jsx语法翻译为js语法；其中，创建虚拟DOM，并将其渲染到前述对应的div中
* `text/javascript`: React-JS语法(也就不再需要引入`<script src="./js/babel.min.js"></script>`)

## `instanceof`:
* 是Java的保留关键字。它的作用是测试它左边的对象是否是它右边的类的实例，返回`boolean`的数据类型

## VSCode插件Live Server:
* HTML代码页右键运行

## `<span>`
* 用于对文档中的行内元素进行组合
* 没有固定的格式表现。当对它应用样式时，它才会产生视觉上的变化。如果不对其应用样式，那么元素中的文本与其他文本不会任何视觉上的差异
* 提供了一种将文本的一部分或者文档的一部分独立出来的方式

## `super(props)`
* 在JavaScript中，`super`指的是父类构造函数(在我们的示例中，它指向`React.Component`实现)
* 在调用父构造函数之前，不能在构造函数中使用`this`
* 即使你没有使用`props`参数调用`super`，你仍然可以在`render`和其他方法中访问`this.props`，在调用构造函数后，React也会在实例上分配`props`

## `bind(this)`
* JavaScript函数中的`this`不是在函数声明的时候定义的，而是在函数调用(即运行)的时候定义的；谁调用这个函数，`this`就指向谁
* `bind`方法会**创建一个新函数**，称为绑定函数。当调用这个绑定函数时，绑定函数会以创建它时传入`bind`方法的第一个参数作为`this`，传入`bind`方法的第二个以及以后的参数加上绑定函数运行时本身的参数按照顺序作为原函数的参数来调用原函数
* 箭头函数不需要绑定，箭头函数的`this`是继承父级的`this`
* 简单暴力的方法：在所有生命周期函数上都用普通函数，即绑定`this`的函数，其他所有函数全部用箭头函数。因为实际上React主动调用的是生命周期函数，然后再在里面调用自定义函数，这些可以自动绑定到`this`

## React构造函数
* 在 React 中，构造函数仅用于以下两种情况：1. 通过给`this.state`赋值对象来初始化内部`State`；2. 为事件处理函数绑定实例
* 如果不初始化`State`或不进行方法绑定，则不需要为React组件实现构造函数
* 在`constructor()`函数中不要调用`setState()`方法。如果你的组件需要使用内部`State`，请直接在构造函数中为`this.state`赋值初始`State`
* 只能在构造函数中直接为`this.state`赋值。如需在其他方法中赋值，你应使用`this.setState()`替代

## 箭头函数：箭头函数中的this指向组件的实例，而不是undefined，因此不需要使用bind()来绑定this

## `console`
https://zhuanlan.zhihu.com/p/631616556

## refs回调形式
* `<input ref={(a)=>{console.log(a)}} type="text" placeholder="点击按钮提示数据"/>`: 参数a就是本dom节点，就是这个input框当作参数传入了ref。因为箭头函数并没有自己的this，它会把外层render函数的this作为自己的this，而reander函数的this指向组件构造的实例，所以本箭头函数就能和实例相关联，此ref所处的dom节点挂载到实例上并且取名为“input1”
* `ref={c => this.input1 = c}`: 结合箭头函数的特性，只有一个参数，那么可以省略参数的小括号，函数体也就一句，也可以省略箭头函数右侧花括号。所以ref这样精简
* 事件函数会发生改变。原来是`const {input2} = this.refs`，而现在是`const {input2} = this`，因为此`ref`所处的dom节点挂载到实例上，所以直接写`this`即可
* 如果`ref`回调函数是以内联函数的方式定义的，在更新过程中它会被执行两次，第一次传入参数null，然后第二次会传入参数DOM元素。这是因为在每次渲染时会创建一个新的函数实例，所以React清空旧的`ref`并且设置新的。通过将`ref`的回调函数定义成`class`的绑定函数的方式可以避免上述问题，但是大多数情况下它是无关紧要的。注意，我们上面所写代码，将ref回调函数写在input标签内，这就是以内联函数的方式定义ref回调函数，符合官网的说明。但是，在更新过程中才会被执行两次，一次null一次传入参数dom元素，第一次执行render渲染dom是初始化，并非更新

## `event`:
* 如果不传递参数默认函数自带event；不传递event的时候也可以传参

## `event.preventDefault()`
* 如果`Event`对象的`cancelable`属性是`fasle`，那么就没有默认动作，或者不能阻止默认动作。无论哪种情况，调用该方法都没有作用
* 此方法并不被ie支持，在ie下需要用`window.event.returnValue = false;`来实现

## ES6的对象解构赋值
* 在一个对象中，当属性(key)与属性值(前面定义的变量)一样的时候，是可以省略的，可以只写一个(key)属性

## `console.log(username, password, this)`
```JavaScript
<input type="text" name="username">
<input type="password" name="password">
Login {props: {…}, context: {…}, refs: {…}, updater: {…}, handleSubmit: ƒ, …}
context: {}
handleSubmit: ƒ ()
password: input
props: {}
refs: {}
state: null
updater: {isMounted: ƒ, enqueueSetState: ƒ, enqueueReplaceState: ƒ, enqueueForceUpdate: ƒ}
username: input
_reactInternalFiber: FiberNode {tag: 1, key: null, stateNode: Login, elementType: ƒ, type: ƒ, …}
_reactInternalInstance: {_processChildContext: ƒ}
isMounted: (…)
replaceState: (…)
[[Prototype]]: Component
```

## `<meta http-equiv="X-UA-Compatible" content="IE=edge">`:
* IE8/9及以后的版本都会以最高版本IE来渲染页面

## `ReactDOM.unmountComponentAtNode(container)`:
* [参考链接](https://blog.csdn.net/qq_41581588/article/details/129178364)

## React `componentWillUnmount()`
* 在组件卸载及销毁之前直接调用
* 方法中不应调用`setState()`，因为该组件将永远不会重新渲染。组件实例卸载后，将永远不会再挂载它

## React定时器
* `setInterval()`: 确保只在组件挂载时启动一次定时器，并使用`clearInterval()`函数在组件卸载时清除定时器
* `setTimeout()`: 确保只在组件挂载时启动一次定时器，并使用`clearTimeout()`函数在组件卸载时清除定时器

## `UNSAFE_componentWillReceiveProps`
* 可以在子组件的render函数执行前获取新的props，从而更新子组件自己的state。
这样的好处是，可以将数据请求放在这里进行执行，需要传的参数则从componentWillReceiveProps(nextProps)中获取。而不必将所有的请求都放在父组件中。于是该请求只会在该组件渲染时才会发出，从而减轻请求负担。
* 实现监听props改变 重新发起请求 修改state值，不需要setState,因为后面有render函数
* 里面第一个参数是改变后的props
* 这个生命周期要注意：数据改变的来源尽量只来自于1方 ，例如当通过props修改子组件的state.age，有通过子组件自身修改state.age会相互覆盖的
* Rename componentWillUpdate to `UNSAFE_componentWill...` to suppress this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. To rename all deprecated lifecycles to their new names, you can run `npx react-codemod rename-unsafe-lifecycles` in your project source folder.

## `static getDerivedStateFromProps(props, state)`
* 这个生命周期函数是为了替代`componentWillReceiveProps`存在的，所以在你需要使用`componentWillReceiveProps`的时候，就可以考虑使用`getDerivedStateFromProps`来进行替代
* 两者的参数是不相同的，而`getDerivedStateFromProps`是一个静态函数，也就是这个函数不能通过`this`访问到`class`的属性，也并不推荐直接访问属性。而是应该通过参数提供的`nextProps`以及`prevState`来进行判断，根据新传入的`props`来映射到`state`
* 如果`props`传入的内容不需要影响到你的`state`，那么就需要返回一个`null`，这个返回值是必须的，所以尽量将其写到函数的末尾
* 作用就是为了让`props`能更新到组件内部`state`中。所以它可能的使用场景有两个
  * 无条件的根据`prop`来更新内部`state`，也就是只要有传入`prop`值， 就更新`state`
  * 只有`prop`值和`state`值不同时才更新`state`值

## `toLocaleTimeString()`: 方法可根据本地时间把`Date`对象的时间部分转换为字符串,并返回结果

## `<input type="checkbox"/>`
* `defaultChecked`: 只在初次渲染时生效，更新时不受控制
* `checked`: 始终受到控制，必须通过绑定`onChange`事件来控制选中情况

## `event`
* `event.target`: 返回触发此事件的元素(事件的目标节点)。重要作用：事件委托(就是将事件绑定到父级/爷爷级对象上，通过事件对象的target属性来控制子级对象的改变，例：点击子级元素时子级发生样式改变): `event.target.style=''`
* `event.currentTarget`: 返回其事件监听器触发该事件的元素，相当于`this`
* `event.type`: 返回当前`Event`对象表示的事件的名称
* `event.timeStamp`: 返回事件生成的日期和时间
* `event.keyCode`: 键盘按键代码(返回值number)和`keydown`/`keyup`(事件会在键盘按下/松开时触发)配合使用

## CSS `display`
* `none`: 此元素将不被显示
* `block`: 此元素将显示为块级元素，此元素前后会带有换行符
* `inline`: 此元素会被显示为内联元素，元素前后没有换行符，将不能再设置宽和高以及上下方向的margin和padding
* `inline-block`: 既具有block元素可以设置width和height属性的特性，又保持了inline元素不换行的特性
* `inherit`: 规定应该从父元素继承 display 属性的值

## `array.reduce(callback, initialValue)`

## [React/Redux/React-Native snippets]
(https://www.cnblogs.com/wanglei1900/p/17556994.html)

## `npm install --save axios`:
* 新建工作区后需要在VSCode中重新配置

## React 18 index.js
```JavaScript
import React from 'react'
import ReactDOM from 'react-dom/client' // import ReactDOM from 'react-dom'
import App from './App'

// ReactDOM.render(<App></App>,document.getElementById('root'))
const container = document.getElementById('root');
const root = ReactDOM.createRoot(container);
root.render(<App />);
```

## 连续解构赋值+重命名: 如果在jsx中写着`<input ref={c => this.keyWordElement = c} type="text" />`， 那么在获取输入值的时候，如果使用连续解构赋值+重命名的形式，就要这样获取: `const {keyWordElement:{value:keyWord}} = this`，这时候获取到的`keyWord`就是用户输入的值

## CSS rem与em
* em是相对单位，使用em进行尺寸度量的元素，都是相对于自身的文字尺寸，各自为政，太过零散，不好进行统一的控制
* rem也是相对单位，所有使用rem进行尺寸度量的元素，都是相对于根元素html标签的文字尺寸，可以很容易的进行统一控制，只要html标签的字体变了，所有元素的rem都会变化

## PubSub `token` for subscriber
```JavaScript
componentDidMount(){
    this.token = PubSub.subscribe('search',(_,stateObj) => {
        this.setState(stateObj)
    })
}
componentWillUnmount(){
    PubSub.unsubscribe(this.token)
}
```

## react-router-dom安装
* `npm install react-router-dom`

## history API
  > `History.createBrowserHistory()`: 得到封装window.history的管理对象 \
  > `History.createHashHistory()`: 得到封装window.location.hash的管理对象 \
  > `history.push()`: 添加一个新的历史记录 \
  > `history.replace()`: 用一个新的历史记录替换当前的记录 \
  > `history.goBack()`: 回退到上一个历史记录 \
  > `history.goForword()`: 前进到下一个历史记录 \
  > `history.listen(function(location){})`: 监视历史记录的变化

## `useParams()`

## redux插件
为了方便我们开发，推荐安装一下`redux`的开发工具：`redux-devtools`(`yarn add redux-devtools -D`)，需要注意的是在 chrome 浏览器中我们也需要安装对应的插件：`redux-devtools`来结合使用

## `const { selectNumber: { value } } = this` = `const {value} = this.selectNumber`

## React `root.unmount()`
[官方文档](https://react.docschina.org/reference/react-dom/client/createRoot#root-unmount)

## TS基本语法
* 脚手架安装: `create-react-app xxx --template typescript`
* 声明文件: `npm i --save @types/{依赖包名称}`，编译器需要通过这个声明文件，进行类型检查工作

## styled-components
* 安装依赖`npm i styled-components`
* 引入`import styled from 'styled-components'`

## React-单元测试
* 浅渲染：将一个组件渲染成虚拟DOM对象，但是只渲染第一层，不渲染所有子组件，所以处理速度非常快。它不需要DOM环境，因为根本没有加载进DOM
* 测试顺序
  * 测试脚本里面应该包括一个或多个describe块，每个describe块应该包括一个或多个it块
  * describe块称为"测试套件"(test suite)，表示一组相关的测试。它是一个函数，第一个参数是测试套件的名称，第二个参数是一个实际执行的函数
  * it块称为"测试用例"(test case)，表示一个单独的测试，是测试的最小单位。它也是一个函数，第一个参数是测试用例的名称，第二个参数是一个实际执行的函数
  * expect断言的写法都是一样的。头部是expect方法，尾部是断言方法，比如equal、a/an、ok、match等。两者之间使用to或to.be连接

## JavaScript生成器函数(Generator function)
* `function *函数名(参数){函数体}`
* 函数体内部使用`yield`表达式，定义不同的内部状态。执行Generator函数生成一个遍历器对象，用该对象调用其`next()`方法来遍历函数内部的状态
* 调用`Generator`函数，返回一个遍历器对象，代表`Generator`函数的内部指针。以后，每次调用遍历器对象的next方法，就会返回一个有着`value`和`done`两个属性的对象
* `value`属性表示当前的内部状态的值，是`yield`表达式后面那个表达式的值；`done`属性是一个布尔值，表示是否遍历结束
* `yield`表达式本身没有返回值，或者说总是返回`undefined`。`next`方法可以带一个参数，该参数就会被当作上一个`yield`表达式的返回值
* 第一次调用`Generator`函数，返回遍历器对象。这时候，函数内部是没有执行的，仅仅返回遍历器对象。当调用`next()`方法时，函数才从头部开始执行，直到遇到`yield`表达式，则交出函数执行权，函数停止执行
* 自动执行器相当于`async``await`源码

## redux-saga
* redux-saga是一个以redux中间件形式存在的一个库，主要是为了更优雅地 管理 Redux 应用程序中的副作用(Side Effects)，执行更高效，测试更简单，在处理故障时更容易
* redux-saga与redux-thunk区别
  * redux-thunk监控传入系统中的每一个action，如果是个函数的话，那么它就会调用那个函数；选择以`middleware`的形式来增强redux store的`dispatch`方法(即：支持了 dispatch(function))，从而在拥有了异步获取数据能力的同时，又可以进一步将数据获取相关的业务逻辑 从View层分离出去
  * redux-saga是以命令/答复的形式与各个saga之间进行通讯，当接收到指令时会执行对应的saga
* `npm install redux-saga`
* `createSagaMiddleware(options)`
  * `sagaMontior`: 用于接收middleware传递的监视事件
  * `emmiter`: 用于从redux向redux-saga进给actions
  * `logger`: 自定义日志方法(默认情况下，middleware会把所有的错误和警告记录到控制台中)
  * `onError`: 当提供该方法时，middleware将带着Sagas中未被捕获的错误调用它
* Effect创建器
  > `Take`: 创建一个`Effect`描述信息，用来命令`middleware`在`Store`上等待指定的`action`。 在发起与`pattern`匹配的`action`之前，`Generator`将暂停 \
  > `Put`: 创建一个`Effect`描述信息，用来命令`middleware`向`Store`发起一个`action`。 这个`Effect`是非阻塞型的，并且所有向下游抛出的错误(例如在`reducer`中)，都不会冒泡回到`saga`当中 \
  > `Call`: 创建一个`Effect`描述信息，用来命令`middleware`以参数 args 调用函数`fn` \
  > `Apply`: 类似Call \
  > `Fork`: 创建一个`Effect`描述信息，用来命令`middleware`以非阻塞调用的形式执行`fn` \
  > `Spawn`: 与fork类似，但创建的是被分离的任务。被分离的任务与其父级任务保持独立 \
  > `Join`: 创建一个`Effect`描述信息，用来命令`middleware`等待之前的一个分叉任务的结果 \
  > `Cancel`: 创建一个 Effect，用以取消任务 \
  > `Select`: 创建一个 Effect，用来命令`middleware`在当前`Store`的`state`上调用指定的选择器(即返回`selector(getState(), ...args)`的结果) \
  > `ActionChannel`: 创建一个 Effect，用来命令`middleware`通过一个事件`channel`对匹配`pattern`的`action`进行排序 \
  > `Flush`: 创建一个 Effect，用来命令`middleware`从`channel`中冲除所有被缓存的数据。被冲除的数据会返回至`saga`，这样便可以在需要的时候再次被利用 \
  > `Cancelled`: 创建一个 Effect，用来命令`middleware`返回该`generator`是否已经被取消 \
  > `setContext`: 创建一个 effect，用来命令`middleware`更新其自身的上下文 \
  > `getContext`: 创建一个 effect，用来命令`middleware`返回`saga`的上下文中的一个特定属性
* Effect组合器
  > `Race`: 创建一个`Effect`描述信息，用来命令`middleware`在多个`Effect`间运行 竞赛(Race)(与`Promise.race([...])`的行为类似) \
  > `All`: 创建一个`Effect`描述信息，用来命令`middleware`并行地运行多个`Effect`，并等待它们全部完成。这是标准的`Promise`
* Saga辅助函数
  > `TakeEvery`: 在发起(dispatch)到`Store`并且匹配`pattern`的每一个`action`上派生一个`saga` \
  > `TakeLatest`: 在发起到`Store`并且匹配`pattern`的每一个`action`上派生一个`saga`。并自动取消之前所有已经启动但仍在执行中的`saga`任务 \
  > `TakeLeading`: 在发起到`Store`并且匹配`pattern`的每一个`action`上派生一个`saga`。 它将在派生一次任务之后阻塞，直到派生的`saga`完成，然后又再次开始监听指定的`pattern` \
  > `Throttle`: 在发起到`Store`并且匹配`pattern`的一个`action`上派生一个`saga`。 它在派生一次任务之后，仍然将新传入的`action`接收到底层的`buffer`中，至多保留(最近的)一个。但与此同时，它在ms毫秒内将暂停派生新的任务，也就是它被命名为节流阀`throttle`的原因。其用途，是在处理任务时，无视给定的时长内新传入的`action`

## React Portal(传送门)
* 子组件样式会受父组件限制，但子组件并不想受父组件限制时
* 在父元素设置`zIndex`后无论子元素`zIndex`值有多大，子元素都会受父元素的影响
* `import { createPortal } from 'react-dom'`, `createPortal(children, domNode, key?)`
  * `children`：React可以渲染的任何内容，如JSX片段（`<div />`或`<SomeComponent />`等等）、Fragment（`<>...</>`）、字符串或数字，以及这些内容构成的数组
  * `domNode`：某个已经存在的DOM节点，例如由`document.getElementById()`返回的节点。在更新过程中传递不同的DOM节点将导致portal内容被重建
  * 可选参数`key`：用作portal key的独特字符串或数字
  * 返回值：`createPortal`返回一个可以包含在JSX中或从React组件中返回的React节点。如果React在渲染输出中遇见它，它将把提供的children放入提供的`domNode`中
* Portal事件冒泡：Portal渲染的元素在父组件的盒子之外，但是渲染的dom节点仍在React的元素树上，事件是会冒泡从传送门的入口端冒出来的，所以在那个dom元素上的点击事件仍然能在dom树中监听到

## React forwardRef(React引用传递)
* 通过组件向子组件自动传递引用ref
* `import { forwardRef } from 'react'`
* 特定使用场景
  * 处理焦点、文本选择或者媒体的控制
  * 触发必要的动画
  * 集成第三方DOM库

## Functional Component缓存
* 性能优化方向
  * 数据：利用缓存，减少rerender的次数
  * 计算：精确判断更新时机和范围，减少计算量
  * 渲染：精细粒度，降低组件复杂度
* 数据缓存优化：`useCallback`, `useMemo`, `React.memo`
* `React.memo`可以仅仅让某些组件进行渲染，可以通过第二个参数自定义比较的逻辑，以高阶函数的形式对组件进行改造，更加灵活，且可用于functional组件；而`PureComponent`只能用于class组件
* `React.memo(Component, areEqual)`: 高阶组件，接受一个组件作为参数返回一个新的组件。新的组件仅检查props变更，会将当前的props和上一次的`props`进行浅层比较，相同则阻止渲染；第二个参数可以传入自定义的比较逻辑(仅比较`props`)，例如实现深层比较(与`shouldComponentUpdate`的返回值相反，该方法返回`true`代表的是阻止渲染，返回`false`代表的是`props`发生变化，应当重新渲染)
* 区分三种性能优化方式
  * `React.memo()`：缓存虚拟DOM(组件UI)
  * `useCallback`：缓存函数
  * `useMemo`：缓存值

## GraphQL

## 二进制和八进制
* ES6 提供了二进制和八进制数值的新的写法，分别用前缀0b(或0B)和0o(或0O)表示
* 如果要将0b和0o前缀的字符串数值转为十进制，要使用Number方法，如`Number('0o10')`

## `<dl>`, `<dt>`, `<dd>`
* `<dl>`: Definition List (定义列表)
* `<dt>`: Definition Term(定义项)
* `<dd>`: Definition Description(定义描述)
* 这三个标签必须同时出现，而且dt，dd必须嵌套在dl内。dt和dd是同级关系，并不是嵌套关系。dd必须紧跟在dt之后，dd前可以有多个dt，但dd前面必须至少有一个dt。dt后面至少需要有一个dd。dt和dd是多对多的关系

## `rcc`, `rfc`

## `npm --save`
* 将安装的包添加到项目的package.json文件的dependencies字段中
* 当运行`npm install <package-name>`时，默认情况下，npm会将安装的包保存到项目的node_modules目录中，但不会将其添加到package.json文件中。这意味着如果将项目分享给其他人或在其他环境中部署项目时，其他人或其他环境需要手动运行`npm install`来安装依赖。为了简化依赖管理，你可以使用--save选项来告诉npm将安装的包添加到package.json文件中的dependencies字段中。这样，其他人或其他环境只需要运行npm install即可安装项目的所有依赖

## TS泛型
[链接](https://blog.csdn.net/semlinker/article/details/106882403?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-106882403-blog-124017662.235%5Ev40%5Epc_relevant_3m_sort_dl_base3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-106882403-blog-124017662.235%5Ev40%5Epc_relevant_3m_sort_dl_base3&utm_relevant_index=1)

## `Promise()`
* `new Promise((resolve,reject)=>{resolve(),reject()})`
* 这个数据容器内部有三种状态: 等待 ==>产生的正确数据  产生了错误的数据

## `createSagaMiddleware()`
* 创建一个Redux中间件，将Sagas与Redux Store链接起来
* sagas中的每个函数都必须返回一个Generator对象，middleware会迭代这个Generator并执行所有`yield`后的Effect(Effect可以看作是redux-saga的任务单元)

## GraphQL
* GraphQL与RESTful区别
  * RESTful一个接口只能返回一个资源，GraphQL一次可以获取多个资源
  * RESTful用不同的URL来区分资源，GraphQL用类型区分资源
* Schema：用于描述接口获取数据逻辑
  * Query描述资源的获取方式，可以将Schema理解为多个Query组成的一张表。其中，Query特指GraphQL中的查询（包含三种类型），query指GraphQL中的查询类型（仅指查询类型）
  * GraphQL中使用Query来抽象数据的查询逻辑，标准情况，有三种查询类型，分别是query（查询）、mutation（更改）和subscription（订阅）
* GraphQL，启动！
  * `npm install express express-graphql graphql mongoose`
  * create `xxx.js` with code
  * `http://localhost:4001/graphql`
    * `4001`: `app.listen(4001)`
    * `/graphql`: `app.use('/graphql', graphqlHTTP({ schema: Schema, rootValue: root, graphiql: true}))`
* 参数类型与传递
  * 基本类型：在GraphQL中他们统称叫标量类型(Scalar Type)，主要包括：`Int`（整型）, `Float`（浮点型）, `String`（字符串）, `Boolean`（布尔型）和`ID`（唯一标识符类型）；也允许自定义标量类型；另有对象类型
  * `!`用来表示这个参数不可以是空的；`[]`表示查询这个字段返回的是数组，`[]`里面是数组的类型
* MongoDB，启动: `mongod -dbpath=G:\NiHon-IT-Training-Plan\React\07_reactGraphQL\DB`
* GraphQL与React
  * 导入依赖: `npm i react-apollo apollo-boost graphql graphql-tag`
  * 要在React里使用Apollo数据栈前端至少需要三个包
    * `apollo-client`用于连接到Apollo后端
    * `graphql-tag`用于编写GraphQL查询
    * `react-apollo`用于执行GraphQL查询并将结果传给React的展示组件
  * `apollo-boost`：这个包包含了搭建Apollo客户端需要的所有东西
  * `react-apollo`：集成React的视图层
  * `graphql-tag`：解析GraphQL查询必要依赖
  * `graphql`：用于解析GraphQL查询

## DvaJS
* dva是基于现有应用架构(redux+react-router+redux-saga等)的一层轻量封装，没有引入任何新概念
* DvaJS特性
  * 易学易用，仅有6个api，对redux用户尤其友好，配合umi使用后更是降低为0 API
  * elm概念，通过reducers, effects和subscriptions组织model
  * 插件机制，比如dva-loading可以自动处理loading状态，不用一遍遍地写showLoading和hideLoading
  * 支持HMR（模块热替换），基于babel-plugin-dva-hmr实现components、routes和 models的HMR
* 数据流向
  * 所有的`state`通过`connect`流向组件，组件经过`dispatch`发起`action`请求
  * 通过model中的`reducer`和`effect`去改变`state`,`effect`副作用函数统一`call`/`fork`同步或者异步与服务进行数据交互
* 启动！
  * `npm install dva-cli -g`
  * `dva new react-dva`
  * `npm start`
* 项目目录结构
  > `mock`: 存放用于 mock 数据的文件 \
  > `public`: 一般用于存放静态文件，打包时会被直接复制到输出目录(./dist) \
  > `src`: 文件夹用于存放项目源代码 \
    > `asserts`: 用于存放静态资源，打包时会经过 webpack 处理 \
    > `components`: 用于存放 React 组件，一般是该项目公用的无状态组件 \
    > `models`: 用于存放模型文件 \
    > `routes`: 用于存放需要 connect model 的路由组件 \
    > `services`: 用于存放服务文件，一般是网络请求等 \
    > `utils`: 工具类库 \
    > `router.js`: 路由文件 \
    > `index.js`: 项目的入口文件 \
  > `editorconfig`: 编辑器配置文件 \
  > `.eslintrc`: ESLint配置文件 \
  > `.roadhogrc.mock.js`: Mock配置文件 \
  > `.webpackrc`: 自定义的webpack配置文件，JSON格式，如果需要JS格式，可修改为`.webpackrc.js`

## UmiJS
* Umi以路由为基础的，同时支持配置式路由和**约定式路由**，保证路由的功能完备，并以此进行功能扩展
* 什么时候不用Umi？
  * 需要支持IE 8或更低版本的浏览器
  * 需要支持React 16.8.0以下的React
  * 需要跑在Node 10以下的环境中
  * 有很强的webpack自定义需求和主观意愿
  * 需要选择不同的路由方案
* 为什么不是create-react-app: 是基于webpack的打包层方案，包含build、dev、lint等，他在打包层把体验做到了极致，但是不包含路由，不是框架，也不支持配置
* 为什么不是next.js: 不够贴近业务，不够接地气
* 约定化思想: 按照约定好的方式开发，就能达到某种效果，中间的过程由框架帮我们完成
* 技术收敛: 把大家常用的技术栈进行整理，收敛到一起
* 插件体系: 是Umi最重要的基建，包括Umi内部实现也是全部由插件构成
* 项目目录结构: 最重要的文件是``.umirc.ts`配置文件，在里面可以配置各种功能和插件，umi支持不同环境读取不同的配置文件
  ```
  .
  ├── package.json
  ├── .umirc.ts 配置文件，包含 umi 内置功能和插件的配置。
  ├── .env 环境变量
  ├── dist 执行 umi build 后，产物默认会存放在这里
  ├── mock 存储 mock 文件，此目录下所有 js 和 ts 文件会被解析为 mock 文件
  ├── public 此目录下所有文件会被 copy 到输出路径
  └── src
      ├── .umi 临时文件目录，比如入口文件、路由等，都会被临时生成到这里
      ├── layouts/index.tsx 约定式路由时的全局布局文件
      ├── pages 所有路由组件存放在这里
          ├── index.less
          └── index.tsx
      └── app.ts 运行时配置文件，可以在这里扩展运行时的能力，比如修改路由、修改 render 方法等
  ```
* 约定式路由
  * 约定式路由也叫文件路由，就是不需要手写配置，文件系统即路由
  * 通过src/pages目录和文件及其命名分析出路由配置, 也就是让umi根据约定好的目录结构帮我们生成路由配置文件
  * 需要注意的是，满足以下任意规则的文件不会被注册为路由
    > 以.或_开头的文件或目录 \
    > 以d.ts结尾的类型定义文件 \
    > 以test.ts、spec.ts、e2e.ts结尾的测试文件（适用于.js、.jsx和.tsx文件） \
    > components和component目录 \
    > utils和util目录 \
    > 不是.js、.jsx、.ts或.tsx文件 \
    > 文件内容不包含JSX元素
* mock功能
  * umi里约定mock文件夹下的文件或者page(s)文件夹下的_mock文件即mock文件
  * 文件导出接口定义，支持基于require动态分析的实时刷新，支持ES6语法，以及友好的出错提示
* dva集成
  * 按目录约定注册model，无需手动app.model
  * 文件名即namespace，可以省去model导出的namespace key
  * 无需手写router.js，交给umi处理，支持model和component的按需加载
  * 内置query-string处理，无需再手动解码和编码
  * 内置dva-loading和dva-immer，其中dva-immer需通过配置开启(简化reducer编写)

## JSON Server
* https://www.npmjs.com/package/json-server
* `npm install -g json-server`: 全局安装，否则找不到`json-server`指令，也不是环境变量的问题——然而还不够，近期默认下载的大概率是测试版，截至目前应该使用的命令是`npm i json-server@0.17.4 -g`才行
* `json-server db.json --port 5000`: 在当前终端所在的文件夹目录上确保存在`db.json`本地文件
* `http://localhost:5000/`

## JavaScript 中问号的三种用法
* `??`: 空值合并操作符，当左侧的操作数为`null`或者`undefined`时，返回其右侧操作数，否则返回左侧操作数
* `?.`: 可选链操作符允许读取位于连接对象链深处的属性的值，而不必明确验证链中的每个引用是否有效。使用它的好处是引用为`null`或者`undefined`的情况下不会引起错误
* `?:`: 三目运算

## yarn与npm的区别
* npm的缺点
  * 当新建一个项目需要执行npm inatall的时候速度太慢
  * 对于同一个项目，不同的人在安装的时候无法保证模块版本的一致性。****
* yarn的优点
  * 安装速度快：因为yarn缓存每一个下载过的包，所以再次使用时无需重复下载。同时利用并行下载以最大化资源利用率，因此安装速度更快。
  * 安全性较高：在执行代码之前，yarn会通过算法校验每个安装包的完整性。这个是npm所没有的。
  * 可靠性强：使用详细，间接的锁文件格式和明确的安装算法，yarn能够保证在不同系统上无差异的工作

## 块元素和内联元素
https://blog.csdn.net/weixin_43912081/article/details/119708763

# Vue

## Vue的特点
* 组件化模式：一个Vue文件含有html，css和js，相互组件独立
* 申明式编码：v-for="p in persons"
* 虚拟dom和diff算法，复用dom节点

## 创建vue实例对象
* 一个vue实例不可能去接管多个容器，如果有多个容器的情况，vue事例永远只接管第一个容器
* 不能多个vue实例同时来接管同一个容器，如果有多个的情况下永远是第一个vue实例来接管该容器
* vue实例与容器直接的对应关系是一对一的

## 模板语法
* 插值语法：一般用在标签体的值`{{}}`
* 指令语法：用于解析标签(标签体,标签属性, 绑定事件)上，类似于`v-bind`(还可以简写为`:`)

## 数据绑定
* **单向绑定(v-bind)：**数据只能从data流向页面
* **双向绑定(v-model)：**数据不仅能从data流向页面，还可以从页面流向data
  * 双向绑定一般都应用在表单类元素上（如：`input`、`select`等）
  * `v-model`:value可以简写为v-model，因为v-model默认收集的就是value值

## el和data的两种写法
* el的两种写法
```js
const v = new Vue({
  el: '#root',
  data: {
    name: 'Tokyo'
  }
});
```
```js
setTimeout(() => {
  v.$mount('#root');
}, 3000)
```
* data的两种写法
```js
data: {
  name: ' Tokyo'
}
```
```js
data: () => { // 尽量不要写成箭头函数
  console.log('@@@', this); //此时this是Window
  return {
    name: 'Tokyo'
  }
}
```
```js
data() {
  console.log('@@@', this); //此时this是Vue
  return {
    name: 'Tokyo'
  }
}
```

## MVVM模型
* **M**：模型(Model)：data中的数据
* **V**：视图(View)：模板代码
* **VM**：视图模型(ViewModel)：Vue实例
data中所有的属性，最后都出现在了vm身上
vm身上所有的属性 及 Vue原型上所有属性，在Vue模板中都可以直接使用

## 数据代理
* 通过vm对象来代理data对象中属性的操作（读/写），更加方便的操作data中的数据
* 基本原理：通过Object.defineProperty()把data对象中所有属性添加到vm上。为每一个添加到vm上的属性，都指定一个getter/setter。在getter/setter内部去操作（读/写）data中对应的属性。
```js
Object.defineProperty(person,'age', {
  value: 18,
  enumerable: true, //此时代表这个属性是可以枚举的
  writable: true, //代表可以重写该属性(控制属性是否被修改)
  configurable:true, //控制属性是否可以被删除 默认为false

  //当读取person的age属性时get属性就会被调用，且返回值就是age的值
  //invoke property proxy映射数据代理
  get: function () {
    //测试它的调用情况
    console.log('@@@ GET AGE');
    //此时age的值依赖number的值
    return number
  },
  //当修改person的age属性时set(setter)属性就会被调用，且会收到修改的具体值
  set(v) {
    //测试
    console.log('CHANGE AGE');
    number=v;
  }
});
```

## 事件处理
* 使用v-on:xxx或@xxx绑定事件，其中xxx是事件名；
* 事件的回调需要配置在methods对象中，最终会在vm上；
* methods中配置的函数，不要用箭头函数！否则this就不是vm了；
* methods中配置的函数，都是被Vue所管理的函数，this的指向是vm或组件实例对象；
* `@click="demo"`和`@click="demo($event)"`效果一致，但后者可以传参；  

## 事件修饰符
* `prevent`：阻止默认事件（常用）；
* `stop`：阻止事件冒泡（常用）；
* `once`：事件只触发一次（常用）；
* `capture`：使用事件的捕获模式；
* `self`：只有event.target是当前操作的元素时才触发事件；
* `passive`：事件的默认行为立即执行，无需等待事件回调执行完毕；

## 计算属性computed
* get的作用，当读取fullName时get就会被调用，且返回值就做为fullName的值
* defineProperty
* 注意vm._data是不存在计算属性的
* 计算属性算完之后直接丢到了viewModel实例对象身上
* get的调用时机
  * 初次读取计算属性时
  * 所依赖的数据(data中的属性)发生变化时，不改变的话直接读缓存
  * methods没有缓存，读几次就调用几次无论要用的数据是否发生变化
* set的调用时机
  * 当fullName被修改时

## 监视属性watch
* 当被监视的属性变化时, 回调函数自动调用, 进行相关操作
* 监视的属性必须存在，才能进行监视！！
* 监视的两种写法：
  1. `new Vue`时传入`watch`配置
  ```js
  const vm = new Vue({
      watch:{
          isHot:{ // isHot
              immediate: true,
              handler(newValue, preValue){
                  console.log(newValue,preValue);
              }
          }
      }
  });
  ```
  2. 通过`vm.$watch`监视
  ```js
  vm.$watch('isHot', { // 'isHot'
      immediate: true,
      handler(newValue, preValue) {
          console.log(newValue,preValue);
      }
  });
  ```
* 深度监视：
  * Vue中的watch默认不监测对象内部值的改变（一层）。
  * 配置`deep:true`可以监测对象内部值改变（多层）。
  * Vue自身可以监测对象内部值的改变，但Vue提供的watch默认不可以(想让它可以则配置`deep:true`)！
  * 使用watch时根据数据的具体结构，决定是否采用深度监视。
* 监视简写形式：
  1. `new Vue`时传入`watch`配置
  ```js
  const vm = new Vue({
      watch:{
          isHot(newValue, preValue){
              console.log(newValue,preValue);
          }
      }
  });
  ```
  2. 通过`vm.$watch`监视
  ```js
  vm.$watch('isHot', function (newValue, preValue) {
      //this === vm
      console.log(newValue, preValue);
  })
  ```

## 绑定样式
* class样式
  * 写法:`class="xxx"` xxx可以是字符串、对象、数组。
    * **字符串写法**适用于：类名不确定，要动态获取。
    * **对象写法**适用于：要绑定多个样式，个数不确定，名字也不确定。
    * **数组写法**适用于：要绑定多个样式，个数确定，名字也确定，但不确定用不用。
* style样式
  * `:style="{fontSize: xxx}"`其中xxx是动态值。
  * `:style="[a,b]"`其中a、b是样式对象。

## 条件渲染
* v-if
  * 写法：
    * `v-if="表达式"`
    * `v-else-if="表达式"`
    * `v-else="表达式"`
  * 适用于：切换频率较低的场景。
  * 特点：不展示的DOM元素直接被移除。
  * 注意：v-if可以和:v-else-if、v-else一起使用，但要求结构不能被“打断”。
* v-show
  * 写法：v-show="表达式"
  * 适用于：切换频率较高的场景。
  * 特点：不展示的DOM元素未被移除，仅仅是使用样式隐藏掉
* 使用v-if的时，元素可能无法获取到，而使用v-show一定可以获取到。
* 建议与`<template>`配合使用

## 基本列表
* v-for指令:
  * 用于展示列表数据
  * 语法：`v-for="(item, index) in xxx" :key="yyy"`，注意其中的`index`可能出问题
  * 可遍历：数组、对象、字符串（用的很少）、指定次数（用的很少）


## react、vue中的key有什么作用？（key的内部原理）
1. 虚拟DOM中key的作用：
  key是虚拟DOM对象的标识，当数据发生变化时，Vue会根据【新数据】生成【新的虚拟DOM】,
  随后Vue进行【新虚拟DOM】与【旧虚拟DOM】的差异比较，比较规则如下：
2. 对比规则：
  1. 旧虚拟DOM中找到了与新虚拟DOM相同的key：
    1. 若虚拟DOM中内容没变, 直接使用之前的真实DOM！
    2. 若虚拟DOM中内容变了, 则生成新的真实DOM，随后替换掉页面中之前的真实DOM。
  2. 旧虚拟DOM中未找到与新虚拟DOM相同的key
    创建新的真实DOM，随后渲染到到页面。
3. 用index作为key可能会引发的问题：
  1. 若对数据进行：逆序添加、逆序删除等破坏顺序操作:
    会产生没有必要的真实DOM更新 ==> 界面效果没问题, 但效率低。
  2. 如果结构中还包含输入类的DOM：
    会产生错误DOM更新 ==> 界面有问题。
4. 开发中如何选择key?:
  1. 最好使用每条数据的唯一标识作为key, 比如id、手机号、身份证号、学号等唯一值。
  2. 如果不存在对数据的逆序添加、逆序删除等破坏顺序操作，仅用于渲染列表用于展示，
            使用index作为key是没有问题的。

## 列表过滤
* 实现方式：
  * 计算属性：
  ```js
  data: {
      // ...
  }
  computed:{
      filPersons(){
          return this.persons.filter(p => p.name.indexOf(this.keyword) !== -1); // getter简写
      }
  }
  ```
  * 监视属性：
  ```js
  data: {
      // ...
      filPersons: [] // 搜索结果数组，写全则不需要immediate: true
  }
  watch: {
      keyword: {
          immediate: true, //上来就进行监视获得到的newV是''
          handler(newV) {
              this.filPersons = this.persons.filter(p => p.name.indexOf(newV) !== -1);
          }
      }
  }
  ```

## Vue监视数据的原理：
* vue会监视data中所有层次的数据。
* 通过`setter`实现监视，且要在`new Vue`时就传入要监测的数据。
  * 对象中后追加的属性，Vue默认不做响应式处理
  * 如需给后添加的属性做响应式，请使用如下API：
    * `Vue.set(target，propertyName/index，value)`或
    * `vm.$set(target，propertyName/index，value)`
* 如何监测数组中的数据？
  * 通过包裹数组更新元素的方法实现，本质就是做了两件事：
    * 调用原生对应的方法对数组进行更新。
    * 重新解析模板，进而更新页面。
* 在Vue修改数组中的某个元素一定要用如下方法：
  * 使用这些API:`push()`、`pop()`、`shift()`、`unshift()`、`splice()`、`sort()`、`reverse()`
  * `Vue.set()` 或 `vm.$set()`
* 特别注意：`Vue.set()` 和 `vm.$set()` 不能给vm或vm的根数据对象添加属性！！！
  * 注: 数据劫持可以理解成为vue对你写在data的数据会进行加工，让它们都变成响应式的

## 常用的生命周期钩子：
* `mounted`: 发送ajax请求、启动定时器、绑定自定义事件、订阅消息等【初始化操作】。
* `beforeDestroy`: 清除定时器、解绑自定义事件、取消订阅消息等【收尾工作】。
* 关于销毁Vue实例
  * 销毁后借助Vue开发者工具看不到任何信息。
  * 销毁后自定义事件会失效，但原生DOM事件依然有效。(click之类的原生事件依然会被调用)
  * 一般不会在beforeDestroy操作数据，因为即便操作数据，也不会再触发更新流程了。

## Vue中使用组件的三大步骤：
* 定义组件(创建组件)
  * 使用Vue.extend(options)创建，其中options和new Vue(options)时传入的那个options几乎一样，但也有点区别；
  * 区别如下：
	  * el不要写，为什么？ ——— 最终所有的组件都要经过一个vm的管理，由vm中的el决定服务哪个容器。
    * data必须写成函数，为什么？ ———— 避免组件被复用时，数据存在引用关系。
  * 备注：使用template可以配置组件结构。
* 注册组件
  * 局部注册：靠new Vue的时候传入components选项
  ```js
  new Vue({
      el: "#root",
      data: {},
      components: {
          school,
          student
      },
  })
  ```
  * 全局注册：靠`Vue.component('组件名',组件)`
* 使用组件(写组件标签)
  * `<school></school>`

## Vue中使用组件的几个注意点：
* 关于组件名:
  * 一个单词组成：
    * 第一种写法(首字母小写)：school
    * 第二种写法(首字母大写)：School
  * 多个单词组成：
    * 第一种写法(kebab-case命名)：my-school
    * 第二种写法(CamelCase命名)：MySchool (需要Vue脚手架支持)
    * 备注：
    * 组件名尽可能回避HTML中已有的元素名称，例如：h2、H2都不行。
    * 可以使用name配置项指定组件在开发者工具中呈现的名字。
* 关于组件标签:
  * 第一种写法：`<school></school>`
  * 第二种写法：`<school/>`
  * 备注：不用使用脚手架时，`<school/>`会导致后续组件不能渲染。
* 一个简写方式：
  * `const school = Vue.extend(options)`可简写为：`const school = options`

## 关于VueComponent：
* school组件本质是一个名为VueComponent的构造函数，且不是程序员定义的，是Vue.extend生成的。
* 我们只需要写<school/>或<school></school>，Vue解析时会帮我们创建school组件的实例对象，
  * 即Vue帮我们执行的：new VueComponent(options)。
* 特别注意：每次调用Vue.extend，返回的都是一个全新的VueComponent！！！！注意这一点很重要
* 关于`this`指向：
  * 组件配置中：data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【**VueComponent实例对象**】(它的原型对象是**Vue实例对象**)。不允许指定`el`。
  * `new Vue(options)`配置中：data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【**Vue实例对象**】。允许指定`el`。
* VueComponent的实例对象，以后简称vc（也可称之为：组件实例对象）。
  * Vue的实例对象，以后简称vm。 vm管理着一个又一个vc，vc可以再
* 因为组件是可复用的 Vue 实例，所以它们与 new Vue 接收相同的选项，例如 data、computed、watch、methods 以及生命周期钩子等。仅有的例外是像 el 这样根实例特有的选项。
  * 所以vm与vc属性配置并不是一模一样，尽管vc底层复用了很多vm的逻辑
* 一个重要的内置关系：`VueComponent.prototype.__proto__ === Vue.prototype === vm.__proto__`
* 为什么要有这个关系：让组件实例对象（vc）可以访问到 Vue原型上的属性、方法。

## 收集表单数据：
  * 若：`<input type="text"/>`，则v-model收集的是value值，用户输入的就是value值。
  * 若：`<input type="radio"/>`，则v-model收集的是value值，且要给标签配置value值。
  * 若：`<input type="checkbox"/>`
* 没有配置input的value属性，那么收集的就是checked（勾选 or 未勾选，是布尔值）
* 配置input的value属性:
  * v-model的初始值是非数组，那么收集的就是checked（勾选 or 未勾选，是布尔值）
  * v-model的初始值是数组，那么收集的的就是value组成的数组
* 备注：v-model的三个修饰符：
  * `lazy`：失去焦点再收集数据
  * `number`：输入字符串转为有效的数字
  * `trim`：输入首尾空格过滤

## 过滤器：
* 定义：对要显示的数据进行特定格式化后再显示（适用于一些简单逻辑的处理）。
* 语法：
  * 注册过滤器：`Vue.filter(name,callback)` 或 `new Vue{filters:{}}`
  * 使用过滤器：`{{ xxx | 过滤器名}}`或`v-bind:属性 = "xxx | 过滤器名"`
* 备注：
  * 过滤器也可以接收额外参数、多个过滤器也可以串联
  * 并没有改变原本的数据, 是产生新的对应的数据

## 内置指令
* 学过的指令：
  * `v-bind`	: 单向绑定解析表达式, 可简写为 :xxx
  * `v-model`	: 双向数据绑定
  * `v-for`  	: 遍历数组/对象/字符串
  * `v-on`   	: 绑定事件监听, 可简写为@
  * `v-if`  	: 条件渲染（动态控制节点是否存存在）
  * `v-else` 	: 条件渲染（动态控制节点是否存存在）
  * `v-show` 	: 条件渲染 (动态控制节点是否展示)
* `v-text`指令：
  * 作用：向其所在的节点中渲染文本内容。 (纯文本渲染)
  * 与插值语法的区别：`v-text`会替换掉节点中的内容，`{{xx}}`则不会。这里有点不太灵活
* `v-html`指令：
  * 作用：向指定节点中渲染包含html结构的内容。
  * 与插值语法的区别：
	  * `v-html`会替换掉节点中所有的内容，`{{xx}}`则不会。
	  * `v-html`可以识别html结构。
  * 严重注意：`v-html`有安全性问题！！！！
	  * 在网站上动态渲染任意HTML是非常危险的，容易导致XSS攻击。
	  * 一定要在可信的内容上使用`v-html`，永不要用在用户提交的内容上！
* `v-cloak`指令（没有值）：
  * 本质是一个特殊属性，Vue实例创建完毕并接管容器后，会删掉`v-cloak`属性。
  * 使用css配合`v-cloak`可以解决网速慢时页面展示出`{{xxx}}`的问题。
  * `<style>[v-cloak]{display: none;}</style> <h2 v-cloak>{{name}}</h2>`
* `v-once`指令：
  * `v-once`所在节点在初次动态渲染后，就视为静态内容了。
  * 以后数据的改变不会引起`v-once`所在结构的更新，可以用于优化性能。
* `v-pre`指令：
  * 跳过其所在节点的编译过程。
  * 可利用它跳过：没有使用指令语法、没有使用插值语法的节点，会加快编译。

## 自定义指令总结：
* 定义语法：
  * 局部指令：
    * `new Vue({directives:{指令名:配置对象} })`或`new Vue({directives: {指令名:回调函数}})`
  * 全局指令：
    * `Vue.directive(指令名,配置对象)`或`Vue.directive(指令名,回调函数)`
* 配置对象中常用的3个回调：
  * `bind`：指令与元素成功绑定时调用。
  * `inserted`：指令所在元素被插入页面时调用。
  * `update`：指令所在模板结构被重新解析时调用。
* 备注：
  * 指令定义时不加`v-`，但使用时要加`v-`；
  * 指令名如果是多个单词，要使用`kebab-case`命名方式，不要用`camelCase`命名。

## redux持久化存储和localStorage持久化存储有什么区别，各自优劣
Redux持久化存储和localStorage持久化存储是两种不同的数据持久化方法，它们之间存在一些关键的区别以及各自的优劣。

Redux持久化存储：

Redux是一个用于JavaScript应用程序的可预测状态容器。其核心思想是通过将应用的状态存储在一个单一的JavaScript对象中，并使用纯函数来修改状态，从而实现可预测性和可维护性。然而，Redux默认并不提供数据持久化的功能，即当应用重新加载或刷新时，之前存储在Redux中的状态会丢失。因此，Redux持久化中间件被开发出来，用于将Redux的状态自动持久化到本地存储中，如浏览器的localStorage或sessionStorage。这样，即使在应用重新加载或刷新后，状态也能被恢复。

优势：

* **状态管理**：Redux提供了强大的全局状态管理能力，使得状态在不同组件间共享变得简单。
* **可预测性**：通过纯函数来修改状态，确保了状态变化的可预测性。
* **灵活性**：Redux持久化中间件可以与各种存储介质配合使用，提供更大的灵活性。

劣势：

* **学习曲线**：Redux及其持久化中间件可能需要一定的学习成本，特别是对于初学者来说。
* **性能开销**：由于需要将状态持久化到存储介质中，可能会引入一定的性能开销。

localStorage持久化存储：

localStorage是Web上的一种本地存储技术，用于在客户端浏览器上永久存储数据。除非用户手动删除相关数据，否则数据会一直存在。它的生命周期是永久的，并且相同域名下的localStorage是共享的，可以读取、清除和覆盖。然而，它仅限于同一浏览器和同源文件，不同浏览器之间不能共享数据。

优势：

* **简单性**：localStorage的API相对简单，易于理解和使用。
* **持久性**：数据存储在本地，除非手动删除，否则会一直存在。
* **共享性**：相同域名下的不同页面或标签页可以共享localStorage中的数据。

劣势：

* **安全性**：localStorage中的数据可以被用户或其他脚本访问和修改，因此可能存在安全隐患。
* **存储限制**：localStorage的存储空间有限，如果存储过多数据可能会影响性能。
* **同源策略**：localStorage受限于同源策略，不同域名下的页面不能共享数据。

综上所述，Redux持久化存储和localStorage持久化存储各有其优缺点。Redux持久化存储更适合于需要全局状态管理和可预测性的场景，而localStorage持久化存储则更适合于简单的数据持久化需求。在选择使用哪种方法时，需要根据具体的应用场景和需求进行权衡。

## `indexOf`
```js
p => p.name.indexOf(this.keyword) !== -1
```
返回指定值在字符串中首次出现的索引，如果未找到该值，则返回`-1`。这里，它检查`this.keyword`（即用户在输入框中输入的关键字）在当前人员名字中的位置。这个条件判断当前人员名字中是否包含用户输入的关键字。如果包含，`indexOf`会返回一个非`-1`的索引值，这个条件就为`true`，否则为`false`
```js
const arr = this.persons.filter(p => p.name.indexOf(this.keyword) !== -1)
```
这行代码的作用是：从`this.persons`数组中过滤出那些名字中包含`this.keyword`（用户输入的关键字）的人员，并将这些人员放入一个新的数组`arr`中

## 数据更新问题
`this.persons.splice(1, 1, { id: '002', name: '马老师', age: 50, sex: '男' });`

这行代码使用了数组的 `splice()` 方法，该方法用于向数组添加/删除项目，然后返回被删除的项目。在这个具体的例子中，`splice()` 方法做了以下事情：

1. **1**: 第一个参数是开始位置，表示从数组的哪个位置开始操作。在这里，它是 `1`，意味着从数组的第二个元素开始（数组索引从 `0` 开始）。

2. **1**: 第二个参数是要删除的元素数量。在这里，它是 `1`，表示从指定的开始位置删除一个元素。

3. **{ id: '002', name: '马老师', age: 50, sex: '男' }**: 这是第三个及之后的参数，表示要添加到数组中的新元素。在这个例子中，添加了一个新的人员对象。

所以，这行代码的作用是在 `this.persons` 数组的第二个位置（索引为 `1`）删除一个元素，并在相同位置添加一个新的人员对象 `{ id: '002', name: '马老师', age: 50, sex: '男' }`。

需要注意的是，如果原始数组在索引 `1` 的位置已经有一个元素，那么该元素会被删除，并替换为新的人员对象。如果原始数组在索引 `1` 的位置没有元素（例如，数组只有一个元素或者为空），那么新的人员对象会被添加到那个位置。

此外，由于 `splice()` 方法直接修改了原数组，所以 `this.persons` 数组现在包含了新添加的人员对象，并且可能不再包含之前位于索引 `1` 的元素。

还有一点需要注意，新添加的人员对象的 `id` 与原数组中可能已存在的某个对象的 `id` 相同（都是 `'002'`）。如果 `id` 是用于唯一标识数组中每个对象的，那么这可能是一个问题，因为它可能导致数据不一致或混淆。在实际应用中，通常应该确保 `id` 的唯一性。

`this.persons[1] = { id: '002', name: '马老师', age: 50, sex:'男' };`

但这样是不行的，无法实现更新

## 箭头函数this
箭头函数（Arrow Functions）在JavaScript中提供了一种更简洁的函数语法。箭头函数的一个关键特性是它不绑定自己的 `this` 值，而是捕获其所在上下文的 `this` 值，作为自己的 `this` 值。这意味着，在箭头函数内部使用的 `this`，实际上是在定义箭头函数时所在的外部作用域的 `this`。

这种特性使得箭头函数在处理回调函数、事件处理器、定时器等方面非常有用，尤其是当你想保持 `this` 指向不变时。

下面是一个具体的例子来说明这个特性：


```javascript
function OuterFunction() {
  this.value = "I am from OuterFunction";

  // 常规函数
  this.normalFunction = function() {
    console.log(this.value); // 输出 "I am from OuterFunction"
  };

  // 箭头函数
  this.arrowFunction = () => {
    console.log(this.value); // 输出 "I am from OuterFunction"
  };
}

const outer = new OuterFunction();

outer.normalFunction(); // 输出 "I am from OuterFunction"
outer.arrowFunction(); // 输出 "I am from OuterFunction"

// 更改全局的 this 指向（在浏览器环境中通常是 window 对象）
const anotherValue = "I am from global scope";
globalThis.value = anotherValue; // 使用 globalThis 以兼容不同的环境（如浏览器和 Node.js）

// 使用 setTimeout 来模拟异步调用，这样可以看到 this 的指向在函数执行时是如何的
setTimeout(outer.normalFunction, 0); // 输出 "I am from global scope"，因为 normalFunction 的 this 在执行时指向了 globalThis（或 window）
setTimeout(outer.arrowFunction, 0); // 输出 "I am from OuterFunction"，因为 arrowFunction 的 this 是在定义时捕获的，指向 OuterFunction 的实例
```
在这个例子中，`OuterFunction` 有一个常规函数 `normalFunction` 和一个箭头函数 `arrowFunction`。当这两个函数被调用时，它们都试图访问 `this.value`。对于 `normalFunction`，它的 `this` 在执行时指向了全局对象（在浏览器中是 `window`），因此它输出了全局作用域中的 `value` 值。然而，对于 `arrowFunction`，它的 `this` 是在定义时捕获的，指向 `OuterFunction` 的实例，因此它输出了 `OuterFunction` 实例中的 `value` 值。

这个特性使得箭头函数在处理 `this` 指向方面更加直观和可预测，尤其是在处理回调函数和事件处理器时。不过，也需要注意，由于箭头函数不绑定自己的 `this`，它们也不能用作构造函数（即不能使用 `new` 关键字来调用）。

## `VueComponent.prototype.__proto__ === Vue.prototype === vm.__proto__`
1. **Vue.prototype**
`Vue.prototype` 是 Vue 构造函数的原型对象。这意味着当你创建一个 Vue 实例（例如 `new Vue({...})`）时，这个实例会继承 `Vue.prototype` 上的所有属性和方法。Vue 允许你扩展 `Vue.prototype` 来添加全局的自定义方法或属性，这样它们就可以在任何 Vue 实例中访问。
2. **VueComponent.prototype**
`VueComponent` 是 Vue 组件的构造函数。当你定义一个 Vue 组件时（无论是全局组件还是局部组件），这个组件的背后实际上是一个 `VueComponent` 的实例。`VueComponent.prototype` 是这个构造函数的原型对象，它继承了 `Vue.prototype` 的所有属性和方法，并可能添加了一些组件特有的属性和方法。
3. **vm.__proto__**
`vm` 通常是一个 Vue 实例的引用。在 JavaScript 中，每个对象都有一个 `__proto__` 属性，它指向该对象的原型。因此，`vm.__proto__` 就是 `vm` 这个 Vue 实例的原型，它应该指向 `Vue.prototype`（或者更准确地说是 `Vue.prototype` 的一个实例，因为原型可能会被修改）。
- `VueComponent.prototype.__proto__` 应该指向 `Vue.prototype`，因为 `VueComponent` 继承自 `Vue`。
- `vm.__proto__` 应该指向 `Vue.prototype`，因为 `vm` 是一个 Vue 实例。

## 构造函数，原型对象，实例，实例的引用
1. **构造函数**：
构造函数是一种特殊的函数，当创建对象时，它会被自动调用。构造函数的主要任务是初始化对象的状态，即为其属性设置初始值。在JavaScript中，构造函数的名字通常与类名相同，它可以有参数，但不能有返回值（除了`void`）。一旦对象生成，构造函数自动调用，且不能再次执行。

例如，在JavaScript中：


```javascript
function Car(color, make) {
    this.color = color;
    this.make = make;
}
```
上面的`Car`就是一个构造函数，它接受两个参数`color`和`make`，并初始化新创建的对象的这两个属性。
2. **原型对象**：
在JavaScript中，每个函数都有一个`prototype`属性，这个属性的值是一个对象，我们称之为“原型对象”。原型对象主要用于共享方法和属性。当一个对象试图访问一个属性或方法时，如果这个属性或方法在该对象自身上不存在，那么JavaScript引擎就会在该对象的原型（即构造函数的`prototype`属性所指向的对象）上查找。这种机制实现了属性和方法的继承。
3. **实例**：
在计算机语言中，“类”在实例化之后叫做一个“实例”。一个类定义了对象的结构（属性和方法），而实例则是这个结构的一个具体实现。每个实例都有自己的内存空间，存储其属性和方法的具体值。在数据库中，实例也可以表示一些程序的集合，如在Oracle中，实例是一些能支撑数据库运行的数据库程序。
4. **实例的引用**：
在计算机语言中，引用是指向某一变量（或对象）的别名。对引用的操作实际上就是对所引用变量（或对象）的直接操作。这种机制允许我们间接地访问和操作对象，而不需要直接知道其内存地址。在JavaScript中，引用是通过变量名来实现的。

例如：


```javascript
let car1 = new Car('red', 'Toyota');
let car2 = car1; // car2是car1的一个引用，它们指向同一个对象
```
在这个例子中，`car2`是`car1`的一个引用，它们都指向同一个`Car`实例。对`car2`的修改也会影响到`car1`，因为它们引用的是同一个对象。

## Vue Cli, Vue SFC, Vite
* Vue CLI，即Vue命令行界面（Command-Line Interface），是一个基于Vue.js进行快速开发的完整系统。它提供了一个交互式的项目脚手架，通过@vue/cli实现，致力于将Vue生态中的工具基础标准化。Vue CLI确保了各种构建工具能够基于智能的默认配置平稳衔接，使开发者能够专注于编写应用程序，而不是花费大量时间在配置上。此外，Vue CLI还提供了丰富的官方插件集合，集成了前端生态系统中最好的工具，以及一个完整的图形用户界面，用于创建和管理Vue.js项目。
* Vue SFC是单文件组件（Single-File Component）的缩写。这是一种特殊的文件格式，允许开发者将Vue组件的模板、逻辑与样式封装在一个单独的`.vue`文件中。具体来说，`<template>`、`<script>`和`<style>`三个块在同一个`.vue`文件中封装、组合了组件的视图、逻辑和样式。这种设计使得组件的开发和维护更加便捷和高效。需要注意的是，浏览器本身并不支持`.vue`文件，因此需要对这些文件进行加载和解析。这通常是通过vue-loader等Webpack的loader来实现的，它们可以将`.vue`文件转换为JavaScript模块，以便在浏览器中运行。总的来说，Vue SFC是Vue.js框架中的一个重要特性，它大大简化了Vue组件的开发过程，提高了开发效率。
* Vite是一种新型的前端构建工具，最初是配合Vue 3.0一起使用的，后来适配了各种前端项目，目前提供了Vue、React、Preact框架模板。Vite旨在提供开箱即用的配置，其插件API和JavaScript API带来了高度的可扩展性，并有完整的类型支持。它具有以下显著特点：快速的冷启动、即时的模块热更新、真正的按需编译。在2023年4月20日，Vite官方团队宣布了Vite 4.3的正式发布，专注于改进devServer的性能，提升了整体速度，并在Best of JS公布的前端构建工具中名列前茅。总的来说，Vite是一个强大且灵活的前端构建工具，为开发者提供了高效、快速的前端开发体验。

## Vue项目创建
* 基于[Vite Vue 3 工具链指南](https://cn.vuejs.org/guide/scaling-up/tooling.html)
```
npm create vue@latest

cd vue-project
npm install
npm run dev
```
* 基于[Vue CLI](https://cli.vuejs.org/zh/#%E8%B5%B7%E6%AD%A5)
```
npm install -g @vue/cli
# OR
yarn global add @vue/cli

vue create my-project
# OR
vue ui

cd my-project
npm run serve
```

## props传参数
* 注意props传递过来的值是不能改的(尽量避免去改，控制台会有警告)
* 如果props和data存在同名的属性，会报错，但已props传递的属性值为主
* 注意props属性名不能是vue底层已征用的属性名(比如key, ref等等)
* 把props传递过来的值当成vc的状态，这样改name是不会出问题的，因为你没有直接去修改props
* 有三种设置形式，具体参考NiHon-IT-Training-Plan\Vue\VueCli\src\components\StudentDemo.vue

## Vue `<label>`标签
`<label>`标签用于定义标签，通常与表单元素一起使用，以提供点击区域，将点击与特定表单元素关联，例如单选按钮或复选框。

## Vue localStorage和sessionStorage
在Vue.js中，`localStorage`和`sessionStorage`都是Web Storage API的一部分，它们提供了在客户端存储数据的方式，但有一些关键的不同点。以下是它们的异同：
### 相同点：
1. **存储类型**：两者都用于在浏览器中存储键值对（key-value pairs）的数据。
2. **数据格式**：它们存储的数据都是字符串格式。如果你需要存储其他类型的数据（如对象或数组），你需要先将它们转换为字符串，然后再存储。同样，当你从存储中检索数据时，你也需要将字符串转换回原始的数据类型。
3. **同源策略**：它们都遵循浏览器的同源策略，这意味着一个源（域、协议和端口）存储的数据不能被其他源访问。
### 不同点：
1. **生命周期**：
   - `localStorage`：数据没有过期时间，它会一直存储在浏览器中，直到用户或脚本显式地删除它。即使用户关闭了浏览器或重启了设备，数据仍然会保留。
   - `sessionStorage`：数据只在当前会话（session）中有效，即当用户关闭浏览器标签页或窗口时，数据会被清除。如果重新打开相同的标签页或窗口，之前存储的数据将不可访问。
2. **存储容量**：虽然现代浏览器对两者的存储容量都有很大的限制（通常是几MB），但具体限制可能因浏览器而异。在大多数情况下，这不会成为问题，但如果你需要存储大量数据，可能需要考虑其他解决方案。
3. **用途**：
   - `localStorage`：通常用于存储需要长期保留的数据，如用户偏好设置、缓存数据等。
   - `sessionStorage`：更适用于存储会话期间需要的数据，如表单输入、临时状态等。
在Vue.js中，你可以使用这两个API来增强应用程序的功能，如存储用户状态、缓存数据以减少服务器请求等。但请注意，由于数据存储在客户端，因此不应存储敏感信息，如密码或私钥，因为这些数据可以被用户或恶意脚本访问。对于敏感数据，应始终使用服务器端存储和加密。

## 代码分析 `<Student ref="student" @click.native="show" />`
1. **ref="student"**
`ref` 是一个特殊的属性，它用于给 Vue 组件或 DOM 元素注册一个引用信息。通过 `ref`，你可以在 Vue 实例的方法或计算属性中直接访问到这个组件或 DOM 元素。
在你给出的代码中，`ref="student"` 意味着你可以在父组件的 Vue 实例中通过 `this.$refs.student` 来访问这个 `Student` 组件的实例。这通常用于需要直接访问子组件实例的场景，比如手动调用子组件的方法或访问其数据。
2. **@click.native="show"**
`@click.native` 是一个事件监听器，用于监听原生 DOM 事件。在 Vue 组件中，事件默认是组件自定义的事件，而不是原生 DOM 事件。如果你想监听组件根元素的原生事件，你需要在事件名后加上 `.native` 修饰符。
在这里，`@click.native="show"` 意味着当 `Student` 组件的根元素被点击时，父组件的 `show` 方法会被调用。这是因为在 Vue 2 中，如果你尝试在组件上直接监听一个原生事件（比如 `click`），它是不会起作用的，除非你使用了 `.native` 修饰符。
注意：在 Vue 3 中，`.native` 修饰符已经不再是必要的，因为 Vue 3 改进了组件的事件监听机制，使得监听组件的根元素的原生事件变得更加直接和简单。但是，如果你正在使用 Vue 2，那么 `.native` 修饰符仍然是一个很有用的工具。
综上所述，这段代码允许你在父组件中通过 `ref` 直接访问 `Student` 组件的实例，并且当 `Student` 组件的根元素被点击时，会调用父组件的 `show` 方法。

## 插槽
* **默认插槽**允许父组件向子组件传递任意内容，子组件中通过`<slot></slot>`标签定义默认插槽的位置。
* **具名插槽**允许在子组件中定义多个插槽，并通过不同的名称来区分它们，从而更加灵活地控制内容的渲染位置。
  * `v-slot`仅仅只能被用在组件上或者template标签上
* **作用域插槽**是Vue的高级插槽机制，它允许父组件将数据传递给子组件，并在子组件中自定义渲染这些数据。这通常用于需要动态渲染的内容以及子组件需要访问来自父组件的数据的情况。

## VUEX
* Vue2使用VUEX3及以下，Vue3才可使用VUEX4及以上
* 对比Redux，VUEX异步操作不需要中间件

## VUE router
* Vue2使用3及以下
* 使用params传递参数，不能配置path，只能配置name
* props
	* **props的第一种写法：**值为对象，该对象的所有key-value都会以props的形式传给detail组件(死数据)
	```js
	props:{
	  a:1,
	  b:'hello'
	}
	```
	* **props的第二种写法：**值为布尔值，布尔值为真，就会把该路由组件收到的所有params(注意如果是query参数不会奏效的)参数以props的形式传递给detail组件
	```js
	props: true
	```
	* **props的第三种写法：**值为函数，$route.query.id
	```js
	props({ query: { id, title } }) {
		return {
			id,
			title
		}
	}
	```

## Vue组件库
* Antdv
* Element
* iView

## Vue 2 & Vue 3
* Vue2.x配置（data、methos、computed...）中可以访问到setup中的属性、方法。
* 但在setup中不能访问到Vue2.x配置（data、methos、computed...）。
* 如果有重名, setup优先。

## Vue 3 setup
* `setup()`执行完才会执行`beforeCreate()`
* context
  ```
	attrs: (…)
	emit: (…)
	expose: exposed => {…}
	slots: (…)
	get attrs: ƒ attrs()
	get emit: emit() { return (event, ...args) => {…}
	get slots: ƒ slots()
	[[Prototype]]: Object
	```

## Vue 3 watch
```js
/*
 * 情况三:监视reactive所定义的一个响应式数据
 * 坑:1.此处无法获取正确的ov(oldValue)
 *    2.强制开启了深度监视
 */
watch(person, (nv, ov) => {
	console.log('person变化了');
	console.log(nv, ov);
	// 两次输出结果相同，均为nv
}, {
	deep: false // 课件中此处的deep配置是无效的，默认开启深度监视无法关闭
	// "vue": "^3.2.13"版本中此处设置可以生效，深度监视能够被关闭
});
```
* `ref`: `ref` 创建的对象是一个 `RefImpl` 实例，它有一个 `.value` 属性，这个 `.value` 属性才是实际的响应式数据。

## 生命周期
* 通过组合式api的形式去使用生命周期钩子
	* **初始化：**setup-beforeMount-mounted
	* **隐藏组件：**beforeUnmount-unmounted
	* **显示组件：**setup-beforeMount-mounted
	* **数据更新：**beforeUpdate-updated
	* **代码更新：**beforeUnmount-setup-beforeMount-unmounted-mounted
* 使用配置项的形式使用生命周期钩子
	* **初始化：**setup-**beforeCreate**-**created**-beforeMount-mounted
	* **隐藏组件：**beforeUnmount-unmounted
	* **显示组件：**setup-**beforeCreate**-**created**-beforeMount-mounted
	* **数据更新：**beforeUpdate-updated
	* **代码更新：**beforeUnmount-setup-**beforeCreate**-**created**-beforeMount-unmounted-mounted
(`setup()`相当于`beforeCreate()`和`created()`)

## Vuex `commit`和`dispatch`
在 Vuex 中，`this.$store.commit` 和 `this.$store.dispatch` 是用于触发状态更改的两种不同方法，但它们具有不同的用途和场景。
1. **this.$store.commit**:
	* **用途**: 直接提交一个 mutation 来更改状态。
	* **何时使用**: 当你想直接更改 Vuex 中的状态时。
	* **注意**: 由于 Vuex 的状态是响应式的，因此状态的更改会触发视图的更新。但是，出于安全考虑，你不能直接更改状态，而是需要提交一个 mutation。Mutation 必须是同步的。
	* **示例**:
	```
	javascript`this.$store.commit('increment', payload);`
	```
	在上面的示例中，我们提交了一个名为 'increment' 的 mutation，并传递了一个 `payload`。
2. **this.$store.dispatch**:
	* **用途**: 触发一个 action。Actions 可以包含任意异步操作，并且最终会通过提交 mutation 来更改状态。
	* **何时使用**: 当你的状态更改逻辑涉及异步操作（如 API 调用）或需要多个 mutation 时。
	* **注意**: Actions 可以是异步的，并且它们可以包含任意复杂的逻辑。但最终的状态更改仍然需要通过提交 mutation 来完成。
	* **示例**:
	```
	javascript`this.$store.dispatch('fetchUser', userId);`
	```
	在上面的示例中，我们触发了一个名为 'fetchUser' 的 action，并传递了一个 `userId`。这个 action 可能会执行一些异步操作（如从 API 获取用户数据），并最终通过提交一个 mutation 来更新状态。
**总结**:
* 如果你只是想直接更改状态，并且不涉及异步操作或复杂逻辑，那么使用 `this.$store.commit`。
* 如果你的状态更改逻辑涉及异步操作或需要多个 mutation，那么使用 `this.$store.dispatch` 来触发一个 action。

## 响应式原理
要正确访问和修改响应式数据，并确保您的代码是响应式的，您应该：
* 确保所有需要响应式的变量或对象都通过 `ref` 或 `reactive` 创建。
* 使用正确的语法来访问和修改这些响应式数据。
* 在组件中使用这些数据，这样当数据变化时，组件会自动重新渲染。
**Vue 2 的响应式原理**
在 Vue 2 中，响应式系统是基于 Object.defineProperty 实现的。当 Vue 实例被创建时，Vue 会遍历 data 对象中的所有属性，并使用 Object.defineProperty 将它们转化为 getter/setter，这样当数据变化时，视图会自动更新。然而，这种方式有几个限制：
1. **无法检测属性的添加或删除**：由于 Vue 2 在实例创建时只处理已存在的属性，对于后来添加的属性，Vue 无法使其变为响应式的。
2. **不能检测数组的变化**：虽然 Vue 2 提供了一些方法来修改数组并触发视图更新（如 push、pop、splice 等），但它不能检测到数组元素的变化或长度的变化。
**Vue 3 的响应式原理**
Vue 3 引入了基于 Proxy 的新响应式系统，这解决了 Vue 2 中存在的一些问题。Proxy 是 ES6 中提供的一个新特性，它可以拦截对象上的各种操作，包括属性的读取、赋值、枚举等。
在 Vue 3 中，当组件的 data 被创建时，Vue 会使用 Proxy 将这个对象包装起来。这样，当数据被访问或修改时，Proxy 的拦截器就会被触发，从而可以追踪数据的变化并通知相关的观察者（通常是组件）。
Vue 3 的响应式系统有以下优点：
1. **可以检测属性的添加或删除**：由于 Proxy 是对整个对象进行拦截，所以即使后来添加了新的属性，Vue 也能使其变为响应式的。
2. **可以检测数组的变化**：Vue 3 不再需要特殊的方法来修改数组，因为 Proxy 可以拦截数组上的任何操作，包括修改元素、改变长度等。
3. **性能优化**：虽然 Proxy 本身可能比 Object.defineProperty 慢一些，但 Vue 3 的响应式系统经过优化，使得在大多数情况下，性能与 Vue 2 相当甚至更好。
此外，Vue 3 还引入了 Composition API，这是一种新的代码组织方式，使逻辑复用更加容易，同时也与响应式系统更加紧密地集成在一起。
总的来说，Vue 3 的响应式系统在处理复杂数据和复杂逻辑时更加灵活和强大，同时也提供了更好的性能和更方便的代码组织方式。

## `reactive` 和 `ref`
* **使用场景**：`reactive` 通常用于处理对象或数组，而 `ref` 更适用于处理基本类型的数据。然而，`ref` 也可以用于处理对象或数组，但这通常是在你需要一个单独的响应式引用时，例如将其传递给一个函数或作为一个单独的 prop 传递。
* **解构与类型**：当使用 `reactive` 创建的响应式对象进行解构时，得到的值将不再是响应式的。而使用 `ref` 创建的响应式引用在解构时，可以通过 `toRefs` 来保持其响应性。此外，`ref` 创建的响应式数据在 TypeScript 中可以保持其类型信息，而 `reactive` 则可能需要额外的类型断言。
* **性能**：在处理大量数据时，`reactive` 通常比 `ref` 更快，因为它直接操作对象属性，而 `ref` 需要通过 `.value` 来访问或修改数据。

## `get` 和 `set`
在 Vue 3 中，计算属性（Computed Properties）的 `get` 和 `set` 方法允许你定义计算属性的读取（getter）和写入（setter）行为。`get` 方法用于返回计算属性的当前值，而 `set` 方法则用于响应计算属性值的设置或更新。
### get 方法
`get` 方法是计算属性的读取器，它定义了当计算属性被访问时应该返回的值。通常情况下，`get` 方法会根据计算属性的依赖项（即响应式数据）来计算并返回一个值。这个值可以是任何类型的数据，比如字符串、数字、对象或数组等。
例如：
```javascript
import { ref, computed } from 'vue';

export default {
  setup() {
    const firstName = ref('John');
    const lastName = ref('Doe');

    const fullName = computed({
      get() {
        return firstName.value + ' ' + lastName.value;
      }
    });

    return {
      firstName,
      lastName,
      fullName
    };
  }
};
```
在上面的代码中，`fullName` 是一个计算属性，其 `get` 方法返回 `firstName` 和 `lastName` 的拼接值。当 `fullName` 被访问时，它会触发 `get` 方法，并返回当前的全名字符串。
### set 方法
`set` 方法是计算属性的写入器，它定义了当计算属性的值被设置或更新时应该执行的操作。在 Vue 3 的计算属性中，你可以提供一个 `set` 方法来监听计算属性的赋值操作，并在这个方法中执行自定义的逻辑。
例如，你可能想要在用户尝试设置 `fullName` 时，自动更新 `firstName` 和 `lastName`：
```javascript
import { ref, computed } from 'vue';

export default {
  setup() {
    const firstName = ref('John');
    const lastName = ref('Doe');

    const fullName = computed({
      get() {
        return firstName.value + ' ' + lastName.value;
      },
      set(newValue) {
        const names = newValue.split(' ');
        firstName.value = names[0];
        lastName.value = names.pop(); // 使用 pop() 来获取最后一个元素，并移除它
      }
    });

    return {
      firstName,
      lastName,
      fullName
    };
  }
};
```
在这个例子中，当用户尝试设置 `fullName` 的值时，`set` 方法会被调用。它接收一个 `newValue` 参数，然后将其分割为名字和姓氏，并分别更新 `firstName` 和 `lastName` 的值。这样，当用户通过某种方式（比如表单输入）设置 `fullName` 时，`firstName` 和 `lastName` 也会相应地更新。
需要注意的是，当计算属性依赖于其他响应式数据时，这些依赖数据的变化会自动触发计算属性的重新计算（通过 `get` 方法）。然而，当计算属性本身被赋值时，只有提供了 `set` 方法的情况下，这个赋值操作才会被处理。如果没有提供 `set` 方法，尝试设置计算属性的值将会导致一个警告或错误。

## Vue 3 同名对象toRef
```js
// nameToRef: toRef(person, "name"),
// ...toRefs(person),
const { name: nameRef1 } = toRefs(person);  
const { name: nameRef2 } = toRefs(person2);
```

## Vue 3 `Suspense`
Vue 3中的Suspense组件主要用于处理异步组件和延迟加载，提供了一种更简洁和直观的方式来管理这些异步操作的状态。其主要功能和用途包括：
1. **占位符显示**：在异步组件加载完成前，Suspense允许开发者定义一个占位符，如“Loading...”，以提供更好的用户体验。
2. **异步组件加载**：当使用异步组件时，Suspense允许开发者定义一个加载状态，直到该组件可用。
3. **异步数据获取**：对于需要异步获取数据的组件，Suspense可以等待数据加载完成后再渲染组件。
4. **懒加载组件**：在应用中使用懒加载技术时，Suspense可以提供一个加载指示器，告诉用户内容正在加载中。
使用Suspense的基本步骤包括使用`<Suspense>`标签包裹异步组件，并在其中定义`default`和`fallback`插槽。`default`插槽用于放置异步组件，而`fallback`插槽则用于放置加载中的占位符。
需要注意的是，Suspense组件只能包含一个异步组件，`fallback`插槽中的内容只能是一个单独的元素，且异步组件必须通过`defineAsyncComponent`方法定义。

# MySQL

## MySQL介绍
* SQL需要与数据库管理系统（DBMS）一起使用，DBMS负责管理数据库，SQL则用于与数据库进行交互

## MySQL快速入门
* 常见的 MySQL 数据类型：
  > INT: 整数类型，可存储范围为-2147483648到2147483647的整数 \
  > VARCHAR: 可变长度字符串类型，可存储最大长度为65535个字符的字符串 \
  > CHAR: 定长字符串类型，可存储最大长度为255个字符的字符串 \
  > DECIMAL: 定点数类型，可存储精度高达65个数字的小数 \
  > DATE: 日期类型，存储年、月、日信息 \
  > DATETIME: 日期时间类型，存储年、月、日、时、分、秒信息，如“2023-03-23 10:30:00” \
  > TIMESTAMP: 时间戳类型，存储时间戳信息

## MySQL介绍

### 环境配置
* `G:`
* `cd G:\NiHon-IT-Training-Plan\MySQL`
* `docker compose -f './docker compose.yaml' up -d`
```
[+] Running 11/11
✔ mysql 10 layers [⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿]      0B/0B      Pulled                                          24.7s 
✔ 558b7d69a2e5 Pull complete                                                                  4.7s 
✔ b85878fb9bb2 Pull complete                                                                  1.6s 
✔ d16f3fd26a82 Pull complete                                                                  4.1s 
✔ afd51b5329cb Pull complete                                                                  3.2s 
✔ 374d2f7f3267 Pull complete                                                                  4.5s 
✔ 4ea1bb2c9574 Pull complete                                                                  9.5s 
✔ 1c9054053605 Pull complete                                                                  6.0s 
✔ d79cd2da03be Pull complete                                                                 14.9s 
✔ e3a1aa788d17 Pull complete                                                                  7.5s 
[+] Running 2/2
✔ Network mysql_default    Created                                                              0.0s 
✔ Container mysql-mysql-1  Started                                                              0.2s
```
* `docker ps`
```
CONTAINER ID   IMAGE          COMMAND                   CREATED              STATUS              PORTS                               NAMES
c6471e03b8f8   mysql:latest   "docker-entrypoint.s…"   About a minute ago   Up About a minute   0.0.0.0:3306->3306/tcp, 33060/tcp   mysql-mysql-1
```
* `docker exec -it c6471e03b8f8 bash`
```
bash-4.4# ...
```
* `mysql -V`
```
mysql  Ver 8.3.0 for Linux on x86_64 (MySQL Community Server - GPL)
```

### 数据库连接
* `mysql -u root -p`
```
Enter password: 12345678
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 10
Server version: 8.3.0 MySQL Community Server - GPL

Copyright (c) 2000, 2024, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> ...
```
* `select version();`
```
+-----------+
| version() |
+-----------+
| 8.3.0     |
+-----------+
1 row in set (0.00 sec)
```
* `show databases;`
```
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| root               |
| sys                |
+--------------------+
5 rows in set (0.01 sec)
```

### 数据库创建
* `create database mydatabase;`
```
Query OK, 1 row affected (0.00 sec)
```
* `show databases;`
```
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydatabase         |
| mysql              |
| performance_schema |
| root               |
| sys                |
+--------------------+
6 rows in set (0.00 sec)
```
* `drop database mydatabase;`
```
Query OK, 0 rows affected (0.00 sec)
```
* `show databases;`
```
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| root               |
| sys                |
+--------------------+
5 rows in set (0.00 sec)
```
* `create database mydatabase;`
```
Query OK, 1 row affected (0.01 sec)
```

### 数据表创建
* `use mydatabase;`
```
Database changed
```
* `create table customers (id int primary key, name varchar(255), email varchar(255));`
```
Query OK, 0 rows affected (0.01 sec)
```
* `desc customers;`
```
+-------+--------------+------+-----+---------+-------+
| Field | Type         | Null | Key | Default | Extra |
+-------+--------------+------+-----+---------+-------+
| id    | int          | NO   | PRI | NULL    |       |
| name  | varchar(255) | YES  |     | NULL    |       |
| email | varchar(255) | YES  |     | NULL    |       |
+-------+--------------+------+-----+---------+-------+
3 rows in set (0.00 sec)
```
* `drop table customers;`
```
Query OK, 0 rows affected (0.01 sec)
```

### 数据插入
```sql
create table customers (
-> id int primary key,
-> name varchar(255),
-> email varchar(255)
-> );
```
```
Query OK, 0 rows affected (0.01 sec)
```
```sql
INSERT INTO customers (id, name, email)
-> VALUES (1, 'JOHN', 'john@test.com');
```
```
Query OK, 1 row affected (0.00 sec)
```
```sql
INSERT INTO customers (id, name, email) VALUES (1, 'JOHN2', 'john2@test.com');
```
```
ERROR 1062 (23000): Duplicate entry '1' for key 'customers.PRIMARY'
```
```sql
INSERT INTO customers (id, name, email) VALUES (2, 'JOHN', 'john@test.com');
```
```
Query OK, 1 row affected (0.00 sec)
```
```sql
INSERT INTO customers (id, name, email) VALUES (null, 'JOHN2', 'john2@test.com');
```
```
ERROR 1048 (23000): Column 'id' cannot be null
```

### 数据查询
```sql
SELECT * FROM customers;
```
```
+----+------+---------------+
| id | name | email         |
+----+------+---------------+
|  1 | JOHN | john@test.com |
|  2 | JOHN | john@test.com |
+----+------+---------------+
2 rows in set (0.00 sec)
```
```sql
SELECT name, email FROM customers;
```
```
+------+---------------+
| name | email         |
+------+---------------+
| JOHN | john@test.com |
| JOHN | john@test.com |
+------+---------------+
2 rows in set (0.00 sec)
```
```sql
SELECT name, email FROM customers WHERE id = 1;
```
```
+------+---------------+
| name | email         |
+------+---------------+
| JOHN | john@test.com |
+------+---------------+
1 row in set (0.00 sec)
```

### 数据更新
```sql
UPDATE customers SET email = 'test@test.com' WHERE name = 'John';
```
```
Query OK, 2 rows affected (0.01 sec)
Rows matched: 2  Changed: 2  Warnings: 0
```

### 数据删除
```sql
DELETE FROM customers WHERE name = 'John';
```
```
Query OK, 2 rows affected (0.00 sec)
```

### 事务
```sql
CREATE TABLE accounts (
  id INT PRIMARY KEY,
  name VARCHAR(50),
  balance DECIMAL(10,2)
);
```
```
Query OK, 0 rows affected (0.01 sec)
```
```sql
DESC accounts;
```
```
+---------+---------------+------+-----+---------+-------+
| Field   | Type          | Null | Key | Default | Extra |
+---------+---------------+------+-----+---------+-------+
| id      | int           | NO   | PRI | NULL    |       |
| name    | varchar(50)   | YES  |     | NULL    |       |
| balance | decimal(10,2) | YES  |     | NULL    |       |
+---------+---------------+------+-----+---------+-------+
3 rows in set (0.00 sec)
```
```sql
INSERT INTO accounts (id, name, balance) VALUES (1, 'name1', '1000');
SELECT * FROM accounts;
```
```
+----+-------+---------+
| id | name  | balance |
+----+-------+---------+
|  1 | name1 | 1000.00 |
+----+-------+---------+
```
```sql
UPDATE accounts SET balance = 100000000 WHERE id = 1;
SELECT * FROM accounts;
```
```
+----+-------+---------+
| id | name  | balance |
+----+-------+---------+
|  1 | name1 | 1000.00 |
+----+-------+---------+
```
```sql
UPDATE accounts SET balance = 10000000 WHERE id = 1;
SELECT * FROM accounts;
```
```
+----+-------+-------------+
| id | name  | balance     |
+----+-------+-------------+
|  1 | name1 | 10000000.00 |
+----+-------+-------------+
```
```sql
INSERT INTO accounts (id, name, balance) VALUES (2, 'name2', '1000');
SELECT * FROM accounts;
```
```
+----+-------+-------------+
| id | name  | balance     |
+----+-------+-------------+
|  1 | name1 | 10000000.00 |
|  2 | name2 |     1000.00 |
+----+-------+-------------+
```
```sql
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
SELECT * FROM accounts
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
SELECT * FROM accounts;
```
```
+----+-------+------------+
| id | name  | balance    |
+----+-------+------------+
|  1 | name1 | 9999900.00 |
|  2 | name2 |    1000.00 |
+----+-------+------------+
```
```sql
UPDATE accounts SET balance = 1000;
SELECT * FROM accounts;
START TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
SELECT * FROM accounts;
UPDATE accounts SET balence = balance + 100 WHERE id = 2;
SELECT * FROM accounts;
ROLLBACK;
SELECT * FROM accounts;
```
```
+----+-------+---------+
| id | name  | balance |
+----+-------+---------+
|  1 | name1 | 1000.00 |
|  2 | name2 | 1000.00 |
+----+-------+---------+
```
```sql
UPDATE accounts SET balance = 1000;
SELECT * FROM accounts;
START TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
SELECT * FROM accounts;
UPDATE accounts SET balence = balance + 100 WHERE id = 2;
SELECT * FROM accounts;
COMMIT;
SELECT * FROM accounts;
```
```
+----+-------+---------+
| id | name  | balance |
+----+-------+---------+
|  1 | name1 |  900.00 |
|  2 | name2 | 1000.00 |
+----+-------+---------+
```

## 表设计-表列约束和默认值

### NOT NULL
```sql
CREATE TABLE `mytable` (
  `id` INT(11) NOT NULL,
  `name` VARCHAR(50) NOT NULL,
  `age` INT(11) DEFAULT NULL
);
DESC mytable;
```
```
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int         | NO   |     | NULL    |       |
| name  | varchar(50) | NO   |     | NULL    |       |
| age   | int         | YES  |     | NULL    |       |
+-------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO mytable (id, name, age) VALUES (1, 'name1', null);
INSERT INTO mytable (id, name, age) VALUES (null, 'name2', null);
SELECT * FROM mytable;
DROP TABLE mytable;
```
```
Query OK, 1 row affected (0.00 sec)
ERROR 1048 (23000): Column 'id' cannot be null
+----+-------+------+
| id | name  | age  |
+----+-------+------+
|  1 | name1 | NULL |
+----+-------+------+
1 row in set (0.00 sec)
Query OK, 0 rows affected (0.01 sec)
```

### PRIMARY KEY
* 主键是一列或一组列，值不能重复且不能为NULL
```sql
CREATE TABLE `mytable` (
  `id` INT(11) NOT NULL PRIMARY KEY,
  `name` VARCHAR(50) NOT NULL,
  `age` INT(11) DEFAULT NULL
);
DESC mytable;
```
```
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int         | NO   | PRI | NULL    |       |
| name  | varchar(50) | NO   |     | NULL    |       |
| age   | int         | YES  |     | NULL    |       |
+-------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO mytable (id, name, age) VALUES (1, 'name1', null);
INSERT INTO mytable (id, name, age) VALUES (1, 'name2', null);
SELECT * FROM mytable;
DROP TABLE mytable;
```
```
Query OK, 1 row affected (0.01 sec)
ERROR 1062 (23000): Duplicate entry '1' for key 'mytable.PRIMARY'
+----+-------+------+
| id | name  | age  |
+----+-------+------+
|  1 | name1 | NULL |
+----+-------+------+
1 row in set (0.00 sec)
Query OK, 0 rows affected (0.01 sec)
```

### UNIQUE
* 与主键不同，可以包含NULL值
```sql
CREATE TABLE `mytable` (
  `id` INT(11) NOT NULL PRIMARY KEY,
  `name` VARCHAR(50) NOT NULL UNIQUE,
  `age` int(50) UNIQUE
);
DESC mytable;
```
```
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int         | NO   | PRI | NULL    |       |
| name  | varchar(50) | NO   | UNI | NULL    |       |
| age   | int         | YES  | UNI | NULL    |       |
+-------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO mytable (id, name, age) VALUES (1, 'name1', null);
INSERT INTO mytable (id, name, age) VALUES (2, 'name1', 18);
INSERT INTO mytable (id, name, age) VALUES (2, 'name2', null);
SELECT * FROM mytable;
DROP TABLE mytable;
```
```
Query OK, 1 row affected (0.00 sec)
ERROR 1062 (23000): Duplicate entry 'name1' for key 'mytable.name'
Query OK, 1 row affected (0.00 sec)
+----+-------+------+
| id | name  | age  |
+----+-------+------+
|  1 | name1 | NULL |
|  2 | name2 | NULL |
+----+-------+------+
2 rows in set (0.00 sec)
Query OK, 0 rows affected (0.01 sec)
```

### FOREIGN KEY
* 外键约束，用于实现表之间关系的约束
* 外键是一个指向另一个表中的列的列，确保了两个表之间的数据的一致性
* 它指定的值必须存在于另一个表中的主键或唯一键列中
```sql
CREATE TABLE `customers` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `email` varchar(50) NOT NULL UNIQUE
);
DESC customers;
CREATE TABLE `orders` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `product_name` varchar(50) NOT NULL,
  `customer_id` int(11) NOT NULL,
  FOREIGN KEY (`customer_id`) REFERENCES `customers`(`id`)
);
DESC orders;
```
```
+-------+--------------+------+-----+---------+-------+
| Field | Type         | Null | Key | Default | Extra |
+-------+--------------+------+-----+---------+-------+
| id    | int          | NO   | PRI | NULL    |       |
| name  | varchar(255) | YES  |     | NULL    |       |
| email | varchar(255) | YES  |     | NULL    |       |
+-------+--------------+------+-----+---------+-------+
+--------------+-------------+------+-----+---------+-------+
| Field        | Type        | Null | Key | Default | Extra |
+--------------+-------------+------+-----+---------+-------+
| id           | int         | NO   | PRI | NULL    |       |
| product_name | varchar(50) | NO   |     | NULL    |       |
| customer_id  | int         | NO   | MUL | NULL    |       |
+--------------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO customers (id, name, email) VALUES (1, 'name1', 'email1');
INSERT INTO customers (id, name, email) VALUES (2, 'name2', 'email2');
INSERT INTO customers (id, name, email) VALUES (3, 'name3', 'email3');
SELECT * FROM customers;

INSERT INTO orders (id, product_name, customer_id) VALUES (1, 'product_name1', '1');
INSERT INTO orders (id, product_name, customer_id) VALUES (2, 'product_name2', '1');
INSERT INTO orders (id, product_name, customer_id) VALUES (3, 'product_name3', '2');
INSERT INTO orders (id, product_name, customer_id) VALUES (4, 'product_name4', '4');
SELECT * FROM orders;

DROP TABLE customers;
DROP TABLE orders;
DROP TABLE customers;
```
```
Query OK, 1 row affected (0.00 sec)
Query OK, 1 row affected (0.00 sec)
Query OK, 1 row affected (0.00 sec)
+----+-------+--------+
| id | name  | email  |
+----+-------+--------+
|  1 | name1 | email1 |
|  2 | name2 | email2 |
|  3 | name3 | email3 |
+----+-------+--------+
3 rows in set (0.00 sec)

Query OK, 1 row affected (0.00 sec)
Query OK, 1 row affected (0.00 sec)
Query OK, 1 row affected (0.01 sec)
ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`mydatabase`.`orders`, CONSTRAINT `orders_ibfk_1` FOREIGN KEY (`customer_id`) REFERENCES `customers` (`id`))
+----+---------------+-------------+
| id | product_name  | customer_id |
+----+---------------+-------------+
|  1 | product_name1 |           1 |
|  2 | product_name2 |           1 |
|  3 | product_name3 |           2 |
+----+---------------+-------------+
3 rows in set (0.00 sec)

ERROR 3730 (HY000): Cannot drop table 'customers' referenced by a foreign key constraint 'orders_ibfk_1' on table 'orders'.
Query OK, 0 rows affected (0.02 sec)
Query OK, 0 rows affected (0.01 sec)
```

### DEFAULT
```sql
CREATE TABLE `mytable` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `age` int(11) NOT NULL DEFAULT 18
);
DESC mytable;
```
```
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int         | NO   | PRI | NULL    |       |
| name  | varchar(50) | NO   |     | NULL    |       |
| age   | int         | NO   |     | 18      |       |
+-------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO mytable (id, name) VALUES (1, 'name1');
INSERT INTO mytable (id, name) VALUES (2, 'name2');
SELECT * FROM mytable;
DROP TABLE mytable;
```
```
Query OK, 1 row affected (0.01 sec)
Query OK, 1 row affected (0.01 sec)
+----+-------+-----+
| id | name  | age |
+----+-------+-----+
|  1 | name1 |  18 |
|  2 | name2 |  18 |
+----+-------+-----+
2 rows in set (0.00 sec)
Query OK, 0 rows affected (0.01 sec)
```

### CHECK
* 列约束，用于定义一个表达式，该表达式在插入或更新数据时必须为真
* 只能在MySQL 8.0版本及以上的版本中使用
```sql
CREATE TABLE `mytable` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `age` int(11) NOT NULL,
  `gender` varchar(10) NOT NULL,
  CHECK (age > 0 AND gender IN ('male', 'female'))
);
DESC mytable;
```
```
+--------+-------------+------+-----+---------+-------+
| Field  | Type        | Null | Key | Default | Extra |
+--------+-------------+------+-----+---------+-------+
| id     | int         | NO   | PRI | NULL    |       |
| name   | varchar(50) | NO   |     | NULL    |       |
| age    | int         | NO   |     | NULL    |       |
| gender | varchar(10) | NO   |     | NULL    |       |
+--------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO mytable (id, name, age, gender) VALUES (1, 'name1', '18', 'male');
INSERT INTO mytable (id, name, age, gender) VALUES (2, 'name2', '0', 'male');
INSERT INTO mytable (id, name, age, gender) VALUES (3, 'name3', '18', 'male1');
SELECT * FROM mytable;
DROP TABLE mytable;
```
```
Query OK, 1 row affected (0.00 sec)
ERROR 3819 (HY000): Check constraint 'mytable_chk_1' is violated.
ERROR 3819 (HY000): Check constraint 'mytable_chk_1' is violated.
+----+-------+-----+--------+
| id | name  | age | gender |
+----+-------+-----+--------+
|  1 | name1 |  18 | male   |
+----+-------+-----+--------+
1 row in set (0.00 sec)
Query OK, 0 rows affected (0.01 sec)
```

## 表设计-数据表关系设计

### 一对一关系
* 一对一关系指的是两个表之间的一种关系，其中一个表的每个记录都只能对应另一个表中的一条记录
* 在一个一对一关系中，一个表中的主键通常也是另一个表中的外键
```sql
CREATE TABLE `person` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `address` varchar(100) NOT NULL
);
DESC person;
CREATE TABLE `contact_info` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `email` varchar(50) NOT NULL UNIQUE,
  `phone` varchar(20) NOT NULL UNIQUE,
  `person_id` int(11) NOT NULL UNIQUE,
  FOREIGN KEY (`person_id`) REFERENCES `person` (`id`)
);
DESC contact_info;
```
```
+---------+--------------+------+-----+---------+-------+
| Field   | Type         | Null | Key | Default | Extra |
+---------+--------------+------+-----+---------+-------+
| id      | int          | NO   | PRI | NULL    |       |
| name    | varchar(50)  | NO   |     | NULL    |       |
| address | varchar(100) | NO   |     | NULL    |       |
+---------+--------------+------+-----+---------+-------+
+-----------+-------------+------+-----+---------+-------+
| Field     | Type        | Null | Key | Default | Extra |
+-----------+-------------+------+-----+---------+-------+
| id        | int         | NO   | PRI | NULL    |       |
| email     | varchar(50) | NO   | UNI | NULL    |       |
| phone     | varchar(20) | NO   | UNI | NULL    |       |
| person_id | int         | NO   | UNI | NULL    |       |
+-----------+-------------+------+-----+---------+-------+
```
```sql
INSERT INTO person (id, name, address) VALUES (1, 'name1', 'add1');
INSERT INTO person (id, name, address) VALUES (2, 'name2', 'add2');
INSERT INTO person (id, name, address) VALUES (3, 'name3', 'add3');
SELECT * FROM person;

INSERT INTO contact_info (id, email, phone, person_id) VALUES (5, 'email1', 'phone1', '1');
INSERT INTO contact_info (id, email, phone, person_id) VALUES (4, 'email2', 'phone2', '2');
INSERT INTO contact_info (id, email, phone, person_id) VALUES (3, 'email3', 'phone3', '3');
INSERT INTO contact_info (id, email, phone, person_id) VALUES (2, 'email4', 'phone4', '4');
INSERT INTO contact_info (id, email, phone, person_id) VALUES (1, 'email5', 'phone5', '2');
SELECT * FROM contact_info;

SELECT * FROM person p JOIN contact_info c ON p.id = c.person_id;

DROP TABLE contact_info;
DROP TABLE person;
```
```
+----+-------+---------+
| id | name  | address |
+----+-------+---------+
|  1 | name1 | add1    |
|  2 | name2 | add2    |
|  3 | name3 | add3    |
+----+-------+---------+
+----+--------+--------+-----------+
| id | email  | phone  | person_id |
+----+--------+--------+-----------+
|  3 | email3 | phone3 |         3 |
|  4 | email2 | phone2 |         2 |
|  5 | email1 | phone1 |         1 |
+----+--------+--------+-----------+
+----+-------+---------+----+--------+--------+-----------+
| id | name  | address | id | email  | phone  | person_id |
+----+-------+---------+----+--------+--------+-----------+
|  1 | name1 | add1    |  5 | email1 | phone1 |         1 |
|  2 | name2 | add2    |  4 | email2 | phone2 |         2 |
|  3 | name3 | add3    |  3 | email3 | phone3 |         3 |
+----+-------+---------+----+--------+--------+-----------+
```

### 一对多关系
* 一对多关系指的是一个表中的每个记录都可以对应另一个表中的多条记录，但另一个表中的每个记录只能对应一个表中的记录
* 对于一对多关系，通常情况下不需要使用中间表
* 在一个一对多关系中，一个表中的主键通常也是另一个表中的外键
```sql
CREATE TABLE `customer` (
  `id` int NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `email` varchar(50) NOT NULL UNIQUE
);
DESC customer;
CREATE TABLE `order` (
  `id` int NOT NULL PRIMARY KEY,
  `order_date` datetime NOT NULL,
  `amount` decimal(10, 2) NOT NULL,
  `customer_id` int NOT NULL,
  FOREIGN KEY (`customer_id`) REFERENCES `customer` (`id`)
);
DESC `order`;
```
```
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int         | NO   | PRI | NULL    |       |
| name  | varchar(50) | NO   |     | NULL    |       |
| email | varchar(50) | NO   | UNI | NULL    |       |
+-------+-------------+------+-----+---------+-------+
+-------------+---------------+------+-----+---------+-------+
| Field       | Type          | Null | Key | Default | Extra |
+-------------+---------------+------+-----+---------+-------+
| id          | int           | NO   | PRI | NULL    |       |
| order_date  | datetime      | NO   |     | NULL    |       |
| amount      | decimal(10,2) | NO   |     | NULL    |       |
| customer_id | int           | NO   | MUL | NULL    |       |
+-------------+---------------+------+-----+---------+-------+
```
```sql
INSERT INTO customer (id, name, email) VALUES (1, 'name1', 'email1');
INSERT INTO customer (id, name, email) VALUES (2, 'name2', 'email2');
INSERT INTO customer (id, name, email) VALUES (3, 'name3', 'email3');
SELECT * FROM customer;

INSERT INTO `order` (id, order_date, amount, customer_id) VALUES (1, '2024-04-04 22:09', 111, 1);
INSERT INTO `order` (id, order_date, amount, customer_id) VALUES (2, '2024-04-04 22:10', 222, 1);
INSERT INTO `order` (id, order_date, amount, customer_id) VALUES (3, '2024-04-04 22:11', 333, 2);
SELECT * FROM `order`;

SELECT * FROM customer c JOIN `order` o ON c.id = o.customer_id;

DROP TABLE `order`;
DROP TABLE customer;
```
```
+----+-------+--------+
| id | name  | email  |
+----+-------+--------+
|  1 | name1 | email1 |
|  2 | name2 | email2 |
|  3 | name3 | email3 |
+----+-------+--------+
+----+---------------------+--------+-------------+
| id | order_date          | amount | customer_id |
+----+---------------------+--------+-------------+
|  1 | 2024-04-04 22:09:00 | 111.00 |           1 |
|  2 | 2024-04-04 22:10:00 | 222.00 |           1 |
|  3 | 2024-04-04 22:11:00 | 333.00 |           2 |
+----+---------------------+--------+-------------+
+----+-------+--------+----+---------------------+--------+-------------+
| id | name  | email  | id | order_date          | amount | customer_id |
+----+-------+--------+----+---------------------+--------+-------------+
|  1 | name1 | email1 |  1 | 2024-04-04 22:09:00 | 111.00 |           1 |
|  1 | name1 | email1 |  2 | 2024-04-04 22:10:00 | 222.00 |           1 |
|  2 | name2 | email2 |  3 | 2024-04-04 22:11:00 | 333.00 |           2 |
+----+-------+--------+----+---------------------+--------+-------------+
```

### 多对多关系
* 多对多关系指的是一个表中的每个记录可以对应另一个表中的多条记录，反之亦然
* 在一个多对多关系中，通常需要使用一个中间表来跟踪两个表之间的关系；中间表中包含两个表的主键，这些主键共同作为中间表的复合主键
```sql
CREATE TABLE `student` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `email` varchar(50) NOT NULL UNIQUE
);
DESC student;
CREATE TABLE `course` (
  `id` int(11) NOT NULL PRIMARY KEY,
  `name` varchar(50) NOT NULL,
  `teacher` varchar(50) NOT NULL
);
DESC course;
CREATE TABLE `enrollment` (
  `student_id` int(11) NOT NULL,
  `course_id` int(11) NOT NULL,
  PRIMARY KEY (`student_id`, `course_id`),
  FOREIGN KEY (`student_id`) REFERENCES `student` (`id`),
  FOREIGN KEY (`course_id`) REFERENCES `course` (`id`)
);
DESC enrollment;
```
```
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int         | NO   | PRI | NULL    |       |
| name  | varchar(50) | NO   |     | NULL    |       |
| email | varchar(50) | NO   | UNI | NULL    |       |
+-------+-------------+------+-----+---------+-------+
+---------+-------------+------+-----+---------+-------+
| Field   | Type        | Null | Key | Default | Extra |
+---------+-------------+------+-----+---------+-------+
| id      | int         | NO   | PRI | NULL    |       |
| name    | varchar(50) | NO   |     | NULL    |       |
| teacher | varchar(50) | NO   |     | NULL    |       |
+---------+-------------+------+-----+---------+-------+
+------------+------+------+-----+---------+-------+
| Field      | Type | Null | Key | Default | Extra |
+------------+------+------+-----+---------+-------+
| student_id | int  | NO   | PRI | NULL    |       |
| course_id  | int  | NO   | PRI | NULL    |       |
+------------+------+------+-----+---------+-------+
```
```sql
INSERT INTO student (id, name, email) VALUES (1, 'student1', 'email1');
INSERT INTO student (id, name, email) VALUES (2, 'student2', 'email2');
INSERT INTO student (id, name, email) VALUES (3, 'student3', 'email3');
SELECT * FROM student;

INSERT INTO course (id, name, teacher) VALUES (1, 'course1', 'teacher1');
INSERT INTO course (id, name, teacher) VALUES (2, 'course2', 'teacher2');
INSERT INTO course (id, name, teacher) VALUES (3, 'course3', 'teacher2');
SELECT * FROM course;

INSERT INTO enrollment (student_id, course_id) VALUES (1, 1);
INSERT INTO enrollment (student_id, course_id) VALUES (1, 2);
INSERT INTO enrollment (student_id, course_id) VALUES (2, 2);
INSERT INTO enrollment (student_id, course_id) VALUES (2, 3);
INSERT INTO enrollment (student_id, course_id) VALUES (3, 1);
SELECT * FROM enrollment;

SELECT * FROM student s LEFT JOIN enrollment e ON s.id = e.student_id LEFT JOIN course c ON c.id = e.course_id;

DROP TABLE enrollment;
DROP TABLE student;
DROP TABLE course;
```
```
+----+----------+--------+
| id | name     | email  |
+----+----------+--------+
|  1 | student1 | email1 |
|  2 | student2 | email2 |
|  3 | student3 | email3 |
+----+----------+--------+
+----+---------+----------+
| id | name    | teacher  |
+----+---------+----------+
|  1 | course1 | teacher1 |
|  2 | course2 | teacher2 |
|  3 | course3 | teacher2 |
+----+---------+----------+
+------------+-----------+
| student_id | course_id |
+------------+-----------+
|          1 |         1 |
|          3 |         1 |
|          1 |         2 |
|          2 |         2 |
|          2 |         3 |
+------------+-----------+
+----+----------+--------+------------+-----------+------+---------+----------+
| id | name     | email  | student_id | course_id | id   | name    | teacher  |
+----+----------+--------+------------+-----------+------+---------+----------+
|  1 | student1 | email1 |          1 |         1 |    1 | course1 | teacher1 |
|  1 | student1 | email1 |          1 |         2 |    2 | course2 | teacher2 |
|  2 | student2 | email2 |          2 |         2 |    2 | course2 | teacher2 |
|  2 | student2 | email2 |          2 |         3 |    3 | course3 | teacher2 |
|  3 | student3 | email3 |          3 |         1 |    1 | course1 | teacher1 |
+----+----------+--------+------------+-----------+------+---------+----------+
```

## 多表联查-多表连接查询的语法
* **SELECT**用于指定需要查询的列
* **FROM**用于指定查询的表格
* **JOIN**用于指定需要连接的表格和连接条件
* **ON**用于指定连接条件，它指定了哪些列用于连接两个表格
```sql
SELECT column_name(s)
FROM table1
JOIN table2 ON condition
```

## 多表联查-多表连接查询的常用方式
* **INNER JOIN**返回两个表格中符合连接条件的记录
* **LEFT JOIN**返回左表格中的所有记录，以及右表格中符合连接条件的记录
* **RIGHT JOIN**返回右表格中的所有记录，以及左表格中符合连接条件的记录
* **FULL OUTER JOIN**返回左表格和右表格中所有的记录，以及符合连接条件的记录（MySQL不直接支持，但也有实现方式）
* 注意：
  * **连接条件必须唯一**连接条件必须是唯一的，否则会导致多个记录匹配，从而影响查询结果
  * **数据库中的表格必须有共同的字段**多个表格需要连接时，这些表格必须有至少一个共同的字段，才能进行连接查询
  * **选择适当的连接方式**不同的连接方式适用于不同的场景，需要根据具体情况选择适当的连接方式
```sql
CREATE TABLE Customers (
  CustomerID int(11) NOT NULL,
  CustomerName varchar(255) NOT NULL,
  ContactName varchar(255) NOT NULL,
  Country varchar(255) NOT NULL
);
INSERT INTO Customers (CustomerID, CustomerName, ContactName, Country) VALUES
(1, 'Alfreds', 'Maria', 'Germany'),
(2, 'Ana', 'Trujillo', 'Mexico'),
(3, 'Antonio', 'Moreno', 'Mexico'),
(4, 'Around', 'Hardy', 'UK'),
(5, 'Berglunds', 'Berglund', 'Sweden');
DESC Customers;
SELECT * FROM Customers;

CREATE TABLE Orders (
  OrderID int(11) NOT NULL,
  CustomerID int(11) NOT NULL,
  OrderDate date NOT NULL,
  ShipCity varchar(255) NOT NULL
);
INSERT INTO Orders (OrderID, CustomerID, OrderDate, ShipCity) VALUES
(1, 3, '2023-01-01', 'México D.F.'),
(2, 5, '2023-01-02', 'Luleå'),
(3, 1, '2023-01-03', 'Berlin'),
(4, 2, '2023-01-04', 'México D.F.'),
(5, 4, '2023-01-05', 'London');
DESC Orders;
SELECT * FROM Orders;
```
```
+--------------+--------------+------+-----+---------+-------+
| Field        | Type         | Null | Key | Default | Extra |
+--------------+--------------+------+-----+---------+-------+
| CustomerID   | int          | NO   |     | NULL    |       |
| CustomerName | varchar(255) | NO   |     | NULL    |       |
| ContactName  | varchar(255) | NO   |     | NULL    |       |
| Country      | varchar(255) | NO   |     | NULL    |       |
+--------------+--------------+------+-----+---------+-------+
+------------+--------------+-------------+---------+
| CustomerID | CustomerName | ContactName | Country |
+------------+--------------+-------------+---------+
|          1 | Alfreds      | Maria       | Germany |
|          2 | Ana          | Trujillo    | Mexico  |
|          3 | Antonio      | Moreno      | Mexico  |
|          4 | Around       | Hardy       | UK      |
|          5 | Berglunds    | Berglund    | Sweden  |
+------------+--------------+-------------+---------+

+------------+--------------+------+-----+---------+-------+
| Field      | Type         | Null | Key | Default | Extra |
+------------+--------------+------+-----+---------+-------+
| OrderID    | int          | NO   |     | NULL    |       |
| CustomerID | int          | NO   |     | NULL    |       |
| OrderDate  | date         | NO   |     | NULL    |       |
| ShipCity   | varchar(255) | NO   |     | NULL    |       |
+------------+--------------+------+-----+---------+-------+
+---------+------------+------------+------------+
| OrderID | CustomerID | OrderDate  | ShipCity   |
+---------+------------+------------+------------+
|       1 |          3 | 2023-01-01 | Mxico D.F. |
|       2 |          5 | 2023-01-02 | Lule       |
|       3 |          1 | 2023-01-03 | Berlin     |
|       4 |          2 | 2023-01-04 | Mxico D.F. |
|       5 |          4 | 2023-01-05 | London     |
+---------+------------+------------+------------+
```

### INNER JOIN
* 内连接（INNER JOIN）是多表连接查询中最常用的方式，它返回两个表格中符合连接条件的记录
```sql
SELECT Orders.OrderID, Customers.CustomerName 
FROM Orders
INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID;
```
```
+---------+--------------+
| OrderID | CustomerName |
+---------+--------------+
|       3 | Alfreds      |
|       4 | Ana          |
|       1 | Antonio      |
|       5 | Around       |
|       2 | Berglunds    |
+---------+--------------+
```
```sql
SELECT Orders.*, Customers.*
FROM Orders
INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID;
```
```
+---------+------------+------------+------------+------------+--------------+-------------+---------+
| OrderID | CustomerID | OrderDate  | ShipCity   | CustomerID | CustomerName | ContactName | Country |
+---------+------------+------------+------------+------------+--------------+-------------+---------+
|       3 |          1 | 2023-01-03 | Berlin     |          1 | Alfreds      | Maria       | Germany |
|       4 |          2 | 2023-01-04 | Mxico D.F. |          2 | Ana          | Trujillo    | Mexico  |
|       1 |          3 | 2023-01-01 | Mxico D.F. |          3 | Antonio      | Moreno      | Mexico  |
|       5 |          4 | 2023-01-05 | London     |          4 | Around       | Hardy       | UK      |
|       2 |          5 | 2023-01-02 | Lule       |          5 | Berglunds    | Berglund    | Sweden  |
+---------+------------+------------+------------+------------+--------------+-------------+---------+
```

### LEFT JOIN
* 左连接（LEFT JOIN）返回左表格中的所有记录，以及右表格中符合连接条件的记录
```sql
SELECT Customers.CustomerName, Orders.OrderID
FROM Customers
LEFT JOIN Orders ON Customers.CustomerID = Orders.CustomerID;
```
```
+--------------+---------+
| CustomerName | OrderID |
+--------------+---------+
| Alfreds      |       3 |
| Ana          |       4 |
| Antonio      |       1 |
| Around       |       5 |
| Berglunds    |       2 |
+--------------+---------+
5 rows in set (0.00 sec)
```

### RIGHT JOIN
* 右连接（RIGHT JOIN）返回右表格中的所有记录，以及左表格中符合连接条件的记录
```sql
SELECT Customers.CustomerName, Orders.OrderID
FROM Customers
RIGHT JOIN Orders ON Customers.CustomerID = Orders.CustomerID;
```
```
+--------------+---------+
| CustomerName | OrderID |
+--------------+---------+
| Antonio      |       1 |
| Berglunds    |       2 |
| Alfreds      |       3 |
| Ana          |       4 |
| Around       |       5 |
+--------------+---------+
```

### FULL OUTER JOIN
* 全外连接（FULL OUTER JOIN）返回左表格和右表格中所有的记录，以及符合连接条件的记录
* MySQL 不支持 FULL OUTER JOIN，但可以通过使用 UNION 操作符模拟其行为
* UNION 操作符：UNION 操作符用于合并两个 SELECT 语句的结果集合，同时去除其中的重复记录
* 在模拟 FULL OUTER JOIN 时，需要使用 UNION 操作符将左连接和右连接的结果合并起来
```sql
SELECT Customers.CustomerName, Orders.OrderID
FROM Customers
LEFT JOIN Orders ON Customers.CustomerID = Orders.CustomerID
UNION
SELECT Customers.CustomerName, Orders.OrderID
FROM Customers
RIGHT JOIN Orders ON Customers.CustomerID = Orders.CustomerID;

DROP TABLE Customers;
DROP TABLE Orders;
```
```
+--------------+---------+
| CustomerName | OrderID |
+--------------+---------+
| Alfreds      |       3 |
| Ana          |       4 |
| Antonio      |       1 |
| Around       |       5 |
| Berglunds    |       2 |
+--------------+---------+
```

## 权限系统设计典型

### 权限系统设计
* 当设计一个基于角色的权限系统时，通常需要设计三个核心表：**用户表**、**角色表**和**权限表**
  * **用户表**存储用户的信息
  * **角色表**定义一组权限的集合
  * **权限表**存储每个权限的详细信息
```sql
CREATE TABLE users (
    user_id INT PRIMARY KEY,
    username VARCHAR(50),
    email VARCHAR(100)
);
CREATE TABLE roles (
    role_id INT PRIMARY KEY,
    role_name VARCHAR(50)
);
CREATE TABLE permissions (
    permission_id INT PRIMARY KEY,
    permission_name VARCHAR(50)
);

CREATE TABLE user_role (
    user_id INT,
    role_id INT,
    PRIMARY KEY (user_id, role_id),
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    FOREIGN KEY (role_id) REFERENCES roles(role_id)
);
CREATE TABLE role_permission (
    role_id INT,
    permission_id INT,
    PRIMARY KEY (role_id, permission_id),
    FOREIGN KEY (role_id) REFERENCES roles(role_id),
    FOREIGN KEY (permission_id) REFERENCES permissions(permission_id)
);

-- 插入用户
INSERT INTO users (user_id, username, email) VALUES
    (1, 'Alice', 'alice@test.com'),
    (2, 'Bob', 'bob@test.com'),
    (3, 'Jerry', 'jerry@test.com');
-- 插入角色
INSERT INTO roles (role_id, role_name) VALUES
    (1, 'manager'),
    (2, 'user');
-- 插入权限
INSERT INTO permissions (permission_id, permission_name) VALUES
    (1, 'view'),
    (2, 'modify'),
    (3, 'delete');
-- 给用户分配角色
INSERT INTO user_role (user_id, role_id) VALUES
    (1, 1), -- Alice是管理员
    (2, 2), -- Bob是普通用户
    (3, 2); -- Charlie是普通用户
-- 给角色分配权限
INSERT INTO role_permission (role_id, permission_id) VALUES
    (1, 1), -- 管理员有查看数据的权限
    (1, 2), -- 管理员有修改数据的权限
    (1, 3), -- 管理员有删除数据的权限
    (2, 1); -- 普通用户有查看数据的权限

SELECT users.username, roles.role_name, permissions.permission_name
FROM users
INNER JOIN user_role ON users.user_id = user_role.user_id
INNER JOIN roles ON user_role.role_id = roles.role_id
INNER JOIN role_permission ON roles.role_id = role_permission.role_id
INNER JOIN permissions ON role_permission.permission_id = permissions.permission_id;

DROP TABLE user_role;
DROP TABLE role_permission;
DROP TABLE users;
DROP TABLE roles;
DROP TABLE permissions;
```
```
+----------+-----------+-----------------+
| username | role_name | permission_name |
+----------+-----------+-----------------+
| Alice    | manager   | view            |
| Alice    | manager   | modify          |
| Alice    | manager   | delete          |
| Bob      | user      | view            |
| Jerry    | user      | view            |
+----------+-----------+-----------------+
```

# Java

## (01)Java介绍

### JDK & JRE
* **JRE**：Java Runtime Environment （Java 运行时环境）
  * JRE包括Java虚拟机（Java Virtual Machine，JVM），以及 Java 平台核心类和基础 Java 平台库；通过 JVM 才能在电脑系统执行 Java 应用程序（Java Application）
* **JDK**：Java Development Kit （Java 开发工具包）
  * JDK 是 JRE 的超集，包含 JRE 的所有内容，以及开发小程序和应用程序所需的工具，例如编译器和调试器

### 自动垃圾回收（Garbage Collection）
* Java中对象的创建和放置都是在存储器堆栈上面进行
* 当一个对象没有任何引用的时候，Java的自动垃圾收集机制就发挥作用，自动删除这个对象所占用的空间，释放存储器以避免存储器泄漏
* 而在常规语言例如C++，程序员必须确保已分配的内存被释放。防止造成内存泄漏的麻烦
* 不同厂商、不同版本的JVM中的存储器垃圾回收机制并不完全一样，通常越新版本的存储器回收机制越快

## (03)Java HelloWorld

### HelloWorld
```java
public class HelloWorld {
    public static void main(String[] args) {
        System.out.println("Hello World!");
    }
}
```
> public：表示这个类是公开的 \
> class：表示类的意思 \
  > public 和 class 是 Java 中的关键字须小写 \
> HelloWorld：表示类名 \
  > 注意:文件名须与类名同名(区分大小写),通常类名以大写字母开头 \
> {}中的内容为类的定义 \
> main方法：Java 程序的固定入口方法 \
  > public：表示方法是公开的 \
  > static：表示方法是静态的 \
  > void：表示方法的返回类型为void \
  > String[]：表示参数的类型 \
  > args：表示参数的名称 \

## (04)Java 注释

### 注释
* 文档注释和多行注释的作用基本相同，唯一的区别是文档注释可以使用javadoc命令生成文档
```java
/**
  *文档注释
*/
```

### 生成JavaDoc
* Tool-Generate JavaDoc-Output directory-Command line arguments: "-encoding UTF-8"-Generate

## (05)Java 标识符
* Java语言中，对于变量，常量，函数，语句块也有名字，我们统统称之为Java标识符，通常由字母和数字以及其它字符构成

### 标识符规范
* 标识符可以以字母[A-Za-z]，美元符号$或下划线_开始
* 首字母后可以是字母、数字、下划线的任意组合
* Java关键字不能当作Java标识符

### 标识符命名约定
* **类和接口名**，首字母大写，如果是俩个单词，第二个单词的首字母大写
* **方法与变量**，首字符小写，其余的首字母大写，含大小写。尽量少用下划线。例如myName
* **常量**，全部字母大写，如果是俩个单词，使用下划线分隔，例如SIZE_NAME

## (06)Java 关键字与保留字

### 关键字
* Java语言中，关键字是特殊意义的固定单词
  * **数据类型**：boolean、int、long、short、byte、float、double、char、class、interface。
  * **流程控制**：if、else、do、while、for、switch、case、default、break、continue、return、try、catch、finally。
  * **修饰符**：public、protected、private、final、void、static、strict、abstract、transient、synchronized、volatile、native。
  * **动作**：package、import、throw、throws、extends、implements、this、supper、instanceof、new

### 保留字
* 保留字是为 Java 预留的关键字，它们虽然现在没有作为关键字。但可能在未来的版本中，将其作为关键字
  * true、false、null、goto、const。

## (07)Java 变量与常量

### 变量
* 变量可以分为三类：**局部变量**、**成员变量（实例变量）**、**静态变量（类变量）**
* 变量是程序中最基本的存储单元,由变量类型,变量名和存储的值组成。
* Java是一种**强类型**语言 ,每个变量都必须声明其数据类型。
* **强类型**：强制数据类型定义，更加严谨安全。所有的变量必须先声明、后使用。指定类型的变量只能接受类型与之匹配的值
#### 局部变量
* 局部变量位于方法或语句块内部，并且仅在声明的方法，语句块中可见
* 程序进入方法、语句块时会创建局部变量，直到执行完方法，语句块时，变量就会消失
* 局部变量没有任何关键字修饰
```
数据类型 标识符;
OR
数据类型 标识符 = 值;
```
#### 成员变量（实例变量）
* 成员变量是指在类体的变量部分中定义的变量，也称为属性，用于存储对象的状态
* 成员变量声明在类的内部，方法外部，对象创建时成员变量也跟着创建，对象消失成员变量也跟着消失
```java
public class HelloWorld {
    //成员变量
    public String name;
    public int age;
}
```
#### 静态变量（类变量）
* 静态变量在类中使用static关键字定义，在方法，语句块之外。
* static 修饰符告诉编译器，无论类被实例化多少次，类变量始终只有一个变量副本。只要类被加载到内存中，它就会存在。
* 随着程序启动时会创建静态变量，程序停止时会销毁静态变量。
```java
public class HelloWorld {
    //静态变量
    public static String name = "zhangsan";;
    public static int age = 18;
}
```

### 常量
* 常量是指在程序的整个运行过程中值保持不变的量，也可以分为三类：**局部常量**、**成员常量（实例变量）**、**静态常量（类变量）**
```java
// final 数据类型 标识符 = 值;
public class HelloWorld {
    //静态常量
    public static final String name = "zhangsan";;
    //成员常量
    final int age = 18;
    public static void main(String[] args) {
        // 局部常量
        final boolean i = true;
    }
}
```

## (08)Java 基本数据类型
* 整数类型、浮点类型、布尔类型、字符类型

### 整数类型
* **字节型byte**类型是最小的整数类型。当用户从网络或文件中处理数据流时，或者处理可能与 Java 的其他内置类型不直接兼容的未加工的二进制数据时，该类型非常有用。
* **短整型short**类型。
* **整型int**类型，常用的一种整数类型。
* **长整型long**：对于超出 int 类型所表示的范围时就要使用 long 类型


### 浮点类型
* 浮点类型是带有小数部分的数据类型，也叫**实型**.浮点型数据包括**单精度浮点型（float）**和**双精度浮点型（double）**。
* 双精度类型 double 比单精度类型 float 具有更高的精度和更大的表示范围。
* 注意：单精度类型float的值必须要以大写字母 F 或小写字母 f 结尾，否则会被当作 double 值。

### 布尔类型
* true 和 false

### 字符类型
* 字符类型（char）表示一个字符。可表示标准的 ASCII 码或 Unicode 字符

## (09)Java 运算符

### 运算符
* 算术运算符
  * 一元运算符
    * `-`: 取反符号
  * 二元运算符
* 赋值运算符
* 逻辑运算符
  > `&&`: 短路与(左边为false则不再执行右边) \
  > `||`: 短路或(左边为true则不再执行右边) \
  > `!`: 逻辑非 \
  > `&`: 逻辑与 \
  > `|`: 逻辑或 \
* 关系运算符
* 位运算符
  * 直接对整数类型的位进行操作，这些整数类型包括 long，int，short，char 和 byte。主要用来对操作数二进制的位进行运算。
  > `&`: 按位进行与运算 \
  > `|`: 按位进行或运算 \
  > `^`: 按位进行异或运算 \
  > `~`: 按位进行取反运算 \
  > `>>`: 有符号右移移运算符 \
  > `<<`: 左移位运算符 \
  > `>>>`: 无符号右移运算符 \
* 补充
  * 三元运算符
  * instanceof: 判断其左边对象是否为其右边类的实例，返回boolean类型的数据。可以用来判断继承中的子类的实例是否为父类的实现。
    ```
    boolean b = (任意对象表达式) instanceof (任意已定义的对象类)
    ```

## (10)Java 运算符优先级
| 优先级 | 运算符 | 关联性 |
|------|-----------------|--------|
| 优先级 | 运算符 | 关联性 |
| 1 | ()、[]、{} | 左到右 |
| 2 | !、-、~、++、-- | 右到左 |
| 3 | *、/、% | 左到右 |
| 4 | +、- | 左到右 |
| 5 | <<、>>、>>>  | 左到右 |
| 6 | <、<=、>、>=、instanceof | 左到右 |
| 7 | ==、!=  | 左到右 |
| 8 | &  | 左到右 |
| 9 | ^  | 左到右 |
| 10 | &#124;  | 左到右 |
| 11 | &&  | 左到右 |
| 12 | &#124;&#124;  | 左到右 |
| 13 | ?: | 右到左 |
| 14 | =、+=、-=、*=、/=  | 右到左 |

## (12)Java 循环

### 循环中断
* `break`：break 用于完全结束一个循环
* `continue`：continue用于跳过循环中剩余的语句而强制执行下一次循环

## (13)Java 字符串与字符串常用方法
* Java字符串属于引用数据类型
* 字符串是由零个或多个字符组成的有限序列

### 字符串定义
* 双引号定义字符串
```
String a = "yes";
```

* 文本块：使用三引号定义一个多行字符串(Java 13 提供的预览特性)
```
String a = """
  Hello
  World
  """;
```

* String 类定义字符串
```
String a = new String("Hello World");
```
### 字符串常用方法
* **字符串拼接**：加法运算符可以将多个字符串进行拼接
* **获取字符串长度**：使用String 类的 `length()`方法可以获取字符串长度
* **截取字符串**：使用String 类的 `substring()`方法可以截取字符串
* **去除首尾空格**：使用String 类的 `trim()`方法可以去除首尾空格
* **字符串替换**：使用String 类的 `replace()`方法可以进行字符串替换
* **根据字符查找字符所在字符串索引**：使用String 类的 `indexOf()`方法和 `lastlndexOf()` 方法可以根据字符查找字符所在字符串索引，`indexOf()`方法为首次出现的索引位置，`lastlndexOf()`方法为最后出现的索引位置

## (14)Java 一维数组
* 数组属于引用数据类型

### 一维数组定义
* 数组中的数据类型可以是基本数据类型和引用数据类型。
* 数组的大小一旦声明就不能再修改
```java
数据类型[] 数组名;
int[] arrayName;
数组名 = new 数据类型[数组长度];
arrayName = new int[5];
OR
数据类型 数组名[];
int arrayName[];
数组名 = new 数据类型[数组长度];
arrayName = new int[5];
OR 简写
数据类型[] 数组名 = new 数据类型[数组长度];
int[] arrayName = new int[5];
```
### 一维数组初始化
* 定义的同时进行数组赋值
  ```java
  数据类型[] 数组名 = {元素1, 元素2, 元素3, 元素n};
  int[] arrayName = {1, 2, 3, 4, 5};
  OR
  数据类型[] 数组名 = new 数据类型[]{元素1, 元素2, 元素3, 元素n};
  int[] arrayName = new int[]{1, 2, 3, 4, 5};
  ```
* 定义后再进行数组赋值
  ```java
  int[] arrayName = new int[5];
  arrayName[0] = 1;
  arrayName[1] = 2;
  arrayName[2] = 3;
  arrayName[3] = 4;
  arrayName[4] = 5;
  ```

### 一维数组取值
* 使用foreach 循环遍历数组
```java
for (int i : arrayName) {
  System.out.println(i);
}
```

## (15)Java 二维数组

### 二维数组定义
* 每个数组元素是一个一维数组
* 数组长度2可为空，表示可变化
```java
数据类型[][] 数组名;
int[][] arrayName;
数组名 = new 数据类型[数组长度1][数组长度2];
arrayName = new int[5][];
OR
数据类型 数组名[][];
int arrayName[][];
数组名 = new 数据类型[数组长度1][数组长度2];
arrayName = new int[5][];
OR
数据类型[][] 数组名 = new 数据类型[数组长度1][数组长度2];
int[][] arrayName = new int[5][];
```

### 二维数组初始化
* 定义的同时进行数组赋值
  ```java
  数据类型[][] 数组名 = {{xx,xx}, {}, {}, {}};
  int[][] arrayName = {{1,2}, {3,4}, {5}};
  OR
  数据类型[][] 数组名 = new 数据类型[][]{{xx,xx}, {}, {}, {}};
  int[][] arrayName = new int[][]{{1,2}, {3,4}, {5}};
  ```
* 定义后再进行数组赋值
  ```java
  int[][] arrayName = new int[3][2];
  arrayName[0][0] = 1;
  arrayName[0][1] = 2;
  arrayName[1][0] = 3;
  arrayName[1][1] = 4;
  arrayName[2][0] = 5;
  ```

### 二维数组取值
* 使用foreach 循环遍历数组
```java
for (int[] ints : arrayName) {
  for (int anInt : ints) {
    System.out.println(anInt);
  }
}
```
* `Arrays.deepToString`
```java
System.out.println(Arrays.deepToString(arrayName))
```

## (16)Java 面向对象概念

### 对象特点
* 对象具有属性和行为
* 对象具有变化的状态
* 对象具有唯一性
* 对象都是某个类别的实例

### 面向对象核心特性
* 封装
  * 利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。
  * 数据被保护在抽象数据类型的内部，尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。
  * 用户无需知道对象内部的细节，但可通过对象对外提供的接口来访问该对象。
  * 保证了程序和数据都不受外部干扰而且不被误用。
* 继承
  * 类之间的一种关系，子类可以拥有父类的全部特征和行为。
* 多态
  * 在父类中定义的属性和方法被子类继承后，可以具有不同的属性或表现方式。
  * 简单说就是子类可以自行实现功能扩展，而不需要修改基于父类的代码。

## (17)Java 类与对象

### 类定义
* 在面向对象中，类和对象是最基本、最重要的组成单元。
* 类是概念模型，定义对象的所有特性和所需的操作，对象是真实的模型，是一个具体的实体。
* 简单理解就是类是一个模板，可用来生产对象，而对象是一个具体的事物。
* Java 中类是引用数据类型

### 类的访问修饰符
| 访问修饰符 | 可修饰 | 可访问 |
|------|------|------|
| public | 类、属性、方法 | 任何 |
| private | 内部类、属性、方法 | 同一类 |
| protected | 内部类、属性、方法 | 同一包和子类 |
| default | 默认修饰符 | 同一包 |

### 类创建对象
* 使用 new 关键字可以实例化对象。首先在内存的栈空间中声明对象。之后在内存的堆空间实例化对象。
```java
类名 对象名称 = new 类名();
```
* 使用getDeclaredConstructor方法获得构造器对象并调用newInstance()方法创建对象
```java
类名 对象名称 = 类名.class.getDeclaredConstructor().newInstance();
```
* 使用Class.forName方法获得类的class并调用newInstance()方法创建对象
```java
类名 对象名称 = (类名) Class.forName("类名").newInstance();
```

## (18)Java 方法

### 方法定义
* 完整的方法通常包括**方法名称**、**方法主体**、**方法参数**和**方法返回值**类型
```java
访问修饰符 返回类型 方法名(参数列表) {
    //语句块
    //如有返回值做return操作
}
```
* 访问修饰符可取：
  * public、private、protected、或省略。
  * 同样方法也可被final、abstract、static等修饰。
* 返回类型：
  * 任何数据类型或 void(无返回值)。

### 方法传值接值
* 方法接收**基本类型参数**时，方法外部和方法内部的变量**互不影响**。
* 方法接收**引用数据类型参数**时，方法外部和方法内部的变量**可相互影响**(虽然String是引用数据类型，但是String一旦赋值无法修改)。

### 可变参数
* 方法参数个数不确定时，可使用可变参数方式。
* 可变参数用 **类型…**​ 表示，可变参数可简单理解为数组类型

## (19)Java 构造方法

### 构造方法
* 构造方法是一个特殊方法，用来初始化类的一个新对象。
* 每个类都有一个默认的构造方法，创建对象之后会自动调用。
* 可以有多个构造方法。
* 方法名必须与类名相同。
* 构造方法不能被static、final、abstract等修饰符修饰。
* 不需要写返回值字段。
* 类中定义了一个或多个构造方法的话 Java 不会再提供默认构造方法。

### this 关键字
* 这里的this关键字用于实例方法指向当前对象。
* 解决实例变量与构造方法参数同名称时，不能赋值的问题。
* 同时this 关键字也还能调用同一类中其他的成员方法。
```java
void change() {
    System.out.println("change");
}
void eat(){
    this.change();
}
```
* 注意：静态成员不能直接访问非静态成员，也就是说static修饰的方法不能使用this。

## (20)Java 方法重载

### 方法重载
* 同一个类中多个同名方法，同名方法的形参列表不同。可避免类似方法，出现太多方法名的情况，同时调用简单。

## (21)Java 类封装

### 封装的优点
* 隐藏实现细节：对象的内部实现被隐藏，只向外部提供一个访问接口，可以减少代码的耦合度，并提高代码的可维护性和可扩展性。
* 简化编程：封装使得对象的使用者可以更加简单和方便地使用对象，不需要了解对象的复杂实现，也不需要知道对象内部的状态和数据结构。
* 提高安全性：封装可以保护对象的属性和方法不被外部直接访问和修改，确保对象的数据安全性和正确性。
* 提高代码的可重用性：封装使得对象可以被多次使用，并且在不同的环境中被重复使用，提高了代码的可重用性。

### 封装的步骤
* 属性的可见性设置为 private。
* 每个属性创建对应的setter方法和getter方法，可见性设置为 public。
* 在setter方法和getter方法中，需对属性值的合法性进行判断。

## (22)Java 继承

### 继承
* 需注意过度的继承也会导致代码的耦合性增加，因此需谨慎使用继承，避免出现继承层次过深和复杂的情况。
* 父类有有参的构造方法但没有无参构造方法的情况，那么在子类中必须有有参构造方法，因为子类如不提供构造方法的话会调用父类中无参的构造方法。
* Java的继承是单一继承，一个子类只能拥有一个父类，一个父类可以拥有多个子类。
```java
访问修饰符 class 类名 extends 父类 {
}
```

## (23)Java super关键字

### super
* super用在子类中，可以访问父类变量或方法。
* super和this一样不能在static 变量、static 方法和 static 代码块中使用。
* 调用super()必须写在子类构造方法的第一行。
* 子类的构造方法会隐含地调用super()(不用显式的写也行)，如父类没有这种形式的构造函数，则报错。

### super用法
* `super.父类属性`：调用父类中的属性
* `super.父类方法`：调用父类中的方法
* `super()`：调用父类的无参构造方法
* `super(参数)`：调用父类的有参构造方法

## (24)Java 方法重写

### 方法重写
* Java中的方法重写(Override)指的是在子类中重新定义一个与父类中同名、同返回类型、同参数列表的方法。
* 并且方法的访问修饰符不能低于父类中的方法。
* 构造方法不能被重写。
* 重写方法一定不能抛出新的检査异常或者比被重写方法更加宽泛的检査型异常。
* 只有父类被子类继承时，方法才能被重写。
* 定义为 static 的方法不能被重写，但是能够再次声明。
* 定义为 final 的方法不能被重写。
* 子类和父类在同一个包中时，子类可以重写父类的所有方法，除了定义为 private 和 final 的方法。
* 子类和父类不在同一个包中时，子类只能重写父类的定义为 public 和 protected 的非 final 方法。

### 方法重写的优点
* 提高代码的可维护性：方法重写可以让子类根据自身的特点重新定义某些继承自父类的方法，使得代码更加灵活，容易维护。
* 实现多态性：方法重写是实现多态性的重要机制，可以在运行时动态地调用子类对象的方法，从而根据不同对象的类型执行不同的操作。

### 与方法重载的区别
* 参数列表不同：方法重载的方法名相同，但是参数列表不同（参数类型、参数个数、参数顺序等），方法重写的方法名和参数列表都必须相同。
* 返回值不同：方法重载可以改变返回值类型，但是方法重写的返回值类型必须和被重写的方法返回值类型相同或是其子类。
* 静态/实例方法：方法重载可以是静态方法或实例方法，方法重写只能是实例方法。
* 修饰符：方法重载可以改变方法的修饰符，但是方法重写的访问修饰符不能低于父类中的方法。
* 抛出异常不同：方法重载的方法可以抛出任何非受查异常，而方法重写的方法只能抛出和被重写方法抛出异常相同或是其子类。

## (25)Java final关键字

### final关键字用法
* final关键字用来表示不可变的、不可修改的意思。
* **变量**：用final修饰的变量表示一个常量，即只能赋值一次且在声明时或构造函数中进行赋值，之后不可修改。
* **方法**：用final修饰的方法表示该方法不可被重写。如果一个类中的某个方法不希望在子类中被修改，可以使用final关键字修饰该方法。
* **类**：用final修饰的类表示该类不能被继承。如果一个类不希望被其他类继承，可以使用final关键字修饰该类。

### final关键字的好处
* 提高程序的性能：Java 编译器可以使用一些优化技术，例如内联方法，以便更好地处理 final 变量。
* 更安全的多线程编程：final 变量在多线程环境中是线程安全的，因为其值不会被更改，避免了线程竞争和同步的问题。
* 更加可读的代码：final 关键字可以让代码更加易于理解和维护，因为它明确了某些值或行为的不可更改性。

## (26)Java 多态

### 多态
* Java中多态是一种对象的行为，指的是同一个方法名，但具体的实现方式却有多种可能。
* 这种能力称为"多态性"，Java中的多态性分为编译时多态性和运行时多态性两种。
**编译时多态性**
* 编译时多态性也称为静态多态性，指的是方法的重载特性，即在编译时确定调用的方法。
**运行时多态性**
* 运行时多态性也称为动态多态性，指的是方法的重写特性，即在运行时根据对象的实际类型确定调用的方法。
* 运行时多态性需要满足三个条件：继承、方法重写和父类引用指向子类对象(向上转型)。

### 多态的优点
* 可扩展性：多态使得程序的扩展变得更加容易。通过继承和方法重写，可以轻松地添加新的功能，而无需对现有代码进行修改。
* 代码重用：多态性使得代码的重用更加容易。可以创建一个通用的父类，然后通过继承该父类创建许多不同的子类。这些子类可以共享通用的属性和方法，从而实现代码重用。
* 灵活性：多态性使得程序更加灵活。通过多态，可以在运行时决定对象的类型，并动态地调用相应的方法。这使得程序的行为可以根据运行时环境的变化而变化，从而使程序更加适应不同的场景。

## (27)Java 抽象类

### 抽象类
* Java中的抽象类是一种特殊的类，它不能被实例化，只能被继承。
* 抽象类定义了一组抽象方法，这些方法没有实现，只有方法声明。
* 子类必须实现这些抽象方法才能被实例化。

### 抽象类的优点
* 抽象类可以为具有相似特征的一组类提供一个通用的抽象概念，避免了代码的重复，提高了代码的复用性和可维护性。
* 抽象类可以限制某些方法的访问权限，从而控制子类对其行为的修改，提高了程序的安全性。
* 抽象类可以通过定义抽象方法来规范子类的行为，增强了程序的可扩展性。子类必须实现抽象方法，以保证其符合规范。

### 抽象方法
* 抽象方法是指只有方法声明而没有方法实现的方法。
* 使用 abstract 关键字进行修饰。
* 抽象方法必须在抽象类中声明。

### 抽象注意事项
* 抽象方法不能被声明为私有、静态、final或native。
* 抽象类可以包含抽象方法和具体实现的方法。
* 抽象类不能实例化。
* 子类继承抽象类时必须实现父类的所有抽象方法，否则子类也必须被声明为抽象类。

## (28)Java 接口

### 接口
* Java中的接口（Interface）是一种特殊的抽象类。
* 它是一组抽象方法的集合，不包含属性，所有方法必须是公共的抽象方法。
* 实现接口的类必须实现接口中所有的方法。接口可以看作是一种约定，用于规范某一类对象必须具备的行为。

### 接口定义
* 接口可以有多个父接口。
* 接口只能继承接口，不能继承类。
  ```java
  访问修饰符 interface 接口名 [extends 接口名(可多个)] {
  }
  ```

### 接口实现
* 一个类可以实现一个或多个接口。
* 如有extends 那么implements须放在extends后。
  ```java
  访问修饰符 class 类名 [extends 类(只一个)] [implements 接口名(可多个)] {
  }
  ```

### 接口的优点
* 规范行为：接口可以规范某一类对象必须具备的行为。
* 多重继承：Java中的类只能单继承，但一个类可以实现多个接口，这样就可以实现多重继承，提高了代码的复用性和灵活性。
* 松耦合：接口使得类与类之间的依赖关系更加松耦合，便于代码的维护和升级。
* 扩展性：接口定义了一组规范，可以方便地进行扩展和升级。如果需要添加新的行为，只需新增一个实现了接口的类即可，不需要修改已有的代码。

### 接口补充
* 从 JDK 1.8 开始，Java 接口可以定义**默认方法**和**静态方法**。
* **默认方法**是在接口中已经有了一个默认的实现方法，实现类可以直接继承或者重写这个方法，而不需要再次实现。
* **静态方法**是指在接口中定义的静态方法，可以通过接口名直接调用，而不需要实现类的实例。

## (29)Java 抽象类与接口区别

### 抽象类与接口区别
* **实现**：一个类只能继承一个类，但是可以实现多个接口。接口的实现使用关键字 implements，而抽象类的实现使用关键字 extends。
* **构造函数**：抽象类可以有构造函数，而接口不能有构造函数。
* **成员变量**：接口中定义的变量默认为 public static final，也就是常量，而抽象类中定义的变量则可以是各种类型的变量。
* **成员方法**：接口中的方法默认为 public abstract，而抽象类中的方法可以有不同的访问修饰符，并且可以有非抽象方法。
* **多重继承**：由于一个类只能继承一个类，而可以实现多个接口，因此接口可以用来实现多重继承。
* 接口更适用于定义类之间的行为规范，而抽象类更适用于将公共功能放在一起，以便子类继承和重用。

## (30)Java static关键字

### static关键字
Java中static关键字用于指示一个成员变量或方法属于类本身，而不是属于类的实例。
使用static关键字定义的变量或方法可以通过类名直接访问，而不需要创建类的实例。

### static优点
* 节省内存：static变量只会在内存中存在一份拷贝，而不是每个实例都有一份拷贝，这可以节省内存空间。
* 方便访问：由于static方法和变量可以直接使用类名调用，所以可以更方便地访问这些成员，而不需要创建类的实例。
* 可以共享数据：static变量可以在所有实例之间共享，这样可以在多个实例之间共享数据，提高了程序的效率。
* 方便实现工具类和单例模式：使用static方法和变量可以方便地实现工具类和单例模式，因为这些类通常不需要创建实例，而是直接使用类名调用方法或变量。

### static关键字使用
* 静态变量
  * 静态变量只分配一次内存，在加载类的过程中完成静态变量的内存分配。
  * 静态变量被类的所有实例共享。
    ```java
    public static int count = 0;
    ```
* 静态方法
  * 静态方法可通过类名直接调用。
    ```java
    public static int getCount() {
        return count;
    }
    ```
* 静态代码块
  * 静态代码块用于初始化类，为类的静态变量赋初始值。
  * 静态代码块可多个并放在类中的任何地方，在加载类时执行静态代码块。
  * 静态代码块只会被执行一次。
    ```java
    static {
        System.out.println("类加载了");
    }
    ```

## (31)Java 内部类

### 内部类
* Java中的内部类是定义在一个类中的类。
* 内部类可分为四种：成员内部类、静态内部类、方法内部类和匿名内部类。

### 成员内部类
* 成员内部类是一种定义在类中的内部类，它与外部类的成员变量和方法处于同一层次。
* 成员内部类可以访问外部类的成员变量和方法，即使这些成员变量和方法是私有的。
```java
class OuterClass {
  // 外部类
  class InnerClass {
    // 内部类
  }
}
```
* 成员内部类优点：
  * 可以访问外部类的私有成员变量和方法，从而可以提供更加严密的封装性。
  * 可以用来实现一些只在外部类中使用的接口，从而提高代码的模块化程度。

### 静态内部类
* 静态内部类是定义在一个类内部，并使用 static 修饰的类。
* 相对于成员内部类，它与外部类的实例无关，也就是说可以不依赖于外部类的实例而直接创建对象。
* 在静态内部类中可以定义静态成员变量、静态方法、实例变量、实例方法等，与普通的类类似。
```java
class OuterClass {
    static class StaticInnerClass {
        // 静态内部类
    }
}
```
* 静态内部类优点：
  * 可以访问外部类的静态变量和方法，方便地共享数据和方法。
  * 可以直接创建静态内部类的对象，而不需要先创建外部类的对象。

### 方法内部类
* 方法内部类是指定义在一个方法内部的类。
* 只能在该方法内部被访问，无法从方法外部访问。
* 还需注意不能使用访问修饰符。
```java
class OuterClass {
    public void method() {
        class MethodInnerClass {
            // 方法内部类
        }
    }
}
```
* 方法内部类通常用于需要临时创建一个类的情况，且这个类只需要在该方法中使用。
* 相比于定义一个独立的类，使用方法内部类可以减少类的数量，避免命名冲突，提高代码的可读性和可维护性。

### 匿名内部类
* 匿名内部类是一种没有命名的内部类。
* 它可以用于创建只需要使用一次的简单类。
* 通常情况下，它用于实现接口或继承类。
* 匿名内部类可使代码更加简洁、灵活和实用。

## (32)Java 异常

### 异常
* Java 异常是指在程序执行过程中发生的一些不期望的、异常的事件，例如除数为 0、空指针引用等。
* 当这些异常事件发生时，程序会停止执行并抛出异常，如果异常没有得到处理，程序可能会终止运行。
* Java 中提供了异常处理机制，可以让程序在发生异常时执行相应的处理逻辑，避免程序崩溃。
* Exception通常表示可预见的问题，例如输入错误、网络中断、文件不存在等等，这些异常可以通过代码进行处理。

### 异常类型
* Java中所有异常类型都是内置类java.lang.Throwable类的子类，即Throwable类是所有异常和错误的父类。
* Throwable类下有两个异常分支 Exception 和 Error。
* Exception包括 Unchecked Exception（非检查异常）和 Checked Exception（检查异常）两大类别。
  * 非检查异常是编译器不要求强制处理的异常，也就是说编写代码时不去处理此类异常，程序还是会编译通过。非检查异常不需要在代码中显式处理，例如NullPointerException(空指针异常)、IllegalArgumentException(非法实参调用方法)等。
  * 检查异常是编译器要求必须处理的异常，也就是说编写代码时必须处理此类异常，否则程序无法编译通过。检查异常必须在代码中显式处理，否则编译器会报错，例如IOException(IO操作异常)、SQLException(SQL异常)等。
* Error是指不希望被应用程序捕获的严重问题，这些错误在应用程序的控制和处理能力之外。

## (33)Java 异常处理

### 异常处理机制
* **捕获异常**：用try catch 语句捕获并处理异常。
* **抛出异常**：抛出异常是Java中一个程序处理的动作，如当前方法没有捕获异常，异常会抛到上层调用方法，直到被捕获为止。

### 捕获异常
* Java中通常采用try catch 语句来捕获异常并处理。
``` java
try {
    // 可能发生异常的语句
} catch (异常类型 e) {
    // 捕获并处理try抛出的异常
} finally {
    // 无论是否发生异常都会执行的语句
}
```
* catch语句可以有多个，代表代码块中可能有很多语句会发生异常。
* 注意：当捕获的多个异常类之间存在父子关系时，捕获异常时一般先捕获子类，再捕获父类。所以子类异常必须在父类异常的前面。
* 因为catch是按照从上往下的顺序进行匹配，一旦匹配就不会再向下继续匹配。
``` java
try {
    int i = 1 / 0;
}catch (Exception e){
    e.printStackTrace();//输出异常信息
}finally {
    System.out.println("Done");
}
```

### 抛出异常
* Java中throw 语句用来直接拋出一个异常，后接一个可拋出的异常类对象。
``` java
// throw 异常类对象;
int b = 0;
if (b == 0) throw new ArithmeticException();
int i = 1 / b;
```
* 这里先判断除数的值，如为零则使用throw语句抛出算数异常类对象。
* 可使用throw语句抛出任何类型的Throwable类或其子类的对象，会中断执行，也就是说throw语句之后的内容不会执行。

### 声明异常
* Java中throws语句可声明方法要抛出何种类型的异常。
* 用于方法可能出现异常，但不处理此异常时，可通过throws语句声明异常。
``` java
// throws 异常类对象1,异常类对象2;
public static void main(String[] args) throws ArithmeticException{
}
```

### throws和throw的区别：
* throws用于在方法声明中指定可能会抛出的异常类型，表示一种可能性，但并不一定会发生这些异常。
* throw则是用于在代码中显式抛出异常，表示一定抛出某种异常。

## (34)Java 自定义异常

### 自定义异常优点
* 该类继承自Java的标准异常类（Exception、RuntimeException等）之一。
* 提高代码的可读性和可维护性：通过自定义异常类，我们可以将程序中可能发生的不同异常情况进行分类，并为每种情况定义一个特定的异常类。这样，我们就可以更清晰地了解程序中可能发生的错误，并更好地维护代码。
* 提供更精确的异常信息：Java的标准异常类提供了一些常用的异常类型，如NullPointerException等。但是，在某些情况下，这些异常类型可能无法满足我们的需求。通过自定义异常类，我们可以提供更加精确和具体的异常信息，这样我们就可以更好地定位和解决程序中的错误。
* 程序结构更清晰：通过自定义异常类，我们可以将异常处理与业务逻辑分离。这样，我们就可以更好地管理代码，并使程序结构更加清晰。
* 提高代码的健壮性：通过自定义异常类，我们可以更好地处理程序中的异常情况，从而提高程序的健壮性和容错性。这有助于保证程序在面对异常情况时仍能够正常运行，并避免程序的崩溃。

## (35)Java Lambda表达式

### Lambda表达式
* Java Lambda表达式是Java 8中引入的一种新特性，它是一种简洁而强大的函数式编程的方式。
* 它允许您将函数作为参数传递给方法，或者使用函数式接口来创建函数对象。
* Lambda表达式可以被看作是一种匿名函数，可以在不创建类的情况下定义函数，因此它是一种更为简洁、灵活的编程方式。

### 函数式接口
* 函数式接口指在一个接口里面有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。
* 在编写程序过程中可将@FunctionalInterface注解放在接口上方，如果接口是函数式接口则编译通过，不符合规范则编译报错。
* @FunctionalInterface注解会让编译器去检查编写的接口是否仅包含一个抽象方法。（所以不一定要写上）

### 使用Lambda表达式优点
* 简洁性：Lambda表达式比传统的Java代码更为简洁，可以减少大量样板式代码，使代码更易于阅读和理解。
* 灵活性：Lambda表达式可以在需要函数式接口的任何地方使用，从而提高了代码的灵活性。
* 并行处理：Lambda表达式可以简化并行处理代码的编写，可充分利用多核CPU的优势。
* Lambda表达式是Java 8中最强大和最具创新性的功能之一。

### 语法
* Lambda表达式的语法基本上由参数列表、箭头符号和方法体组成。
* 这个表达式中参数列表包含传递给方法的参数，箭头符号指示Lambda表达式的开始，而方法体则包含在大括号中的代码块。
```java
(parameter1, parameter2, ...) -> { expression }
```

## (36)Java Lambda表达式简写

### 省略参数类型
* 如果Lambda表达式的参数类型可以被编译器推断出来，那么可以省略参数类型。
```java
MyInterface myLambda = (a, b) -> a + b;
```

### 省略参数类型
* 局部变量类型推断
* Java 11开始支持在Lambda表达式中使用var关键字来定义变量。
* 使用var关键字可以让代码更加简洁，并且可以更容易地表达出变量的意图。
```java
MyInterface myLambda = (var a, var b) -> a + b;
```

### 省略参数括号
* 如果Lambda表达式只有一个参数，可以省略参数括号。
```java
MyInterface myLambda = a -> a * a;
```

### 省略方法体大括号
* 如果Lambda表达式方法体只有一行代码，可以省略方法体大括号。
```java
MyInterface myLambda = a -> a * a;
```

### 方法引用
* 如果Lambda表达式只是调用一个已经存在的方法，可以使用方法引用。
* 方法引用是一种特殊的Lambda表达式。方法引用使得代码更加简洁，易于阅读和维护。
* 方法引用可以看作是Lambda表达式的一个语法糖，它通过一些特定的符号和语法来指定要调用的方法。
```java
MyInterface myInterface = System.out::println;
```

### 方法引用形式
* 静态方法引用
  * 语法：ClassName::staticMethodName
  * 示例：System.out::println
  * 上面的代码使用了System.out对象的println方法，这个方法是一个静态方法，因此可以使用静态方法引用的语法糖。
* 实例方法引用
  * 语法：object::instanceMethodName
  * 示例：String::length
  * 上面的代码使用了String类的length方法，这个方法是一个实例方法，因此可以使用实例方法引用的语法糖。
* 对象方法引用
  * 语法：ClassName::instanceMethodName
  * 示例：ArrayList::size
  * 上面的代码使用了ArrayList类的size方法，这个方法是一个实例方法，但是它没有特定的实例对象，因此可以使用对象方法引用的语法糖。
* 构造方法引用
  * 语法：ClassName::new
  * 示例：String::new
  * 上面的代码使用了String类的构造方法，这个方法是一个构造方法，因此可以使用构造方法引用的语法糖。

## (37)Java 函数式接口

### 使用函数式接口的优点
* 简化代码：使用函数式接口和 Lambda 表达式可以使代码更加简洁，减少样板代码，降低代码复杂度。
* 提高可读性：使用函数式接口可以更加直观地表达代码的意图，使得代码更加易读易懂。
* 支持并行执行：函数式接口和 Lambda 表达式支持并行执行，可以将任务分配给多个线程同时执行，提高程序的并发能力和效率。
* 支持更灵活的设计模式：使用函数式接口可以更加灵活地设计代码结构，例如可以使用 Lambda 表达式作为参数传递，可以在运行时动态生成函数式接口的实现类等。
* 在函数式编程中，函数是头等对象即头等函数，这意味着一个函数，既可以作为其它函数的输入参数值，也可以从函数中返回值，被修改或者被分配给一个变量。

### Runnable
* Runnable 是一个没有参数和返回值的函数式接口，用于表示一个可执行的任务。
* 该接口只有一个抽象方法 run()，用于定义具体的任务代码或处理逻辑。
* 在多线程编程中，可以通过实现 Runnable 接口来创建一个新的线程。
```java
Runnable task = () -> System.out.println("Running the task");
new Thread(task).start();
```

### Consumer
* Consumer 是一个接收单个输入参数并且没有返回值的函数式接口。它表示了对输入参数的消费操作。
* 该接口只有一个抽象方法 accept(T t)，用于消费一个参数数据
* 该接口还有一个默认方法 andThen(Consumer<? super T> after)，可返回一个组合的 Consumer，依次执行操作。
```java
Consumer<String> consumer = System.out::println;
consumer.accept("Hello, World!");
```

### Supplier
* Supplier 是一个没有参数但是返回一个值的函数式接口。它表示了对值的生成操作。
* 该接口只有一个抽象方法 get()，用于按照由Lambda表达式定义的相关实现，返回一个具体的数据
```java
Supplier<Integer> randomInt = () -> new Random().nextInt(10);
int result = randomInt.get();
System.out.println(result); // 0 到 9 之间的随机整数
```

### Function
* Function 是一个接收一个参数并产生一个结果的函数式接口。它表示了从一个值到另一个值的映射操作。
* 该接口只有一个抽象方法 R apply(T t)，用于接收一个数据操作数据之后返回一个新的数据。
```java
Function<Integer, String> intToString = (i) -> "The number is " + i;
String result = intToString.apply(66);
System.out.println(result); // 输出 "The number is 66"
```

### Predicate
* Predicate 是一个接收单个输入参数并返回一个布尔值的函数式接口。它表示了对输入参数的判断操作。
* 该接口只有一个抽象方法 boolean test(T t)，用于对接受数据做出相应的判断。
```java
Predicate<Integer> isPositive = i -> i > 0;
boolean result1 = isPositive.test(42);
System.out.println(result1); // 输出 true
boolean result2 = isPositive.test(-1);
System.out.println(result2); // 输出 false
```

## (38)Java Lambda延迟执行

### Lambda延迟执行
* Java中Lambda表达式是不会立即执行的，而是在需要执行的时候才会被调用执行。
* 这种延迟执行的机制可以带来节省计算资源的优点：Lambda表达式只有在需要执行的时候才会被调用执行，因此可以减少不必要的计算资源消耗，提升性能。
* 但同时需要注意的是，Lambda表达式的延迟执行也可能带来一些负面影响，例如一些错误可能在运行时才被发现，因此需要在使用Lambda表达式时慎重考虑其优缺点。

## (39)Java 多线程

### 进程
* 进程是一个具有一定独立功能的程序在某个数据集合的一次运行活动，是系统进行资源分配和调度的一个独立单位。
* 从操作系统角度来看，可将进程分为系统进程和用户进程两类。
* 系统进程执行操作系统程序，完成操作系统的某些功能。
* 用户进程运行用户程序，直接为用户服务。
* 系统进程的优先级通常高于一般用户进程的优先级。
* 进程=(程序+数据+进程控制块PCB)。

### 程序与进程区别
* 进程是动态的：是程序的一次执行过程。
* 程序是静态的：是一组指令的有序集合。
* 进程是暂存的：在内存驻留。
* 程序是长存的：在存储介质中存储。

### 线程
* 80年代中期，随着操作系统理论和技术发展，提出了比进程更小的、能够独立运行的基本单位线程。
* 线程可以提高系统内程序并发执行的级别，可以进一步提高系统效率。
* 进程是资源拥有者，进程的创建撤销切换等过程中系统会付出较大的时空开销。
* 线程是进程中的一个实体，是处理器调度和分派的基本单位。
* 同时基本上不拥有系统资源，只拥有少量在运行中必不可少的资源，与同属进程共享进程全部资源。
* 同一个进程中的多个线程之间可以并发执行。
* 线程又称为轻量级进程(LWP)，传统的进程又称为重量级进程(HWP)。

### 线程的优点
* 创建新线程花费时间少，无需额外分配资源。
* 线程之间切换快。
* 线程间的通信，更便捷，更快。
* 线程可独立运行，能够充分利用和发挥CPU与外部设备的并行工作能力。

## (40)Java 线程创建

### 继承Thread类
* 可以定义一个继承Thread类的子类，在子类中重写run()方法，run()方法中的代码将在新的线程中执行。
* Thread类是Java多线程编程的核心类，提供了多种常用的方法:
* start()：启动线程，并执行线程中的run()方法。
* run()：定义线程的执行逻辑，必须被重写。
* sleep(long millis)：使当前线程暂停指定的时间（毫秒）。
* join()：等待线程执行完毕。
* join(long millis)：等待线程执行指定的时间（毫秒）。
* isAlive()：判断线程是否还存活。
* interrupt()：中断线程的执行。
* setPriority(int priority)：设置线程的优先级。
* getPriority()：获取线程的优先级。
* getName()：获取线程的名称。
* setName(String name)：设置线程的名称。
* yield()：让出CPU资源，使其他线程有机会执行。

### 实现Runnable接口
* 实现Runnable接口相较于继承Thread类：
* 实现 Runnable 接口相对于继承 Thread 类更加灵活。
* 因为 Java 是单继承的，如果继承了 Thread 类，就不能再继承其他的类。
* 但实现 Runnable 接口并不会对类的继承关系造成影响。
* 也更加符合面向对象的设计原则。
* 大多数情况下，使用多线程仅仅是为了实现某个功能，而不是继承 Thread 类的某些特性。

### 实现Callable接口
* Callable接口与Runnable接口类似，可用于多线程编程。
* 不同的是，Callable接口的call()方法可以返回一个值，并且可以抛出异常。
* 而 Runnable接口的run()方法是void 类型的，无法返回值或者抛出异常。

## (41)Java 线程状态
### 线程状态可分为
* NEW：线程刚被创建，但还没有被启动。
* RUNNABLE：线程正在执行或者等待执行，也就是有可能处于运行状态，或还在等待 CPU 时间片。
* BLOCKED：线程被阻塞不能执行，有可能正在等待获得一个监视器锁，。
* WAITING：线程正在等待另一个线程执行特定操作，例如调用 wait() 或者 join()等。
* TIMED_WAITING：线程正在等待另一个线程执行特定操作，但是等待时间有限，例如调用 sleep()等。
* TERMINATED：线程已经执行完毕。
* 一个线程在一个时间点只能处于一种状态。

### Java多线程状态的作用
* 实现线程同步：多线程状态中的 BLOCKED 和 WAITING 状态可以用来实现线程同步，从而避免多个线程访问共享资源时的并发问题。
* 监控线程状态：多线程状态可以用来监控线程的状态，从而了解线程的执行情况，及时进行调优和问题排查等等。

## (42)Java 线程中断

### 线程中断
* Java中，线程中断是一种协作机制，可允许一个线程中断另一个线程的执行。
* 线程中断并不是强制性的，它只是向目标线程发出了一个请求，希望目标线程能够自行停止执行。
* 目标线程可以根据自己的需要决定是否停止执行。

## (43)Java 守护线程
### 守护线程
* Java 中，守护线程（Daemon Thread）是一种特殊的线程。
* 它的作用是为其他线程提供服务，不会阻止 JVM 的退出。当所有的非守护线程结束时，守护线程会自动结束。

## (44)Java 线程同步

### 线程同步
* Java 线程同步是指在多个线程并发执行时，对共享资源进行协调和管理，以保证多线程间的数据访问正确性和一致性。
* Java 提供了多种同步机制，其中最常用的是JVM 实现的synchronized 关键字和JDK 实现的 ReentrantLock。

### synchronized关键字
* synchronized 关键字是 Java 中实现线程同步的一种方式。
* 它的作用是协调多个线程对共享资源的访问，以保证数据的正确性和一致性。
  * 保证原子性：synchronized 关键字可保证被它修饰的方法或代码块在同一时间只能被一个线程执行，从而避免了多个线程同时访问共享资源导致的数据不一致问题。
  * 保证可见性：synchronized 关键字不仅可以保证原子性，还可以保证多个线程对共享资源的修改在其他线程中是可见的。这是因为 synchronized 会将修改后的数据刷新到主内存中，而其他线程在访问共享资源时会从主内存中读取最新的数据。
  * 保证有序性：synchronized 关键字可以保证代码的执行顺序与程序中编写的顺序一致，即遵循了“先行发生原则”。这是因为 synchronized 在释放锁时会强制刷新线程的本地内存，从而使得之前的所有操作对其他线程都是可见的。

### 同步方法语法
* synchronized 方法会锁住整个对象，即使该对象有多个 synchronized 方法，其他线程也不能访问该对象的其他 synchronized 方法。
* 即同步方法中的锁对象是 this。
* 如果要对某个方法进行细粒度的控制，可以使用 synchronized 代码块。
```java
public synchronized void methodName() {
    // 方法体
}
```

### 同步代码块语法
* object 表示用来锁住代码块的对象，该对象可以是任何对象，但是需要保证多个线程访问该对象时使用的是同一个对象。
* 当某个线程进入该代码块时，它会锁住 object 对象，其他线程在访问该对象时需要等待当前线程释放锁。
* synchronized 代码块只会锁住被 synchronized 关键字修饰的代码块，其他代码不受影响。
* 如果要对整个方法进行控制，可以将 synchronized 关键字放在方法定义的位置。
```java
synchronized (object) {
    // 代码块
}
```

### ReentrantLock
* ReentrantLock 是 Java 中的一个可重入锁，它与 synchronized 关键字一样，都是用来实现线程同步的机制。
* ReentrantLock 与 synchronized 关键字相比，提供了更加灵活的线程同步控制。
* 作用：
  * 可以控制线程的等待时间：使用ReentrantLock可以调用tryLock(long time, TimeUnit unit)方法来控制线程等待获取锁的时间。如果等待时间超过了指定的时间，线程就会放弃获取锁，返回false，继续执行后续代码。
  * 可以实现公平锁：ReentrantLock提供了构造函数ReentrantLock(boolean fair)，用于指定锁是否是公平锁。公平锁是指多个线程获取锁的顺序与它们发出获取锁请求的顺序相同，即先来先服务。
  * 可以实现可重入锁：可重入锁是指同一个线程可以多次获取同一把锁，而不会被阻塞。ReentrantLock 就是一个可重入锁。
  * 可以实现条件变量：ReentrantLock 还提供了一个 Condition 接口，可以实现类似于 Object.wait() 和 Object.notify() 的功能，用于线程之间的通信和协调。
  * 可以实现精确控制锁的释放：相比于 synchronized 关键字，在使用 ReentrantLock 时，程序员可以更加精确地控制锁的释放时机，从而更好地控制线程同步。

### ReentrantLock
* 创建ReentrantLock对象。
```java
ReentrantLock lock = new ReentrantLock();
```
* 加锁
* 使用lock()方法可以获取锁对象，并且该方法是可重入的，也就是说，同一个线程可以多次调用该方法获取锁。
* 当多个线程同时访问加锁的代码块时，只有一个线程能够获取锁，其他线程需要等待锁被释放后才能进入代码块。
* 需要注意的是，加锁后一定要释放锁，否则会出现死锁的情况。
* 一般使用 try-finally 结构来确保锁被释放，即使在加锁过程中出现异常也能保证锁被释放。
```java
lock.lock();
try {
    // 需要线程同步的代码
} finally {
    lock.unlock();
}
```
* 解锁
* 使用unlock() 方法可以释放锁对象。
* ReentrantLock 还提供了一些高级的功能，如可重入锁、公平锁、限时等待等，可以通过构造函数或者相应的方法来实现。
```java
lock.unlock();
```

## (45)Java 线程wait与notify
### wait方法
* Java中的wait()方法是用于线程之间进行通信和同步的方法之一。
* 它使当前线程进入等待状态，直到另一个线程通知它可以继续执行。
* wait()方法必须在synchronized块内部调用，并且会释放该线程的锁，直到另一个线程调用notify()或notifyAll()方法为止。

### notify方法
* Java中的notify()方法是用于线程之间进行通信和同步的方法之一。
* 它用于通知等待的线程可以继续执行。
* notify()方法必须在synchronized块内部调用，并且只能唤醒等待该对象锁的一个线程，如果有多个线程等待该对象的锁，那么唤醒哪一个线程是不确定的。

## (46)Java 线程池

### 线程池
* 在Java中，线程池是一组预先创建的线程，这些线程可以被重复使用来执行多个任务。
* 使用线程池的好处是可以避免频繁地创建和销毁线程，从而提高程序的性能和效率。
* Java中的线程池通过Executor框架实现，可以使用`ThreadPoolExecutor`或  `ScheduledThreadPoolExecutor`类来创建线程池。
* `ThreadPoolExecutor`可以在程序启动时创建一定数量的线程，并且维护一个任务队列。当有新的任务到来时，线程池中的线程就会自动从任务队列中取出一个任务进行执行，当任务执行完毕后，线程又会自动返回线程池，等待下一个任务的到来。这样，线程的创建和销毁就大大减少了，同时也保证了并发任务的高效执行。
* `ScheduledThreadPoolExecutor`它继承`ThreadPoolExecutor`，可以按照一定的时间间隔定期执行任务，并且供了一些用于调度任务的方法如`schedule()`和`scheduleAtFixedRate()`。

## (47)Java ForkJoin

### ForkJoin
* ForkJoin是Java中用于实现并行计算的框架，它是一个线程池框架。
* 它通过将一个大任务拆分成若干个小任务，然后将这些小任务分配给不同的线程进行处理，最后将结果合并起来得到最终结果。

### RecursiveTask类：
* RecursiveTask是一个抽象类，它继承自ForkJoinTask类，并且实现了Future接口。它是ForkJoin框架中用于表示可以分解成更小任务的任务的基类之一。 RecursiveTask类compute()方法用于执行任务的实际计算。这个方法返回一个泛型类型的结果，表示这个任务的计算结果。 与普通的ForkJoinTask不同的是RecursiveTask在compute()方法中会递归地创建更小的子任务，并将它们提交给ForkJoinPool进行处理。在子任务的计算完成后，它们的结果会被合并起来得到最终的结果。
* 如果数组的大小小于等于阈值THRESHOLD，那么我们就对这个数组进行串行计算，否则就将数组拆分成两部分，分别创建两个ForkJoinExample对象，然后通过调用fork()方法将这两个对象提交给ForkJoinPool进行处理，并通过调用join()方法将它们的结果合并起来。

### ForkJoinPool类：
* ForkJoinPool是实现ForkJoin框架的线程池，它是一个ExecutorService的实现类。
* ForkJoinPool通过管理一组工作线程来执行ForkJoinTask。每个工作线程都维护了一个工作队列用于保存待执行的任务。当一个任务被提交给ForkJoinPool时，ForkJoinPool会选择一个工作线程来执行这个任务，如果这个任务还可以被分解成更小的子任务，那么这个线程就会将这个任务分解成多个子任务，并将它们加入到自己的工作队列中等待执行。
* 当一个工作线程的工作队列为空时，它会尝试从其他工作线程的工作队列中偷取一些任务来执行。这个偷取的过程被称为工作窃取算法"work-stealing"。这种机制可以保证ForkJoinPool中的所有线程都能够充分利用CPU资源，从而提高程序的性能。
* ForkJoinPool中可通过调用invoke()方法将一个任务提交给ForkJoinPool进行处理。当这个任务执行完成后，invoke()方法会返回这个任务的计算结果。
* 此外，ForkJoinPool还提供了一些方法，例如getParallelism()方法和getActiveThreadCount()方法，可以用于获取ForkJoinPool的一些状态信息。

## (48)Java 泛型

### 泛型
* Java中的泛型是一种在编译时期处理数据类型安全的机制。
* 它允许程序员在代码中定义一个通用的类、接口或方法，以便在实例化时可以指定具体的数据类型。
* 泛型的作用是增强代码的重用性和类型安全性。
* 使用泛型可以将数据类型的检查和转换从运行时移至编译时，从而可以在编译期就发现类型不匹配或错误的代码。
* 这样可以减少在运行时出现类型错误的可能性，提高代码的稳定性和可靠性。

### 泛型使用
* 泛型使用尖括号 <> 来定义类型参数，还可以使用通配符 ? 来表示不确定的类型。
* 通配符 ? 表示不确定的类型。这里可以添加null，因为其是一个特殊的类型，可以表示任何类型。

## (49)Java 反射

### 反射
* Java 反射（Reflection）是指在运行时动态地获取一个类的信息，并可以操作该类的属性、方法、构造函数等。
* 反射使得 Java 程序可以在运行时检查任意一个对象所属的类的属性和方法，并可以在运行时修改该类的属性和调用其方法，而不需要在编译期确定这些操作。
* 通过反射，可以访问类的私有属性和方法，甚至可以通过反射创建新的类实例。

### Java 反射提供了四个主要的类
* Class、Constructor、Field 和 Method。
* 其中，Class 类表示一个类或接口的运行时类型
* Constructor 类表示一个类的构造函数。
* Field 类提供有关类或接口的单个字段的信息，以及对它的动态访问权限。
* Method 类表示一个类的方法。

### 反射获取类信息的常用方法
* Class.getName()：获取类的名称。
* Class.getModifiers()：获取类的修饰符。
* Class.getSuperclass()：获取类的父类。
* Class.getInterfaces()：获取类实现的接口。
* Class.getConstructors()：获取类的所有公共构造函数。
* Class.getDeclaredConstructors()：获取类的所有构造函数（包括私有构造函数）。
* Class.getMethods()：获取类的所有公共方法。
* Class.getDeclaredMethods()：获取类的所有方法（包括私有方法）。
* Class.getFields()：获取类的所有公共属性。
* Class.getDeclaredFields()：获取类的所有属性（包括私有属性）。

### 反射基本步骤
1. 获取 Class 对象：可以通过 Class 类的 forName() 方法获取一个类的 Class 对象，也可以通过对象的 getClass() 方法获取一个对象的 Class 对象。还可以通过类名.class获取。
2. 获取构造函数：可以使用 Class 类的 getConstructor() 或 getDeclaredConstructor() 方法获取一个类的构造函数。
3. 设置或获取属性值：可以使用 Field 类的 set() 和 get() 方法设置或获取一个属性的值。
4. 获取方法：可以使用 Class 类的 getMethod() 或 getDeclaredMethod() 方法获取一个类的方法。
5. 调用方法：可以使用 Method 类的 invoke() 方法调用一个方法。

### 反射注意事项
* Java 反射是一个非常强大的工具，它可以让我们在运行时动态地获取和修改一个类的信息，创建对象，调用方法，获取和设置属性值等。
* 可以实现灵活的程序设计，尤其是在框架和插件式的应用程序中。但有些点需要注意：
* 避免滥用反射：反射虽然强大，但在大多数情况下必须使用反射的情况很少，反射会影响代码的性能和可读性。只有在必要的情况下才应该使用反射。
* 安全性问题：由于反射可以绕过访问修饰符的限制，因此在使用反射时需要特别小心。
* 性能问题：反射操作的性能比普通的方法调用要慢很多，因此在性能敏感的场合下应该尽量避免使用反射。

## (50)Java IO概念

### IO
* IO是**Input/Output的缩写，表示输入输出**。
* 在计算机编程中，**输入输出是程序与外部世界交互的方式**。
* 程序**通常需要读取外部数据并处理它**，然后将**处理结果输出到外部**。
* Java提供了一个**用于读写数据的标准库，称为Java IO**。
* 它提供了**一组类和接口**，可以**读写文件、网络流、内存流**等等。
* Java IO是**基于流（Stream）模型的**，它将数据看作是**一系列连续的字节流，从而进行读写操作**。
* Java IO在**处理IO操作时，是阻塞式的**，即**IO操作会一直阻塞直到数据完全读取或写入**。
* Java IO是Java中非常重要的一个部分，它提供了**许多类和接口来处理文件、网络和其他数据流**。
* 但除了Java IO之外，Java还**提供了NIO（New IO）和NIO2（New IO 2）两个新的IO API**，它们提供了**更加高效和灵活的IO操作方式**。
* 在选择Java IO或NIO时需要**根据具体的需求来选择适合的API**。对于一些**简单的IO操作**，可以使用Java IO，它的代码**简单易懂，适合快速开发**。
* 而对于一些**高并发、大数据量的IO操作**，应该**使用NIO或NIO2，它们提供了更高效的IO操作方式**。

### 流
* Java IO中最重要的概念之一是**流(Stream)**。
* 流是**一种数据传输方式，就像水流一样**。
* 数据从**源头(比如文件、网络)流向程序**，程序对数据**进行处理**，然后数据再从**程序流向目标(比如文件、网络)**。
* 流的作用是将**数据传输过来**，以便程序能够读取、处理、写出数据。
* Java中的流可按照数据单位的不同分为两种类型：**字节流和字符流**。
* Java中的流还可按照功能划分的不同分为两种类型：**节点流和处理流**。

#### 字节流
* 字节流用于**读写二进制数据**。字节流的**基本单位是字节(byte)**。
* Java中提供了两个基本的字节流：InputStream和OutputStream。
* InputStream：字节输入流，用于从**输入源中读取数据**。
* OutputStream：字节输出流，用于向**输出源中写入数据**。

#### 字符流
* 字符流用于**读写字符数据**。字符流的**基本单位是字符(char)**。
* Java中提供了两个基本的字符流：Reader和Writer。
* Reader：字符输入流，用于从**输入源中读取字符数据**。
* Writer：字符输出流，用于向**输出源中写入字符数据**。

#### 节点流
* 节点流：直接**与数据源相连的流，也称为低级流**。
* 节点流可以**从输入源中读取数据，或者向输出源中写入数据**。

#### 处理流
* 处理流：通过**对其他流进行包装，构建而成的流，也称为高级流**。
* 处理流**不能从输入源中读取数据**，或者向输出源中写入数据，它们只是**通过包装节点流的方式对其进行扩展或转换**。

### NIO
* NIO（New IO）则是**基于通道（Channel）和缓冲区（Buffer）的模型**。
* 通道是**双向**的，可以进行**读写操作**，而缓冲区则是用于**临时存储数据的区域**。
* NIO中的数据操作是**非阻塞的**，即**IO操作不会一直阻塞等待数据的到来或发送完成**。
* 当数据准备好时，通道会**通知程序进行数据的读取或写入**。
* 另外，NIO还**提供了选择器（Selector）机制**，可以让程序**同时处理多个通道的IO事件**。

### NIO2
* NIO2是JDK 7中**新引入的API**，它扩展了NIO API，提供了更多**便利的功能和更高级别的抽象**。
* **主要特性包括**：
  * 文件系统访问：NIO2**提供了Path和Files两个类**，用于**更方便地访问文件系统**。
  * 异步IO操作：NIO2提供了**异步IO操作的支持**，可以让程序更好地利用系统资源。
  * 改进的文件通道：NIO2**提供了FileChannel类的扩展，可以支持更多的操作，例如文件锁定、内存映射等**。
  * 改进的网络通道：NIO2**提供了AsynchronousSocketChannel和AsynchronousServerSocketChannel两个类**，可以支持**异步网络IO操作**。
 * NIO2的引入进一步**提高了Java在处理IO操作方面的能力**，使得Java在高并发、大数据量、异步IO等方面**更加灵活和强大**。

## (51)Java 文件IO

### 文件IO
* Java IO中的文件IO是指读写文件的操作。
* 在Java中，文件IO主要通过File、FileInputStream、FileOutputStream、FileReader和FileWriter等类实现。

#### File类
* File类用于表示文件和目录路径名的抽象表示。
* File类提供了多个构造方法，可以根据需要选择不同的构造方法来创建File对象。
* 常用的构造方法：
  * File(String pathname)：根据给定的路径名字符串创建一个新的File对象。路径可以是绝对路径或相对路径。
  * File(String parent, String child)：根据给定的父路径字符串和子路径字符串创建一个新的File对象。父路径可以是绝对路径或相对路径，子路径是相对于父路径的。
  * File(File parent, String child)：根据给定的父路径File对象和子路径字符串创建一个新的File对象。子路径是相对于父路径的。
```java
// 根据给定的路径名字符串创建File对象
File file1 = new File("C:\\example.txt");

// 根据给定的父路径和子路径字符串创建File对象
File file2 = new File("C:\\temp", "example.txt");

// 根据给定的父路径File对象和子路径字符串创建File对象
File parentDir = new File("C:\\temp");
File file3 = new File(parentDir, "example.txt");
```
* 它提供了一组方法，可以查询文件属性、创建和删除文件、以及遍历文件系统中的文件和目录等。
  * exists()：检查文件或目录是否存在。
  * isFile()：检查是否为文件。
  * isDirectory()：检查是否为目录。
  * getName()：获取文件或目录的名称。
  * getPath()：获取文件或目录的路径。
  * getAbsolutePath()：获取文件或目录的绝对路径。
  * getParent()：获取文件或目录的父目录路径。
  * list()：获取目录下的文件和子目录的名称数组。
  * listFiles()：获取目录下的文件和子目录的File对象数组。
  * mkdir()：创建目录。
  * mkdirs()：创建目录及其所有不存在的父目录。
  * delete()：删除文件或目录。
  * renameTo(File dest)：重命名文件或目录，将其移动到指定的目录下。

#### FileInputStream和FileOutputStream类
* ileInputStream和FileOutputStream是字节流，用于读取和写入文件。
* 它们的构造函数都需要传入File对象或文件路径名。

#### FileReader和FileWriter类
* FileReader和FileWriter是字符流，用于读取和写入文件。
* 它们的构造函数也需要传入File对象或文件路径名。

## (52)Java 缓冲流

### 缓冲流
* 在读写数据时，经常会发现IO操作非常耗时，这是因为每次读写操作都会涉及到磁盘或网络IO，而这种IO操作是非常慢的。
* 为了提高IO操作的效率，Java提供了缓冲流。
* 缓冲流是基于字节流和字符流之上的一层，是处理流的一种，它可以将数据缓存到内存中，减少实际IO操作的次数。
* 在读取数据时，缓冲流会预先读取一定量的数据到缓存中，当应用程序需要读取数据时，缓冲流会先从缓存中读取，如果缓存中没有数据了，就再去进行实际的IO操作。
* 在Java中，缓冲流有四种类型：
  * **BufferedInputStream**：字节缓冲输入流。
  * **BufferedOutputStream**：字节缓冲输出流。
  * **BufferedReader**：字符缓冲输入流。
  * **BufferedWriter**：字符缓冲输出流。

#### 缓冲字节流
* BufferedInputStream和BufferedOutputStream常用方法：
* 构造方法：
  * public BufferedInputStream(InputStream in): 创建一个新的缓冲输入流，以读取指定的输入流。
  * public BufferedOutputStream(OutputStream out): 创建一个新的缓冲输出流，以将数据写入指定的底层输出流。
* 读取数据和写入数据：
  * public int read() throws IOException: 从输入流中读取下一个字节数据。
  * public int read(byte[] b, int off, int len) throws IOException: 从输入流中读取一定量的字节，并将其存储在缓冲区数组 b 中。
  * public void write(int b) throws IOException: 将指定的字节写入此缓冲的输出流。
  * public void write(byte[] b, int off, int len) throws IOException: 将指定字节数组中从偏移量 off 开始的 len 个字节写入此缓冲输出流。
* 刷新缓存区：
  * public void flush() throws IOException: 刷新缓冲的输出流，强制将所有缓存的输出字节写入到底层输出流中。
* 关闭流：
  * public void close() throws IOException: 关闭缓冲的输入流或输出流，同时会关闭底层流。

#### 缓冲字符流
* BufferedReader和BufferedWriter常用方法
* 构造方法：
  * public BufferedReader(Reader in): 创建一个新的缓冲输入流，以读取指定的输入流。
  * public BufferedWriter(Writer out): 创建一个新的缓冲输出流，以将数据写入指定的底层输出流。
* 读取数据和写入数据：
  * public int read() throws IOException: 从输入流中读取一个字符。
  * public int read(char[] cbuf, int off, int len) throws IOException: 从输入流中读取一定量的字符，并将其存储在缓冲区数组 cbuf 中。
  * public void write(int c) throws IOException: 将指定的字符写入此缓冲的输出流。
  * public void write(char[] cbuf, int off, int len) throws IOException: 将指定字符数组中从偏移量 off 开始的 len 个字符写入此缓冲输出流。
* 刷新缓存区：
  * public void flush() throws IOException: 刷新缓冲的输出流，强制将所有缓存的输出字符写入到底层输出流中。
* 关闭流：
  * public void close() throws IOException: 关闭缓冲的输入流或输出流，同时会关闭底层流。

## (53)Java 对象流

### 对象流
* Java对象流是一种I/O流，可以用于读取和写入Java对象。
* 这些对象可以是任何Java类的实例，只要这些类实现了java.io.Serializable接口。

### 序列化和反序列化
* 序列化是将Java对象转换为字节序列的过程，这些字节序列可以在文件或网络连接中进行传输。
* 反序列化是将字节序列转换回Java对象的过程。
* ObjectOutputStream和ObjectInputStream可以用于将Java对象序列化为字节流并将其写入文件或网络连接，也可以将字节流反序列化为Java对象。
* 它们提供了一种方便的方式来持久化Java对象。

### Serializable接口
* 要使用对象流，Java类必须实现java.io.Serializable接口。
* Serializable接口是一个标记接口，它没有任何方法或字段，仅用于表示类可以被序列化。
* 在实现Serializable接口时，需要注意以下几点：
* 所有字段都必须是可序列化的。如果一个字段是一个对象，那么该对象的类也必须实现Serializable接口。
* transient关键字可以用于标记不希望序列化的字段。
* 如果一个类的父类没有实现Serializable接口，则需要确保父类的无参构造函数可以被调用。

### 序列化版本控制
* 在序列化和反序列化对象时，如果对象的类发生更改，则可能会发生版本控制问题。
* 例如，如果我们在Person类中添加了一个新字段，则在反序列化时导致不兼容，会出现异常。
* 为了解决这个问题，我们可以使用serialVersionUID。
* 每个可序列化的类都有一个serialVersionUID字段。
* 这样，当我们尝试反序列化旧版本的类时，JVM可以检查serialVersionUID并确定类是否与序列化的版本匹配。

### 避免序列化不必要的属性
* 在某些情况下，可能希望不序列化对象的某些属性。
* 例如，忽略某些敏感属性，以提高安全性。
* 在这种情况下，可以使用transient关键字修饰属性，从而防止它被序列化。

### 自定义序列化和反序列化
* 有时候，Java对象可能包含不支持序列化的属性或字段，或者我们希望控制序列化和反序列化过程。
* 在这种情况下，我们可以自定义序列化和反序列化过程。
* 自定义序列化的类需要继承Serializable接口，并添加相应的方法。
* 如：writeObject方法、readObject方法、readObjectNoData方法等。
* Serializable接口中没有任何成员，这些方法都是可选的并不强制要求，但一般需要定义前2个方法。

## (54)Java Socket

### Socket概念
* Socket（套接字）网络应用进程之间通信需要API接口，目前在Internet中使用最广泛的网络应用编程接口就是Socket接口。
* 在计算机网络中，Socket是一种抽象的概念，它不仅仅是一种网络通信协议的实现，还是一种通信机制的封装，可以在不同的操作系统和编程语言中使用。
* 在Java中，Socket是一个类，它提供了一种用于创建网络应用程序的接口。

### TCP Socket编程
* TCP Socket编程是指使用TCP协议进行网络通信的编程方式。
* 在Java中，可以使用Socket类和ServerSocket类来实现TCP Socket编程。
* 基本流程：
  * 服务器创建ServerSocket对象并监听某个端口。
  * 客户端创建Socket对象，指定服务器IP地址和端口号。
  * 客户端向服务器发送连接请求。
  * 服务器接受连接请求，建立连接。
  * 通过Socket对象进行数据传输。
  * 传输结束后，关闭连接。

### UDP Socket编程
* UDP是一种无连接的协议。
* UDP Socket编程是指使用UDP协议进行网络通信的编程方式。
* 在Java中，可以使用DatagramSocket类和DatagramPacket类来实现UDP Socket编程。
* 它提供了不可靠的、无序的、基于数据包的数据传输服务。
* 使用UDP套接字，客户端和服务器可以直接发送和接收数据包。以下是UDP套接字的基本流程：
* 创建DatagramSocket对象：使用DatagramSocket类的构造函数创建UDP套接字。
* 创建DatagramPacket对象：使用DatagramPacket类的构造函数创建UDP数据包对象。
* 发送数据：使用DatagramSocket类的send()方法发送数据。
* 接收数据：使用DatagramSocket类的receive()方法接收数据。
* 关闭套接字：使用DatagramSocket类的close()方法关闭UDP套接字。

# Spring框架

## Spring介绍

### Spring框架介绍
* Spring 是于 2003年6月 兴起的一个轻量级的 Java 开发框架，它是为了解决企业应用开发的复杂性而创建的。Spring 的核心是**控制反转（IoC）**和**面向切面编程（AOP）**。
* Spring 是可以在 Java SE/EE 中使用的轻量级开源框架。
* Spring 的主要作用就是为代码“解耦”，降低代码间的耦合度。就是让对象和对象（模块和模块）之间关系不是使用代码关联，而是通过配置来说明。即在 Spring 中说明对象（模块）的关系。
* Spring 根据代码的功能特点，使用 IoC 降低业务对象之间耦合度。
* IoC 使得主业务在相互调用过程中，不用再自己维护关系了，即不用再自己创建要使用的对象了。
* 而是把创建对象的权利交给框架，也就是指将对象的创建、对象的存储、对象的管理交给了Spring容器。
* Spring容器是Spring中的一个核心模块，用于管理对象，底层可以理解为是一个Map集合。
* 而 AOP 使得系统级服务得到了最大复用，将那些与业务无关，却为业务模块所共同调用的逻辑或责任分开封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可操作性和可维护性。

### Spring优点？
* 它是一个容器管理对象，容器是装东西的，Spring 容器不装文本，数字。装的是对象。Spring 是存储对象的容器。
1. 轻量
  Spring 核心功能的所需的 jar 总共在 3M 左右。Spring 框架运行占用的资源少，运行效率高。不依赖其他 jar
2. 针对接口编程，解耦合
  Spring 提供了 Ioc 控制反转，由容器管理对象，对象的依赖关系。原来在程序代码中的对象创建方式，现在由容器完成。对象之间的依赖解耦合。
3. AOP 编程的支持
  通过 Spring 提供的 AOP 功能，方便进行面向切面的编程，许多不容易用传统 OOP （面向对象程序设计）实现的功能可以通过 AOP 轻松应付
  在 Spring 中，开发人员可以从繁杂的事务管理代码中解脱出来，通过声明式方式灵活地进行事务的管理，提高开发效率和质量。
4. 方便集成各种优秀框架
  Spring 不排斥各种优秀的开源框架，相反 Spring 可以降低各种框架的使用难度，Spring提供了对各种优秀框架（如 Struts,Hibernate、MyBatis）等的直接支持。简化框架的使用。
  Spring 像插线板一样，其他框架是插头，可以容易的组合到一起。需要使用哪个框架，就把这个插头放入插线板。不需要可以轻易的移除。

### Spring模块介绍
* Spring Context: 定义上下文信息即IOC容器
* Spring Beans: Bean工厂与Bean装配
* Spring Context Support: 对Spring IoC的拓展支持
* Spring Expression: SpEL 表达式语言
* Spring Context indexer: Spring 类管理组件扫描和ClassPath扫描

### Spring总结
* Spring 主要学习两个核心部分：IoC 和AOP
* IoC：控制反转，把创建对象过程交给 Spring 进行管理
* AOP：面向切面，不修改源代码进行功能增强

## IoC控制反转

### IoC控制反转
* 控制反转（IoC，Inversion of Control），是一个概念，是一种思想。
* 指将传统上由程序代码直接操控的对象调用权交给容器，通过容器来实现对象的装配和管理。
* 控制反转就是对对象控制权的转移，从程序代码本身反转到了外部容器。通过容器实现对象的创建，属性赋值，依赖的管理。
* 当前比较流行的实现方式是依赖注入。
* 依赖：classA 类中含有 classB 的实例，在 classA 中调用 classB 的方法完成功能，即 classA对 classB 有依赖。
* IoC 的实现：
  * 依赖注入：DI(Dependency Injection)，程序代码不做定位查询，这些工作由容器自行完成。
  * 依赖注入 DI 是指程序运行过程中，若需要调用另一个对象协助时，无须在代码中创建被调用者，而是依赖于外部容器，由外部容器创建后传递给程序。
  * Spring 的依赖注入对调用者与被调用者几乎没有任何要求，完全支持对象之间依赖关系的管理。
* Spring 框架使用依赖注入（DI）实现 IoC。
* Spring 容器是一个超级大工厂，负责创建、管理所有的 Java 对象，这些 Java 对象被称为 Bean（单例）。
* Spring 容器管理着容器中 Bean 之间的依赖关系，Spring 使用“依赖注入”的方式来管理 Bean 之间的依赖关系。
* 使用 IoC 实现对象之间的解耦和。

### IOC底层
* IOC 思想基于 IOC 容器完成。 IOC 容器底层就是对象工厂，Spring提供的IOC容器实现的两种方式（两个接口）
  * BeanFactory接口：IOC容器基本实现是Spring内部接口的使用接口，不提供给开发人员进行使用（加载配置文件时候不会创建对象，在获取对象时才会创建对象。
  * ApplicationContext接口：BeanFactory接口的子接口，提供更多更强大的功能，提供给开发人员使用（加载配置文件时候就会把在配置文件对象进行创建）推荐使用！
* ApplicationContext通常的实现
  * FileSystemXmlApplicationContext ：此容器从一个XML文件中加载beans的定义，XML Bean配置文件的全路径名必须提供给它的构造函数。
  * ClassPathXmlApplicationContext：此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置。
* IOC的优点
  * IOC 或 依赖注入把应用的代码量降到最低。最小的代价和最小的侵入性使松散耦合得以实现。
  * IOC 容器支持加载服务时的饿汉式初始化和懒加载。

## 基于XML的DI

### 注入分类
* bean 实例在调用无参构造器创建对象后，就要对 bean 对象的属性进行初始化。初始化是由IoC容器自动完成的，称为注入。
* 根据注入方式的不同，常用的有两类：Set 注入、构造注入

#### Set 注入
* Set 注入也叫设值注入，通过 setter 方法传入被调用者的实例。
* 简单类型（Java中的基本数据类型和String类型）
* 引用类型
  * 当指定 bean 的某属性值为另一 bean 的实例时，通过 ref 指定它们间的引用关系。ref的值必须为某 bean 的 id 值
  * 使用<bean>标签声明XXX对象
  * 在User对象的声明中使用<bean>标签的ref属性
#### 有参构造注入
* 构造注入是指，在构造调用者实例的同时，完成被调用者的实例化。即使用构造器设置依赖关系。
在构造方法中给属性赋值构造注入使用<constructor-arg>标签
* <constructor-arg>表示构造方法一个参数。
* < constructor-arg>标签属性:
  * name:表示构造方法的形参名
  * index:表示构造方法的参数的位置,参数从左往右位置是0, 1 ,2的顺序
  * value:构造方法的形参类型是简单类型的，使用value
  * ref:构造方法的形参类型是引用类型的,使用ref

### 引用类型属性自动注入
* 对于引用类型属性的注入，也可不在配置文件中显示的注入。
* 可以通过为<bean/>标签设置 autowire 属性值，为引用类型属性进行隐式自动注入（默认是不自动注入引用类型属性）。
* 根据自动注入判断标准的不同，可以分为两种：
  * byName：根据名称自动注入
  * byType：根据类型自动注入
* byName
根据被注入属性的名称作为 Bean 名称作为依赖查找，并将对象设置到该属性
* byType
根据被注入属性的类型作为依赖类型进行依赖查找，并将该对象设置到该属性

### 多配置文件
* 多配置文件优点
  * 多配置文件的大小比在一个文件中配置大小要小。
  * 避免多人竞争带来的冲突。
* 多配置文件分配方式：
  * 按功能模块，一个模块一个配置文件
  * 按类的功能，数据库相关的配置一个配置文件， 做事务的功能一个配置文件…​
* 包含关系的配置文件：
  * 主配置文件:包含其他配置文件的配置文件，一般是不定义对象。
  * 语法:`<import resource=“其他配置文件的路径"/>`
  * 关键字:"classpath":类路径
  * 在spring的配置文件中要指定其他文件的位置，需要使用classpath,告诉spring到哪去读取配置文件。

## DI(注解方式)

### DI(注解方式)
* 需要在 Spring 配置文件中配置组件扫描器，用于在指定的包中扫描相关注解。
* 组件扫描(component-scan) ,组件就是java对象。
* base-package:在指定的包中的相关注解。
* component-scan工作方式: Spring会扫描base-package指定的包，找到包中和子包中的所有类的注解。按照注解的功能创建对象，或进行属性赋值。
```xml
<context:component-scan base-package="User"/>
```
指定多个包
```xml
<context: component-scan base-package="User"/>
<context :component-scan base-package="User1"/>
<!--分隔符(;或,)可以分隔多个包名-->
<context: component-scan base-package="User;User1"/>
<!--或使用顶级的父包-->
<context : component-scan base-package="xxx"/>
```

### @Component
* @Component:等同于<bean>
  * 属性:value就是对象的名称，也就是bean的id值，value的值是唯一的。
  * 不指定对象名称,由Spring提供默认名称:类名的首字母小写
  * 位置:写在类的上面
```xml
@Component(value = "user")
          ||
<bean id="user" class="xxx"/>
```
```java
@Component(value ="user")
public class User {}
```
* 另外，Spring 还提供了 3 个创建对象的注解：
  * `@Controller` 用于对 Controller 进行注解
  * `@Repository` 用于对 DAO 进行注解
  * `@Service` 用于对 Service 进行注解
* 这三个注解与@Component 都可以创建对象，但这三个注解有些区别
* @Repository，@Service，@Controller 是对@Component 注解的细化，标注不同层的对象。

### @Value
* @Value:简单类型的属性赋值
  * 属性:value是String类型的，表示简单类型的属性值。
  * 位置:推荐写在属性定义的上面。
```java
@Component
public class User {
    @Value(value = "张三")
    private String name;
    @Value(value ="18")
    private Integer age;}
```

### @Autowired
* @Autowired: Spring框架提供的注解，实现引用类型赋值。默认使用的是byType注入。
  * Spring中通过注解给引用类型赋值，使用的是自动注入原理，支持byName，byType
  * 位置:推荐写在属性定义的上面。
```java
  @Component
  public class User {
      @Autowired
      private Xxx xxx;
```

### @Autowired与@Qualifier
* @Autowired byName方式:
  * 属性上面加入@Qualifier(value="xxx"):表示使用指定名称的bean完成赋值。
  * 属性上面加入@Autowired
```java
  @Component
  public class User {
      @Qualifier("xxx")
      @Autowired
      private Xxx xxx;
```

### @Resource
* @Resource:来自JDK中的注解，支持byName，byType。默认为byName。
  * 位置:推荐写在属性定义的上面。
  * 注意:默认为byName:先使用byName自动注入，如果byName注入失败，再使用byType
```java
@Component
public class User {
    @Resource
    private Xxx xxx;
```
  * 如只使用byName方式,需要增加一个name属性
```java
  @Component
  public class User {
      @Resource(name="xxx")
      private Xxx xxx;
```

### 注解对比XML
* 注解方式：
  * 优点：方便、直观、高效（代码少，没有配置文件的书写那么复杂）。
  * 缺点：以硬编码的方式写入到 Java 代码中。
* XML 方式：
  * 优点：配置和代码是分离的。
  * 缺点：编写麻烦，效率低。

## AOP 面向切面编程

### AOP（Aspect Orient Programming）面向切面编程
* 术语：
  * Aspect:切面，表示增强的功能，就是一堆代码，完成某个一个功能。常见的切面功能有日志管理/权限控制等等。
  * JoinPoint:连接点，连接业务方法和切面的位置。就某类中的业务方法
  * Advice:通知，通知表示切面在特定连接点采取的操作。
  * Pointcut:切入点，指多个连接点方法的集合。

### AOP实现
* AOP的技术实现框架:
  * Spring AOP：Spring在内部实现了AOP规范。但开发中很少使用Spring的AOP规范，因其较为笨重。
  * AspectJ: 开源的AOP框架。Spring框架中集成了AspectJ框架，通过Spring就能使用AspectJ的功能。
* AspectJ框架实现AOP有两种方式:
  * 使用xml的配置文件：配置全局事务
  * 使用注解：AspectJ有5个注解
```
@Before前置通知
@AfterReturning后置通知
@Around环绕通知
@AfterThrowing异常通知
@After最终通知
```

### 切入点表达式
* AspectJ支持三种通配符：
  * `*` 匹配任意字符，只匹配一个元素
  * `..` 匹配任意字符，可以匹配多个元素，在表示类时，必须和 * 联合使用
  * `+` 表示按照类型匹配指定类的所有类，必须跟在类名后面，如com.User.User+,表示继承该类的所有子类包括本身
* 表达式的原型:
  * execution(<访问修饰符><方法返回值><包名称.类.方法(参数)><异常>)
  * execution代表方法的执行
  * 访问修饰符和异常可以省略
  * 例如表达式execution(* User.User.*(..))
    * 意思User类中的所有方法。
    * 第一个“*”代表任意访问修饰符及任意方法返回值。
    * 第二个“*”代表任意方法。
    * “..”匹配任意数量、任意类型的参数。
  * 目标类、接口与该切面类在同一个包中可以省略包名。
```
表达式    execution(public * User.*(..))
含义      User类中的所有公有方法

表达式   execution(* User.User.*.*(..)) 
含义     匹配 User.User 包下的所有类的所有方法
```
  * 在AspectJ中，切入点表达式可以通过 “&&”、“||”、“!”等操作符结合起来。
```
表达式    execution (* *.get(int,..)) || execution(* *.insert(int,..))
含义      匹配任意类中第一个参数为int类型的get方法或insert方法

表达式    !execution (* *.get(int,..))
含义      匹配任意类中第一个参数不是为int类型的get方法
```

### AOP 快速入门
* 操作流程
  * 引入 AOP 相关依赖
    * AspectJ 依赖
```xml
<dependency>
    <groupId>org.aspectj</groupId>
    <artifactId>aspectjrt</artifactId>
    <version>1.9.9.1</version>
</dependency>
<dependency>
    <groupId>org.aspectj</groupId>
    <artifactId>aspectjweaver</artifactId>
    <version>1.9.9.1</version>
</dependency>
```
  * 创建目标类:接口和实现类。要做的是给类中的方法增加功能
  * 创建切面类:普通类
    * 在类上面加上@Aspect
    * 注意:如使用注解方式的话需要加上@Component
    * 在类中定义方法，方法就是切面要执行的功能代码在方法的上面加入Aspect中的相关注解，例如@Before注解，但需要指定切入点表达式execution()
  * Spring的配置文件(推荐使用注解)
    * 声明目标对象(可以使用注解)
    * 声明切面类对象(可以使用注解)
    * 声明Aspect框架中的自动代理生成器标签:<aop:aspectj-autoproxy></aop:aspectj-autoproxy>
  * 创建测试类，从IoC容器中获取目标对象(实际就是代理对象)进行测试即可。

### AspectJ 注解

#### @Pointcut:切入点
* 属性:value切入点表达式。
* 位置:放在方法上面
* 注意:使用@Pointcut定义在一个方法的上面，这个方法的名称就是切入点表达式的别名。
```java
@Pointcut("execution(* com.lalapodo.Service.UserService.*(..))")
private void pointcut(){}
```

#### @Before:前置通知
* 属性:value切入点表达式。
* 位置:放在方法上面
* 注意:在目标方法之前先执行,不改变目标方法执行结果,不影响目标方法的执行。
* 参数:可以有JoinPoint参数
```java
@Aspect
@Component
public class UserAop {
    @Before(value="execution(* com.lalapodo.Service.UserService.*(..))")//定位业务方法
    public void insertUser(JoinPoint joinPoint){
        System.out.println(joinPoint);
        System.out.println("插入了一个User");
    }
}
@Service
public class UserServiceImpl implements UserService {
    @Override
    public void getUser() {
        System.out.println("get了User");
    }
}
```

#### @AfterReturning:后置通知
* 属性:value切入点表达式。
  * returning自定义变量，表示目标方法返回值。
* 位置:放在方法上面
* 注意:在目标方法之后执行,能够获取到目标方法的返回值，可以根据这个返回值做不同的处理功能。
```java
@AfterReturning(value = "pointcut()",returning = "res")
public void insertUser(Object res) {
    System.out.println(res);
    System.out.println("插入了一个User");
}
```

#### @Around:环绕通知
* 属性:value切入点表达式。
* 位置:放在方法上面
* 注意:在目标方法的前后都能执行,会影响最后的调用结果。
* 参数:可以有ProceedingJoinPoint。
  * 作用:执行目标方法
```java
@Around("pointcut()")
public void insertUser(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
    proceedingJoinPoint.proceed();
    System.out.println("插入了一个User");
}
```

#### @AfterThrowing:异常通知
* 属性:value切入点表达式。
  * throwing自定义变量，表示目标方法抛出的异常对象。
* 位置:放在方法上面
* 注意:在目标方法抛出异常时执行,用于监控目标方法执行时是不是有异常。
```java
@AfterThrowing(value = "pointcut()",throwing = "exception")
public void insertUser(Exception exception) {
    System.out.println(exception);
    System.out.println("插入了一个User");
}
```

#### @After:最终通知
* 属性:value切入点表达式。
* 位置:放在方法上面
* 注意:总是会执行,顺序为在目标方法之后执行
```java
@After("pointcut()")
public void insertUser() {
    System.out.println("插入了一个User");
}
```

## Spring事务

### Spring 集成 Mybatis
* 操作流程
  * 引入 Mybatis与数据库相关依赖
  * 创建配置类
  * Config.java
  * SqlConfig.java
  * MybatisConfig.java
  * 创建实体类:映射数据库表
  * 创建Mapper
  * Service实现即可

### Spring事务
* 数据库事务是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。
* 事务由事务开始与事务结束之间执行的全部数据库操作组成。

#### Spring事务优点:
* 以事务的方式对数据库进行访问，有如下的优点:
  * 把逻辑相关的操作分成了一个组
  * 在数据永久改变前，可以预览数据变化
  * 能够保证数据的读一致性。

#### Spring的事务:
* Spring支持两种事务方式:
  * 分别是编程式事务和声明式事务，后者最常见
  * 声明式事务通常情况下只需一个@Transactional注解
* 声明式事务: 声明式事务将事务管理代码从业务方法中抽离了出来，以声明式的方式来实现事务管理。
* 编程式事务: 编程式事务，必须在每个业务操作中包含额外的事务管理代码，就导致代码看起来非常的臃肿。

#### Spring的事务配置:
* 操作流程
  * 在需要开启事务的方法上加上@Transactional注解
  * Config.java
  * SqlConfig.java

#### 事务的传播行为属性:
* 事务的传播行为可以由传播属性指定，Spring定义了7种类型的传播行为。其中最常用的是REQUIRED和REQUIRES_NEW。
* 事务的传播行为可以在@Transactional注解的propagation属性中定义。
```java
PROPAGATION_REQUIRED -- 默认行为。支持当前事务，如果当前没有事务，就新建一个事务。
PROPAGATION_REQUIRES_NEW -- 新建事务，如果当前存在事务，把当前事务挂起。
PROPAGATION_SUPPORTS -- 支持当前事务，如果当前没有事务，就以非事务方式执行。
PROPAGATION_NOT_SUPPORTED -- 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
PROPAGATION_MANDATORY -- 支持当前事务，如果当前没有事务，就抛出异常。
PROPAGATION_NEVER -- 以非事务方式执行，如果当前存在事务，则抛出异常。
PROPAGATION_NESTED -- 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。
```
#### 事务的隔离级别:
* 事务的隔离级别可以通过隔离级别事务属性(isolation)指定。
```java
DEFAULT -- 数据库默认的事务隔离级别。
READ_UNCOMMITTED -- 这是事务最低的隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读。
READ_COMMITTED -- 保证一个事务修改的数据提交后才能被另外一个事务读取，另外一个事务不能读取该事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻像读。
REPEATABLE_READ -- 这种事务隔离级别可以防止脏读、不可重复读，但是可能出现幻像读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了不可重复读。
SERIALIZABLE -- 这是花费最高代价但是最可靠的事务隔离级别，事务被处理为顺序执行。除了防止脏读、不可重复读外，还避免了幻像读
```
#### 事务的属性:
* 事务的属性可以在**@Transactional注解**中定义。
* 参数名称: 功能描述
  * readOnly: 该属性用于设置当前事务是否为只读事务，设置为true表示只读，false则表示可读写，默认值为false
  * rollbackFor: 该属性用于设置需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，则进行事务回滚
  * rollbackForClassName: 该属性用于设置需要进行回滚的异常类名称数组
  * noRollbackFor: 该属性用于设置不需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，不进行事务回滚
  * noRollbackForClassName: 该属性用于设置不需要进行回滚的异常类名称数组
  * isolation: 该属性用于设置事务隔离级别
  * propagation: 该属性用于设置事务的传播行为
  * timeout: 该属性用于设置事务的超时秒数，默认值为-1表示永不超时

#### @Transactional注意:
* Spring官方建议在具体的类（或类的方法）上使用 @Transactional 注解，而不要使用在类所要实现的任何接口上。
  * 你当然可以在接口上使用 @Transactional 注解，但是这将只能当你设置了基于接口的代理时它才生效。
* @Transactional 注解可以被应用于接口定义和接口方法、类定义和类的 public 方法上。
* @Transactional 只能被应用到 public 方法上, 对于其它非public的方法,如果使用了@Transactional也不会报错,但方法没有事务功能。

# SpringMVC

## SpringMVC介绍

### MVC模式
* MVC模式（Model–view–controller）是软件工程中的一种软件架构模式，把软件系统分为三个基本部分：模型（Model）、视图（View）和控制器（Controller）。
* MVC模式最早在1978年提出。MVC模式的目的是实现一种动态的程序设计，使后续对程序的修改和扩展简化，并且使程序某一部分的重复利用成为可能。

### 组件的互动
* 模型（Model） 用于封装与应用程序的业务逻辑相关的数据以及对数据的处理方法。
  * “ Model ”有对数据直接访问的权力，例如对数据库的访问。
  * “ Model ”不依赖“ View ”和“ Controller ”，也就是说， Model 不关心它会被如何显示或是如何被操作。
* 视图（View）能够实现数据有目的的显示。
* 控制器（Controller）起到不同层面间的组织作用，用于控制应用程序的流程。它处理事件并作出响应。

### SpringMVC
* Spring MVC属于SpringFrameWork的后续产品，已经融合在Spring Web Flow里面。
* Spring 框架提供了构建 Web 应用程序的全功能 MVC 模块。
* 使用 Spring 可插入的 MVC 架构，从而在使用Spring进行WEB开发时，可以选择使用Spring的Spring MVC框架。

### SpringMVC 优点
* 基于 MVC 架构，功能分工明确，解耦合。
* SpringMVC能够使用 Spring 的 IoC 和 Aop，整合其他框架方便。
* SpringMVC使用方便，使用@Controller 就能创建处理器对象,@Service 就能创建业务对象。

### 第一个SpringMVC项目
* Maven坐标导入SpringMVC依赖与设置tomcat服务器

![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240426224547.png)

* 创建SpringMVC配置文件
* 初始化Servlet容器
* 返回中文信息乱码解决
* 创建Controller
* 最后请求进行测试

## SpringMVC请求

### 前面使用注解介绍

#### @RequestMapping
* @RequestMapping:将请求和处理请求的控制器方法进行关联起来，建立映射关系。
* SpringMVC接收到指定的请求，找到在映射关系中对应的控制器方法来处理这个请求。
* 位置:SpringMVC控制器类或方法定义上方
* 属性:
  * value默认属性：必须设置，为一个字符串类型的数组，表示该请求映射能够匹配的请求地址
  * method属性：非必须，为一个请求方法类型数组，表示该请求映射能够匹配的请求方式
  * 拥有派生注解：
    * get请求-→@GetMapping
    * post请求-→@PostMapping
    * put请求-→@PutMapping
    * delete请求-→@DeleteMapping
    * …​
  * params属性：非必须，为一个字符串类型的数组，可以通过表达式设置请求参数和请求映射的匹配关系
  * headers属性：非必须，为一个字符串类型的数组，可以通过表达式设置请求头信息和请求映射的匹配关系

#### @ResponseBody
* @ResponseBody：将Controller方法的返回结果通过适当的转换器转换为指定的格式后，直接写入HTTP响应正文中通常用来返回JSON/XML数据。
* 位置:SpringMVC控制器类或方法定义上方

#### @Controller
* @Controller：标注此注解后的组件会被Spring识别为可以接受并处理网页请求的组件。
* @Controller注解继承了Spring的@Component注解，会把对应的类声明为Spring对应的Bean，并且可以被Web组件管理。

### SpringMVC中的路径匹配
* Spring支持两种路径匹配方式。
  * PathPattern：Spring 5 引入。使用预解析的方法匹配路径。专门为Web路径匹配而设计，可以支持复杂的表达式，执行效率很高。
  * AntPathMatcher：Sping在2013年引入。Spring中用于类路径、文件系统和其它资源的解决方案，效率比较低。
* PathPattern可以向下兼容AntPathMatcher的逻辑
```
?:表示任意的单个字符
*:表示任意的0个或多个字符
**:表示任意的一层或多层目录
{xxx}:路径占位符,使用@PathVariable注解可以此获取参数变量
```
* PathPattern配置开启
```java
@Configuration
@EnableWebMvc
public class WebConfiguration implements WebMvcConfigurer {
    @Override
    public void configurePathMatch(PathMatchConfigurer configurer) {
        configurer.setPatternParser(new PathPatternParser());
    }
}
```
* PathPattern特性
```
可以支持{*path}:同时可以匹配到多级路径
PathPattern 只支持结尾部分使用 **，不同于AntPathMatcher
```
### SpringMVC中的路径冲突
如当一次请求匹配到多个路径，那么就需要选出最接近的路径。
通常会使用@RequestMapping注解，根据不同功能模块修改其映射路径解决此问题。

### SpringMVC获取请求参数
* **(原始)通过ServletAPI获取**，将HttpServletRequest作为控制器方法的形参，此时HttpServletRequest类型的参数表示封装了当前请求的请求报文对象
```
request.getParameter("xxx");
```
* **方法形参获取**，多个值逗号分开即可
```java
@RequestMapping("/hello")
@ResponseBody
public String hello(String name,String password){
    System.out.println(name);
    System.out.println(password);
    return "hello world";
}
```
* **通过POJO获取**
  * 如果参数较多，那么接收参数的时候就较为复杂，这个时候可以使用POJO获取参数。
  * 需要注意请求参数key的名称要和POJO中属性的名称一致。
```java
@RequestMapping("/hello")
@ResponseBody
public String hello(User user){
    System.out.println(user);
    return "hello world";
}
```
* @RequestParam
  * 当请求参数与方法形参对应不上，可使用@RequestParam注解解决
  * 位置放在方法形参定义前面
  * 属性:
    * required：是否为必传参数
    * defaultValue：参数默认值
### SpringMVC JSON数据处理
* 可借助其他JSON依赖帮助处理JSON数据，例如jackson等等
* 操作流程，导入jackson包
```xml
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.13.4.2</version>
</dependency>
```
* 配置类上添加@EnableWebMvc注解
* 方法形参前添加@RequestBody即可
* @RequestBody(常用注解):将外部传递的json数据映射到形参的集合或对象中

## SpringMVC响应

### SpringMVC响应
* SpringMVC接收到请求后，需要进行一些操作进行处理请求，将结果进行响应操作。

#### 响应文本数据
* 需要添加@ResponseBody注解，将文本数据进行响应。

#### 响应JSON数据
* SpringMVC还可以响应实体类(集合)对象。
* 需要添加依赖@ResponseBody注解和@EnableWebMvc注解。
* 此时控制器方法返回值为实体类类型时，即可响应JSON数据。

### RESTful API
* 传统风格API
  * http://localhost/user/getUser 查询所有用户信息
  * http://localhost/user/insertUser 添加用户信息
  * http://localhost/user/updateUser 更新用户信息
  * http://localhost/user/deleteUser 删除用户信息
* SpringMVC还支持RESTful风格API
  * http://localhost/user GET请求方式查询所有用户信息
  * http://localhost/user POST请求方式添加用户信息
  * http://localhost/user/{userId} PUT请求方式更新用户信息
  * http://localhost/user/{userId} DELETE请求方式删除用户信息
* 优点
  * 统一接口，GET/POST/PUT/DELETE进行CRUD操作。
  * 面向资源，一目了然。
  * 数据描述简单，一般以JSON做数据交换…​。
* 缺点
  * 对于查询参数过多的接口，会导致URL的长度过长、造成请求失败。
  * 应按照实际需求制作相应的接口。
* RESTful快速入门
  * @RestController=@Controller+@ResponseBody

## SpringMVC拦截器

### 拦截器
* SpringMVC的控制器拦截器,用于对控制器进行预处理和后处理。
* 依赖于Web框架，在实现上基于Java的反射机制，属于面向切面编程（AOP）的一种运用。
* 一个拦截器实例在一个控制器生命周期之内可以多次调用。
* 类似于Servlet中的过滤器Filter。

### 拦截器和过滤器区别
* 过滤器
  * 过滤器属于Servlet技术
  * 过滤器主要对所有请求过滤
  * 过滤器的执行时机早于拦截器
* 拦截器
  * 拦截器属于SpringMVC技术，必须要有SpringMVC环境才可以使用
  * 拦截器通常对控制器Controller进行拦截
  * 拦截器只能拦截dispatcherServlet处理的请求

### 拦截器应用场景
* 进行权限检查，登录检测等等。
* 只要是多个Controller中的处理方法都需要的逻辑，可以抽离出使用拦截器实现。

### 拦截器配置
* 创建拦截器类
* preHandler方法，返回true放行，执行原始方法，返回false则拦截。
  * request参数:请求对象
  * response参数:响应对象
  * handler参数:被调用的控制器方法对象
* 重写WebMvcConfigurer中的addInterceptors进行拦截器注册
* 如有静态资源重写WebMvcConfigurer中的addResourceHandlers放行静态资源

# SpringBoot

## SpringBoot介绍

### SpringBoot
* Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。
* 该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。
* 通过这种方式，Spring Boot致力于在蓬勃发展的快速应用开发领域成为领导者。

### SpringBoot特点
* SpringBoot所具备的特征有：
  * 可以创建独立的Spring应用程序，并且基于其Maven或Gradle插件，可以创建可执行的JARs和WARs；
  * 内嵌Tomcat或Jetty等Servlet容器；
  * 提供自动配置的“starter”项目对象模型（POMS）以简化Maven配置；
  * 尽可能自动配置Spring容器；
  * 提供准备好的特性，如指标、健康检查和外部化配置；
  * 不需要XML配置等等。

### 第一个SpringBoot项目
* 创建新项目，选择Spring Initializr，配置项目相关信息
* 选择当前项目需要使用的技术依赖项
* 创建Controller
* 运行SpringApplication即可启动项目用于测试。
* 除此之外还可以使用package打包命令打包后使用java -jar直接运行程序。

## SpringBoot配置

### Springboot结构中的pom.xml文件
* parent:继承的项目中定义了若干个依赖坐标版本，减少依赖冲突。
* 即只需提供groupId与artifactId，version由SpringBoot提供。
```xml
<parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId> <!---->
    <version>3.2.5</version>
    <relativePath/> <!-- lookup parent from repository -->
</parent>
```
* starter:定义了当前项目使用的相关依赖坐标，减少配置依赖的操作。
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```

### Springboot中的配置文件
* SpringBoot中的配置文件分别是三种类型,优先级从上至下，越上面的优先级越高。
  * application.properties
  * application.yml
  * application.yaml
  * 注意:如有config目录，则config目录下的配置文件优先级高于类路径下的配置文件。
* SpringBoot开发中配置文件建议使用yml格式，因为其层次分明，且支持对象数组等定义。
  * 但需注意yml语法大小写敏感，同层级左侧对齐等等语法要求。

#### Springboot中的配置文件如何读取？
* 使用@Value注解从配置文件中读取数据,例如:@Value("${属性名.属性名}")
* 使用环境对象Environment,默认获取application配置文件的内容
  * 使用@PropertySource可以读取自定义配置文件到 Spring 的 Environment 中。
  * 和@Value搭配使用，可以将自定义配置文件中的属性变量值注入到当前类使用了@Value注解的成员变量中。
  * 注意@PropertySource默认情况下不会加载yaml/yml文件,默认加载的是.xml或者 .properties文件。
  * 如需要加载.yml文件，就需要继承DefaultPropertySourceFactory类并修改。
  * @PropertySource(value = "classpath:test.yml",factory = YamlConfig.class)
* 使用实体类对象进行属性映射
  * 在实体类上标注@ConfigurationProperties注解进行配置文件加载。
  * 并且此实体类需要注册到IoC容器。
  * 如遇未配置 Spring Boot 配置注解处理器警告，在pom中添加如下依赖即可。
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-configuration-processor</artifactId>
    <optional>true</optional>
</dependency>
```
#### Springboot配置文件中的多环境
* 开发环境、测试环境、生产环境都有不同的环境，例如各种日志级别，数据库连接…​。
* 因此配置文件中的多环境也非常有必要。
* yml配置文件中可以直接使用---来区分不同的配置
```yml
# yml
spring:
  profiles:
    active: pro
---
# 开发环境
spring:
  config:
    activate:
      on-profile: dev
server:
  port: 8080
---
# 生产环境
spring:
  config:
    activate:
      on-profile: pro
server:
  port: 80
```
* properties配置文件可以直接使用不同名称的多配置文件来区分不同的配置
  * application-dev.properties 开发环境配置文件。
  * application-pro.properties 生产环境配置文件。
* 注意:SpringBoot只会默认加载名为application.properties的配置文件
* 所以需要在application.properties配置文件中设置使用哪个配置文件
```
spring.profiles.active=pro
```

#### Springboot命令行启动
* 命令行启动提供的配置参数优先级最高，即使配置文件中已经定义了相关参数。
* 主要方便在对应用程序打包后需要临时改变相关参数的情况，而无需修改代码或配置文件再重新打包运行。
```
java -jar lalapodo.jar --server.port=8080 --spring.profiles.active=pro
```
* 在Docker容器运行时也方便临时修改参数。
```
FROM amazoncorretto:17.0.5
ADD lalapodo.jar lalapodo.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "lalapodo.jar", "--server.port=8080", "--spring.profiles.active=pro"]
```

## SpringBoot集成Quartz

### Quartz
Quartz是OpenSymphony开源组织在Job scheduling领域的开源项目，它可以与J2EE与J2SE应用程序相结合也可以单独使用。

Quartz可以用来创建简单或为运行十个，百个，甚至是好几万个Jobs这样复杂的程序。

Jobs可以做成标准的Java组件或 EJBs。

### Quartz相关API
  * Scheduler：Quartz 中的任务调度器，通过 Trigger 和 JobDetail 可以用来调度、暂停和删除任务。
  * 调度器就相当于一个容器，装载着任务和触发器，该类是一个接口，代表一个 Quartz 的独立运行容器。
  * Trigger：Quartz 中的触发器，是一个类，描述触发 Job 执行的时间触发规则，主要有 SimpleTrigger 和 CronTrigger 这两个子类。
    * 仅需调度一次或者以固定时间间隔周期执行调度，SimpleTrigger 是最适合的选择。
    * 而 CronTrigger 可以通过 Cron 表达式定义出各种复杂时间规则的调度方案。
  * Job：Quartz 中具体的任务，包含了执行任务的具体方法。
  * JobDetail：Quartz 中需要执行的任务详情，包括了任务的唯一标识和具体要执行的任务，可以通过 JobDataMap 往任务中传递数据。
  * JobBuilder：用于定义/构建 JobDetail 实例，用于定义作业的实例。
  * TriggerBuilder：用于定义/构建触发器实例。

### SpringBoot集成Quartz
1. 引入Quartz依赖
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-quartz</artifactId>
</dependency>
```
2. 定义Job类
  * 其中JobExecutionContext包含各种上下文信息的句柄。
  * 可以通过它获取Job运行时的环境以及属性信息。
  * 而JobDataMap实现了Map接口，用法同Map类似，它可以装载任何可序列化的数据对象。
  * 执行Job时JobDataMap可用来传递数据，JobDataMap存在于JobExecutionContext中，通过JobExecutionContext来获取。
3. 创建Quartz配置类定义任务

## SpringBootTask

### SpringBoot Task
* Spring Task 是 Spring 自主研发的轻量级定时任务工具，相比于 Quartz 更加简单方便，且不需要引入其他依赖即可使用。
* Spring Task 缺点在于不支持持久化，并且默认是所有定时任务都在一个线程中执行，不配置线程池可能会出现线程阻塞、卡死等！

### SpringBoot Task使用
1. 启动类加上@EnableScheduling注解开启Spring Task
2. 定义定时任务交由Ioc容器

### SpringBoot Task配置
```java
@Configuration
public class SpringTaskConfig implements SchedulingConfigurer {
    @Override
    public void configureTasks(ScheduledTaskRegistrar taskRegistrar) {
        ThreadPoolTaskScheduler threadPoolTaskScheduler = new ThreadPoolTaskScheduler();
        //设置线程池大小 默认为1
        threadPoolTaskScheduler.setPoolSize(10);
        //设置线程名称前缀
        threadPoolTaskScheduler.setThreadNamePrefix("aaa-");
        //设置线程池关闭时是否等待任务完成
        threadPoolTaskScheduler.setWaitForTasksToCompleteOnShutdown(true);
        //设置线程池关闭前最大等待时间
        threadPoolTaskScheduler.setAwaitTerminationSeconds(60);
        //初始化
        threadPoolTaskScheduler.initialize();
        taskRegistrar.setTaskScheduler(threadPoolTaskScheduler);
    }
}
```

## SpringBoot集成MyBatis

### MyBatis简介
* MyBatis是一个基于Java的持久层框架，它使用对象关系映射实现了对结果集的封装。
* 对象关系映射:把数据库表和实体类及实体类的属性对应起来，让开发者操作实体类就实现操作数据库表。
* 它封装了JDBC操作的很多细节，使开发者只需要关注SQL语句本身，而无需关注注册驱动，创建连接等烦杂过程。

### SpringBoot集成MyBatis
1. 引入MyBatis相关依赖
```xml
<dependency>
    <groupId>org.mybatis.spring.boot</groupId>
    <artifactId>mybatis-spring-boot-starter</artifactId>
    <version>2.2.2</version>
</dependency>
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <scope>runtime</scope>
</dependency>
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>druid-spring-boot-starter</artifactId>
    <version>1.2.14</version>
</dependency>
```
2. 配置文件中配置数据库相关信息
3. 定义数据库表实体类
4. 定义Mapper接口
5. 定义Service接口及实现类
6. 类路径mapper目录下定义SQL映射文件
7. 定义控制器类
8. 发送请求进行测试即可

## API接口开发
API（Application Programming Interface，应用程序编程接口）接口的开发是一个涉及多个步骤和技术的过程。以下是一个概括性的指南，用于说明如何开发API接口，特别是在Java Spring Boot环境下：
### 1. 确定需求和API设计
* **需求分析**：明确API需要实现的功能、数据交互的格式（如JSON、XML）以及安全性要求等。
* **API设计**：设计API的URL结构、HTTP方法（如GET、POST、PUT、DELETE）、请求参数和响应格式。可以使用RESTful风格来设计API。
### 2. 环境搭建
* **开发工具**：选择合适的开发环境，如IntelliJ IDEA、Eclipse等，并安装必要的插件。
* **构建工具**：使用Maven或Gradle作为项目的构建工具，管理项目的依赖和构建过程。
* **框架选择**：选择Spring Boot作为开发框架，因为它简化了Spring应用的搭建和部署，并提供了开箱即用的配置和常用功能。
### 3. 创建项目和添加依赖
* 使用Spring Initializr（https://start.spring.io/）或IDE的Spring Boot项目创建向导来快速生成项目结构。
* 在`pom.xml`（Maven）或`build.gradle`（Gradle）文件中添加必要的依赖，如Spring Web Starter（用于Web开发）、Spring Data JPA（用于数据库操作）等。
### 4. 编写代码
* **实体类**：定义与数据库表对应的实体类，并使用JPA注解进行映射。
* **数据访问层**：使用Spring Data JPA的Repository接口或自定义Repository来实现数据的增删改查。
* **服务层**：编写服务层代码，封装业务逻辑，并调用数据访问层的方法。
* **控制器层**：创建Controller类，使用`@RestController`注解标记为RESTful控制器，并使用`@RequestMapping`、`@GetMapping`、`@PostMapping`等注解定义API的URL和HTTP方法。
### 5. 配置数据库和JPA
* 在`application.properties`或`application.yml`文件中配置数据库连接信息（如URL、用户名、密码）和JPA的相关设置（如Hibernate的方言、DDL生成策略等）。
### 6. 测试和调试
* 编写单元测试和集成测试来验证API的正确性和稳定性。
* 使用Postman、Curl等工具进行API接口的测试。
### 7. 部署和运维
* 将应用打包成可执行文件（如jar包）或部署到Web服务器（如Tomcat）。
* 使用Docker、Kubernetes等容器化技术进行应用的部署和管理。
* 监控应用的运行状态，进行必要的性能调优和故障排查。
### 8. 安全性考虑
* 对API接口进行安全性设计，如使用HTTPS协议、进行身份验证和授权、防止SQL注入和XSS攻击等。
### 示例代码
以下是一个简单的Spring Boot API接口示例：
```java
@RestController
@RequestMapping("/api/users")
public class UserController {

    @Autowired
    private UserService userService; // 假设有一个UserService类来处理业务逻辑

    @GetMapping("/{id}")
    public ResponseEntity<User> getUserById(@PathVariable Long id) {
        User user = userService.findUserById(id);
        if (user == null) {
            return ResponseEntity.notFound().build();
        }
        return ResponseEntity.ok(user);
    }

    @PostMapping
    public ResponseEntity<User> createUser(@RequestBody User user) {
        User savedUser = userService.saveUser(user);
        return ResponseEntity.status(HttpStatus.CREATED).body(savedUser);
    }

    // 其他API方法...
}
```
在这个示例中，`UserController`类定义了两个API接口：一个用于根据ID获取用户信息（GET请求），另一个用于创建新用户（POST请求）。这些接口通过Spring Boot的注解进行定义，并通过服务层调用相应的业务逻辑。

## 日志记录与处理
网上购物平台中的异常处理日志实现是一个关键的组成部分，它有助于及时发现和定位问题，保障平台的稳定运行。以下是一个关于如何实现异常处理日志的详细指南：
### 一、日志记录的目的
1. **问题定位**：通过详细的日志记录，可以快速定位到系统出现的问题及其原因。
2. **性能监控**：日志可以帮助监控系统的性能，发现潜在的瓶颈或异常行为。
3. **安全审计**：记录用户行为和系统操作，有助于进行安全审计和防范潜在的安全风险。
### 二、日志记录的原则
1. **详细性**：日志信息应尽可能详细，包括时间戳、操作类型、用户信息、请求参数、响应结果以及异常堆栈等。
2. **分级管理**：根据日志的重要性进行分级（如ERROR、WARN、INFO、DEBUG等），便于后续的处理和筛选。
3. **安全性**：确保日志信息的安全，避免敏感信息泄露。
### 三、异常处理日志的实现步骤
#### 1. 选择日志框架
网上购物平台通常会选择成熟的日志框架来实现日志记录，如Log4j、Logback、SLF4J等。这些框架提供了灵活的日志配置和强大的日志处理能力。
#### 2. 配置日志框架
根据项目的实际需求，配置日志框架的日志级别、日志格式、日志输出位置（控制台、文件、数据库等）等。例如，在Log4j中，可以通过`log4j.properties`或`log4j2.xml`文件进行配置。
#### 3. 在代码中记录日志
在代码的关键位置（如API接口的实现、业务逻辑的处理、异常捕获等）添加日志记录语句。使用不同的日志级别来记录不同重要性的信息。例如，使用`ERROR`级别记录严重的错误信息，使用`INFO`级别记录正常的业务操作信息。
#### 4. 捕获并记录异常
在代码中使用try-catch语句块来捕获可能发生的异常，并在catch块中记录异常信息。这包括异常的类型、消息、堆栈跟踪等。例如：
```java
try {
    // 业务逻辑代码
} catch (Exception e) {
    logger.error("处理业务逻辑时发生异常", e);
    // 异常处理代码
}
```
#### 5. 定期检查和分析日志
定期对日志进行检查和分析，以发现潜在的问题和性能瓶颈。可以使用日志分析工具（如Logstash、Kibana等）来辅助分析。
### 四、特殊场景处理
1. **敏感信息处理**：在记录日志时，应避免包含敏感信息（如用户密码、银行卡号等）。如果必须记录，应进行脱敏处理。
2. **高并发场景**：在高并发场景下，日志记录可能会对系统性能产生影响。因此，需要合理设置日志级别和输出位置，以减少对系统性能的影响。
3. **分布式系统**：在分布式系统中，日志可能分散在多个节点上。因此，需要实现日志的集中管理和分析，以便快速定位问题。

# SpringMaven

## Maven介绍

### Maven
* Maven这个单词来自于犹太语，意为知识的积累。
* Maven 翻译为"专家"、"内行"，是 Apache 下的一个纯 Java 开发的开源项目。
* 基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。
* Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。
* Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。
* Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。

### Maven优点
* 快速构建工程，管理jar包，编译代码，运行单元测试，打包，生成报表，部署项目等等。

### Maven仓库
* Maven中，仓库是一个位置。
* Maven仓库是项目中依赖的第三方库，这个库所在的位置叫做仓库。
* Maven中，任何一个依赖、插件或者项目构建的输出，都可以称之为构件。
* Maven仓库能帮助我们管理构件（主要是JAR），它就是放置所有JAR文件（WAR，ZIP，POM等等）的地方。
* Maven 仓库有三种类型：
  * 本地（local）:用来存储从远程仓库或中央仓库下载的插件和jar包，项目使用一些插件或jar包，优先从本地仓库查找。
  * 中央（central）:Maven中内置的一个远程仓库地址http://repo1.maven.org/maven2，它是中央仓库，由Maven社区维护，其中包含了大量常用的库。
  * 远程（remote）:如果Maven在中央仓库中也找不到依赖的文件，它会停止构建过程并输出错误信息到控制台。为避免这种情况，Maven 提供了远程仓库的概念，它是开发人员自己定制仓库，包含了所需要的代码库或者其他工程中用到的 jar 文件。

### Maven项目目录结构
* src/main/java —— java 代码文件
* src/main/resources —— 项目资源文件
* src/test/java —— 单元测试java 代码文件
* src/test/resources —— 测试资源文件
* target —— 项目输出位置，编译后的 class 文件会输出到此目录
* pom.xml —— maven 项目核心配置文件

### Maven常用命令
* clean：清理命令，删除 target 目录及内容
* compile：编译命令，将 src/main/java 下的文件编译为 class 文件输出到 target 目录下
* test：测试命令，将执行 src/test/java 下的单元测试类
* package：打包命令
* install：安装命令，将项目打包后发布到本地仓库

## Maven POM

### POM
* POM是 Maven 工程的基本工作单元，是一个XML文件，包含了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。
* 执行任务或目标时，Maven 会在当前目录中查找 POM。它读取 POM，获取所需的配置信息，然后执行目标。
* 所有 POM 文件都需要 project 元素和三个必需字段：groupId，artifactId，version。
  * project 工程的根标签。
  * modelVersion 模型版本需要设置为 4.0。
  * groupId 这是工程组的标识。它在一个组织或者项目中通常是唯一的。
  * artifactId 这是工程的标识。它通常是工程的名称。
  * version 这是工程的版本号。在 artifact 的仓库中，它用来区分不同的版本。

### POM依赖范围
```
依赖范围      编译          测试          运行时       打入jar包
compile        Y            Y             Y             Y
test           -            Y             -             -
provided       Y            Y             -             -
runtime        -            Y             Y             Y
system         Y            Y             -             Y
```
* compile：编译范围，指 A 在编译时依赖 B，此范围为默认依赖范围。
* test：test范围只有在测试编译和测试运行阶段可用。
* provided：provided依赖只有在当JDK或者一个容器已提供该依赖之后才使用，provided依赖在编译和测试时需要，在运行时不需要。
* runtime：runtime依赖在运行和测试的时候需要，但在编译的时候不需要。
* system：system范围依赖与provided类似，但是必须显示的提供一个对于本地系统中jar文件的路径。一般不推荐使用。

## Maven 依赖管理

### Maven依赖管理
* Maven一个核心的特性就是依赖管理。
* 当我们处理多模块的项目（包含成百上千个模块或者子项目），模块间的依赖关系就变得非常复杂，管理也变得很困难。
* 针对此种情形，Maven 提供了一种高度控制的方法。

### 可传递性依赖发现
* 一种相当常见的情况，比如说 A 依赖于其他库 B。如果，另外一个项目 C 想要使用 A ，那么 C 项目也需要使用库 B。
* Maven 通过读取项目文件（pom.xml），找出它们项目之间的依赖关系。
* 我们需要做的只是在每个项目的 pom 中定义好直接的依赖关系。其他的事情 Maven 会帮我们搞定。
* 通过可传递性的依赖，所有被包含的库的图形会快速的增长。
* 当有重复库时，可能出现的重复的情形将会持续上升。

#### 依赖排除
* 任何可传递的依赖都可以通过 "exclusion" 元素被排除在外。

#### 依赖可选
* 任何可传递的依赖可以被标记为可选的，通过使用 "optional" 元素。

### 依赖管理
* 通常情况下，在一个共通的项目下，有一系列的项目。
* 在这种情况下，我们可以创建一个公共依赖的 pom 文件，该 pom 包含所有的公共的依赖关系，我们称其为其他子项目 pom 的 pom 父。
* 此 pom 父是一个不具有业务功能的空工程。能解决批量模块同步构建的问题。
* 操作步骤
1. 创建一个空的maven项目
2. 将项目打包方式改为pom(重要)
3. 添加所要管理的项目到此pom.xml文件中
```xml
<modules>
    <module>xxx</module>
</modules>
```
4. 使用此 pom 父统一管理项目即可
5. 此 pom 父会按照项目与项目之间的依赖关系来自动决定执行的顺序和配置的顺序无关。
6. 除此之外，还可以把子项目(模块)共同使用的jar包都抽离出来，维护在 pom 父中，方便管理。
7. pom 父
```xml
<properties>
    <spring.version>5.3.23</spring.version>
</properties>
<dependencies>
    <!--依赖-->
    <dependency>
          <!-- 项目名称 -->
          <groupId>xxx</groupId>
          <!-- 模块名称 -->
          <artifactId>xxx</artifactId>
          <!-- 版本 -->
          <version>${spring.version}</version>
      </dependency>
</dependencies>
```
8. 子项目(模块)继承 pom 父即可
```xml
<parent>
    <artifactId>parent_demo</artifactId>
    <groupId>com.lalapodo</groupId>
    <version>1.0</version>
</parent>
```
9. pom 父也能够配置可选依赖
```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>xxx</groupId>
            <artifactId>xxx</artifactId>
            <version>xxx</version>
        </dependency>
    </dependencies>
</dependencyManagement>
```

## Maven远程仓库搭建

### 远程仓库搭建
* 构建Maven项目时，检查pom.xml文件确定依赖包的位置，顺序如下：
  1. 从本地仓库中查找并获得依赖包。
  2. 从Maven默认中央仓库中查找并获得依赖包。
  3. 如果在pom.xml中定义了自定义的远程仓库，那么也会在这里的仓库中进行查找并获得依赖包。
* 远程仓库一般是镜像站以及nexus私有仓库居多。
* 这里介绍Nexus私有仓库搭建。

### 自定义仓库分类:
* 宿主仓库hosted:保存自定义依赖或制件等等
* 代理仓库proxy:代理远程仓库，通过nexus访问其他公共仓库，例如中央仓库
* 仓库组group:若干个仓库组成一个组

### 操作步骤
1. 下载Nexus或使用Docker启动。
  * 官方下载地址 https://help.sonatype.com/repomanager3/product-information/download
  * Docker地址 https://hub.docker.com/r/sonatype/nexus3/ `docker run -d -p 8081:8081 --name nexus sonatype/nexus3`
2. 运行下载的Nexus即可或Docker。
  * 官方文档参考 https://help.sonatype.com/repomanager3/installation-and-upgrades/installation-methods
3. 启动完成后配置使用即可。

### 配置步骤
1. Nexus中配置自定义仓库
2. 修改Mavensettings.xml进行自定义仓库配置
```xml
<server>
    <!--仓库Name-->
    <id>tesrepo</id>
    <!--用户名-->
    <username>admin</username>
    <!--密码-->
    <password>123456</password>
</server>
```
3. 配置自定义仓库访问路径
```xml
<mirror>
    <!--仓库组ID-->
    <id>maven-public</id>
    <!--*代表所有内容都从自定义仓库获取-->
    <mirrorOf>*</mirrorOf>
    <!--私服仓库组maven-public的访问路径-->
    <url>http://localhost:8081/repository/maven-public/</url>
</mirror>
```
4. 将配置的自定义仓库添加到仓库组中例如(maven-public)
5. pom.xml文件中配置仓库即可
```xml
<distributionManagement>
    <repository>
        <id>xxx</id>
        <url>xxx</url>
    </repository>
</distributionManagement>
```
6. Maven命令deploy即可完成

# SpringMybatis

## Mybatis介绍

### MyBatis简介
* MyBatis是一个基于Java的持久层框架，它使用对象关系映射实现了对结果集的封装。
* 对象关系映射:把数据库表和实体类及实体类的属性对应起来，让开发者操作实体类就实现操作数据库表。
* 它封装了JDBC操作的很多细节，使开发者只需要关注SQL语句本身，而无需关注注册驱动，创建连接等烦杂过程。

### MyBatis功能概况
* 与其他对象关系映射框架不同，MyBatis没有将Java对象直接与数据库表关联起来，而是将Java方法与SQL语句关联。
* MyBatis允许用户充分利用数据库的各种功能，例如存储过程、视图、各种复杂的查询以及某数据库的专有特性。
* 如果要对遗留数据库、不规范的数据库进行操作，或者要完全控制SQL的执行，MyBatis是一个不错的选择。
* 与JDBC相比，MyBatis简化了相关代码：SQL语句在一行代码中就能执行。MyBatis提供了一个映射引擎，声明式的把SQL语句执行结果与对象树映射起来。
* 通过使用一种内建的类XML表达式语言，或者使用Apache Velocity集成的插件，SQL语句可以被动态的生成。
* MyBatis与Spring Framework和Google Guice集成，这使开发者免于依赖性问题。
* MyBatis支持声明式数据缓存
* 当一条SQL语句被标记为“可缓存”后，首次执行它时从数据库获取的所有数据会被存储在一段高速缓存中，今后执行这条语句时就会从高速缓存中读取结果，而不是再次命中数据库。

### 第一个MyBatis项目
1. Maven坐标导入MyBatis依赖
2. 参考官方文档定义配置文件，名称为mybatisConfig.xml
3. 定义Mapper接口
4. 定义实体类
5. 参考官方文档定义SQL映射文件，位于类路径mappers目录下，名称为TestMapper.xml
6. 单元测试进行测试

## Mybatis配置

### SQL映射文件注意事项
* Mapper接口的全类名和SQL映射文件的namespace需一致
* Mapper接口中方法名和SQL映射文件中编写SQL的标签的id属性需一致

### Mybatis配置文件
* 配置文件中的标签必须按照固定的顺序配置，某些标签可省略。
* configuration（配置）
  * properties（属性）
  * settings（设置）
  * typeAliases（类型别名）
  * typeHandlers（类型处理器）
  * objectFactory（对象工厂）
  * plugins（插件）
  * environments（环境配置）
    * environment（环境变量）
      * transactionManager（事务管理器）
      * dataSource（数据源）
  * databaseIdProvider（数据库厂商标识）
  * mappers（映射器）

### Mybatis多环境
* environments标签中可配置多个environment,使用id属性区分多环境。
* 在environments标签中使用default属性指定使用什么环境。

### 类型别名
* Mybatis提供了类型别名(typeAliases)标签可以简化SQL映射文件中的resultType书写

## Mybatis获取参数

### Mybatis获取参数
Mybatis提供了两种参数占位符：

#{}：执行SQL时将 #{} 占位符替换为?，自动赋予参数值。

${}：SQL字符串拼接，会存在SQL注入问题，不建议使用。

注意：为字符串类型或日期类型的字段进行赋值时，${}需要手动加单引号，#{}可以自动添加单引号。

#### 单参数的情况
* 单参数可以使用${}和#{}，其中名称可以为任意名称获取参数值。
```xml
<select id="getOne" resultType="test">
	select * from test_table where id = #{id}
</select>
```

#### 多参数的情况
* 多参数的情况，MyBatis会自动将这些参数放在一个Map集合中。
  * 一种情况是arg0,arg1…是键。
  * 另一种情况是param1,param2…是键。
* 直接使用${}和#{}写上Map集合相应的的键就可以获取相应的值。
* 建议在接口方法参数上使用 @Param 注解，Mybatis 会将 arg 或 param1 开头的键名替换为对应注解的属性值。
* 可以使代码清晰，可读性高。
```xml
<select id="getOneTwoarg" resultType="test">
	select * from test_table where id = #{param1} and name = #{param2}
</select>
```
```xml
<select id="getOneTwoarg" resultType="test">
	select * from test_table where id = #{id} and name = #{name}
</select>
```

#### 实体类类型的情况
* 实体类类型的情况可使用${}和#{}，访问实体类对象中的属性名即可获取属性值。
```xml
<insert id="insertOne">
	insert into test_table (id,name,age) values (default,#{name},#{age})
</insert>
```

#### Map集合的情况
* 和多参数情况比较相像，直接使用${}和#{}写上Map集合相应的的键就可以获取相应的值。
```xml
<select id="getOneMap" resultType="test">
	select * from test_table where id = #{id} and name = #{name}
</select>
```

## Mybatis自定义结果映射

### 自定义结果映射 resultMap
* resultMap能设置自定义结果映射，解决数据库字段名和实体类中的属性名不一致造成的问题。
* 注意：字段名和属性名一致的属性也要进行映射。
  * 数据库字段名如使用_,可以在配置文件中开启驼峰命名。
```xml
<settings>
    <setting name="mapUnderscoreToCamelCase" value="true"/>
</settings>
```
* 标签resultMap：
  * id：表示自定义结果映射的唯一标识，不能重复。
  * type：映射类型
```xml
<!--id标识唯一的resultMap，type表示映射类型-->
<resultMap id="customResult" type="com.lalapodo.Dao.TestTable">
</resultMap>
```
* 子标签id：设置主键的字段映射关系
  * property：设置映射关系中实体类属性名
  * column：设置映射关系中表的字段名
```xml
<id property="id" column="id"/>
```
* 子标签result：设置普通字段的映射关系
  * property：设置映射关系中实体类属性名
  * column：设置映射关系中表的字段名
```xml
<result column="name" property="name"/>
<result column="age" property="age"/>
```

### 多对一映射关系
* 标签association：处理多对一映射关系
  * property：需要处理多对一映射关系的属性名
  * javaType：该属性的类型
* 同样具有子标签id和子标签result
```xml
<association property="test2" javaType="com.lalapodo.Dao.TestTable2">
    <id property="uid" column="uid"/>
    <result property="UName" column="u_name"/>
</association>
```

### 一对多映射关系
* 标签collection：用来处理一对多映射关系
  * property：需要处理一对多映射关系的属性名
  * ofType：该属性的集合中存储的数类型
* 同样具有子标签id和子标签result
```xml
<collection property="test1" ofType="com.lalapodo.Dao.TestTable">
    <id property="id" column="id"/>
    <result column="name" property="name"/>
    <result column="age" property="age"/>
</collection>
```

## Mybatis SQL执行

### SQL 特殊字段
* xml文件中，<、>、&等字符使用是非法的。
* 如需要在xml中使用这些符号，必须将其转义为实体。如`&lt;`、`&gt;`、`&amp;`
* 还可以使用`<![CDATA[...]]>`,被这个标记所包含的内容将解析为纯文本。
* `<![CDATA[...]]>`:告诉xml解析器忽略解析。

### SQL 模糊查询
* 可以先把LIKE的内容组装好后传入SQL语句。
* `#{name}="%z%"`
* 还可以在SQL语句组装LIKE的内容

### SQL 查询传入表名
* 这里只能使用`${}`，因为表名是不能加单引号的。

### SQL 批量删除
* 这里只能使用`${}`，因为如果使用`#{}`，SQL语句解析后会与原意不符。
* 例如:DELETE FROM test_table WHERE id in ('1,2,3')。与原意不符

### insert标签可以获取自增id
* 属性:
  * useGeneratedKeys：设置其值为true时使用自增id
  * keyProperty：数据库表记录新增操作完成后，返回自增id赋予传来的实体类对象。
* 单元测试获取新增记录自增Id

## Mybatis动态SQL

### 动态SQL
* 动态SQL主要对多条件查询时等情况，条件表达式和SQL语句如何连接等需要。
* Mybatis提供了相关标签对动态SQL进行支持，致力于解决这些问题。
  * if
  * where
  * choose,when,otherwise
  * set
  * trim
  * foreach

#### if标签
* if标签：条件判断，test属性结果为true，则标签中的内容会执行，否则标签中的内容不会执行。
  * test属性：写逻辑表达式。
* test属性结果为true时SQL语句就会根据传递的参数值进行动态的拼接。
* 但如果只给了name和age参数，那么SQL语句会成为一条错误的SQL语句。
* 最直接解决就是在where后加一个永远为true的等式。
* 但这样如果数据库是很久之前的版本，可能会影响SQL语句的索引优化，所有Mybatis提供了其他标签解决此问题。

#### where标签
* where标签解析为where关键字
* 动态的去掉条件前的 and 或 or
* 还能在没有值的情况下不添加where关键字

#### choose,when,otherwise标签
* 功能与Java中的swtich,case,default类似
* 注意:when至少要有一个，otherwise可以没有，但最多一个。

#### set标签
* set标签解析为set关键字
* 可搭配if标签判断是否具有输入
* set标签可用来删除更新SQL语句中额外的逗号

#### trim标签
* trim标签用于添加或删除标签中的特定内容
* 如果trim标签包裹的内容全都不满足，则trim标签无任何效果
  * prefix属性：trim标签包裹的内容前添加特定内容
  * suffix属性：trim标签包裹的内容后添加特定内容
  * prefixOverrides属性：trim标签包裹的内容前删除特定内容
  * suffixOverrides属性：trim标签包裹的内容后删除特定内容

#### foreach标签
* foreach标签可用来迭代任何可迭代的对象（如数组，集合）。
  * collection属性：需迭代的对象。
  * item属性：本次迭代中得到的元素。
  * separator属性：集合项迭代之间的分隔符。foreach 标签不会错误地添加多余的分隔符。
  * open属性：在拼接SQL语句之前拼接的语句，只会拼接一次。
  * close属性：在拼接SQL语句之后拼接的语句，只会拼接一次。

#### sql标签
* sql标签可以写一段公有SQL内容，include标签可引入此标签中的SQL内容。

#### include标签
* include标签可以引用sql片段

## Mybatis分页插件

### Mybatis分页插件
* MyBatis插件又称拦截器（Interceptor）
* 分页插件优点
  * 分页插件可以帮助我们更好的获取page信息
  * 上一页和下一页和首页和尾页都能够轻松的获取到
  * 将复杂的分页操作进行了封装，从而让分页功能变得非常简单。

### Mybatis分页插件配置
* 导入与PageHelper的依赖
```xml
<dependency>
    <groupId>com.github.pagehelper</groupId>
    <artifactId>pagehelper</artifactId>
    <version>5.3.2</version>
</dependency>
```
* Mybatis主配置文件(`Spring/_06_SpringMybatis/src/main/resources/mybatisConfig.xml`)中配置分页插件
```xml
<plugins>
    <!-- com.github.pagehelper为PageHelper类所在包名 -->
    <plugin interceptor="com.github.pagehelper.PageInterceptor">
        <property name="helperDialect" value="mysql"/>
    </plugin>
</plugins>
```
* 分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。
* 可以配置helperDialect属性来指定分页插件使用哪种方言。
* 配置时，可以使用下面的缩写值：
  * oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby
* `.../src/main/resources/mybatisConfig.xml`中开启日志格式
```xml
<settings>
    <!--PageHelper分页插件日志-->
    <setting name="logImpl" value="STDOUT_LOGGING"/>
</settings>
```

### Mybatis分页插件使用
* 配置完成后可直接使用分页功能了
* 在查询之前使用分页功能PageHelper.startPage(int pageNum, int pageSize)
  * pageNum：当前页的页码
  * pageSize：每页显示的条数
  * PageInfo参数获取
* PageInfo相关API
  * getTotal()：获取总条数
  * getPages()：获取总页数
  * getPageNum()：获取当前页
  * getPageSize()：获取每页显示条数
  * getPrePage()：获取上一页
  * getNextPage()：获取下一页
  * isIsFirstPage()：获取是否是第一页
  * isIsLastPage()：获取是否是最后一页

## Mybatis缓存

### Mybatis缓存的存在原因
* Mybatis为减少和数据库的交互次数，减少系统开销，提高系统效率，提供了缓存机制。
* MyBatis系统中默认定义了两级缓存：一级缓存和二级缓存，默认情况下只有一级缓存开启。
数据怎样使用缓存最优? 经常查询并且不经常改变的数据使用缓存最优。

### 一级缓存
* 一级缓存也叫本地缓存，与数据库同一次会话期间查询到的数据会放在本地缓存中。
* 以后如果需要获取相同的数据，直接从缓存中获取。
* 作用域默认为sqlSession，不需要实现Serializable。
* 当 sqlSession flush 或 close 后, 该 sqlSession 中的所有缓存将被清空。
* 一级缓存不能被关闭，但可以调用clearCache()来清空一级缓存。
* 注意：
  * Mybatis默认会开启一级缓存，不需要配置。
  * 如果sqlSession执行了DML操作（insert、update、delete）。
  * 那么Mybatis会清空当前sqlSession缓存中的所有缓存数据，这样保证缓存中的数据和数据库一致。
  * sqlSession存储缓存数据时，使用 [ namespace:sql:参数 ] 作为key，查询返回的语句作为value保存的。

### 二级缓存
* 二级缓存也叫全局缓存，因一级缓存作用域太低，所以有了二级缓存。
* 二级缓存作用域为Mapper ( Namespace )，并且可自定义存储源，如 Ehcache。
* 作用域为Namespace是指对该Namespace对应的配置文件中所有的SELECT操作结果都缓存，这样不同线程之间就可以共用二级缓存。
* 工作机制：
  * 一个sqlSession查询一条数据，这个数据就会被放在当前会话的一级缓存中。
  * 如果当前sqlSession关闭了，一级缓存中的数据被保存到二级缓存中。
  * 新的sqlSession查询信息，就可以从二级缓存中获取内容。

#### 快速开启二级缓存
1. 放入二级缓存的对象需要实现序列化接口，如超出缓存范围时可写入硬盘。
2. Mybatis主配置文件中启用二级缓存。
```xml
<settings>
    <setting name="cacheEnabled" value="true"/>
</settings>
```
3. SQL映射文件中使用cache元素将namespce与缓存进行绑定即可。
```xml
<cache/>
```
### Mybatis缓存查询的顺序
* 先查询二级缓存，如二级缓存未命中，再查询一级缓存。
* 如一级缓存也未命中，则查询数据库。

# Spring补充

## Spring区别

1. **Spring**
   - **定义**：Spring是一个开源的Java应用程序框架，由Rod Johnson在2002年创建。它是为了解决企业应用开发的复杂性而创建的，提供了全面的基础设施支持和丰富的功能特性，如依赖注入（DI）、面向切面编程（AOP）、事务管理、数据访问、Web应用等。
   - **特点**：轻量级、可扩展性强、容易使用和优秀文档。
   - **用途**：广泛应用于各种类型的Java项目中，为企业级应用开发提供全面的支持。

2. **Spring MVC**
   - **定义**：Spring MVC是Spring框架的一部分，是基于Servlet API构建的原始Web框架。它提供了灵活可扩展的MVC（Model-View-Controller）架构，方便开发者构建高性能的Web应用程序。
   - **特点**：遵循MVC设计模式，将应用程序的不同方面分离开来，通过模型、视图和控制器的协作来处理Web请求。
   - **用途**：主要用于Web应用的开发，实现前后端的分离和交互。

3. **SpringBoot**
   - **定义**：SpringBoot是一个用于构建Java应用程序的开源框架，它简化了Java应用程序的开发过程，提供了一种快速、便捷的方式来创建独立的、可执行的、生产级别的Spring应用程序。
   - **特点**：基于Spring框架，通过自动配置和“约定优于配置”的原则，减少了开发人员的工作量，使得开发过程更加高效。
   - **用途**：用于快速构建和部署Spring应用，尤其适合微服务架构的应用开发。

4. **Spring Maven**
   - **说明**：这里指的是使用Maven作为构建工具来构建Spring项目的做法，而不是一个独立的框架或技术。Maven是一个项目管理和构建自动化工具，可以帮助开发者自动化构建过程、依赖管理和项目信息管理。
   - **特点**：通过Maven可以方便地管理Spring项目的依赖、构建和部署。
   - **用途**：作为Spring项目的构建工具，提高开发效率和项目管理的便捷性。

5. **Spring MyBatis**
   - **说明**：这里指的是在Spring项目中整合MyBatis作为数据访问层的技术。MyBatis是一个支持普通SQL查询、存储过程和高级映射的持久层框架。
   - **特点**：MyBatis消除了几乎所有的JDBC代码和参数的手工设置以及结果集的检索，使用简单的XML或注解用于配置和原始映射，将接口和Java的POJOs（Plain Old Java Objects，普通的Java对象）映射成数据库中的记录。
   - **用途**：在Spring项目中，Spring MyBatis提供了灵活的数据访问能力，支持复杂的SQL查询和映射。

## Spring联系

- **Spring是核心**：无论是Spring MVC、SpringBoot还是Spring MyBatis，它们都是基于Spring框架的扩展或整合。Spring为这些技术提供了全面的基础设施支持和丰富的功能特性。
- **相互协作**：在实际的项目开发中，这些技术往往不是孤立使用的，而是相互协作、共同构建出一个完整的Java应用程序。例如，在一个Web项目中，可能会使用SpringBoot作为项目的构建框架，Spring MVC作为Web层的实现技术，MyBatis作为数据访问层的技术，并通过Maven来管理项目的依赖和构建过程。
- **共同目标**：这些技术的共同目标是简化Java应用程序的开发过程，提高开发效率，降低开发成本，并提升应用程序的可靠性和可维护性。
- **包含关系**：SpringMVC`<`SpringWebMVC`<`Spring`<`SpringBoot

## SpringMVC和SpringBoot
1. SpringMVC属于一个企业WEB开发的MVC框架，覆盖面包括前端视图开发、文件配置、后台接口逻辑开发等。XML、config等配置相对比较复杂。
2. SpringBoot框架相对于SpringMVC框架说，更专注于微服务后台接口，不开发前端视图，同时遵循默认优于配置，简化了插件配置流程，不需要配置XML，相对于SpringMVC，大大简化了流程。
* springmvc从两个方面来看，一是spring,spring的核心中IOC和AOP,IOC就是控制反转(就是将原本由程序代码直接操作的对象的调用权交给容器)，目的是为了减低计算机代码的耦合度，所谓的耦合度就是代码中的逻辑关系不要太紧密，避免后面改的人会因为不懂业务逻辑导致改错代码；除此之外也避免我们每次创建新的对象，减少对应的代码量。我们实际代码过程中最常见的方式是依赖注入（DI Dependency Injection）,所谓依赖注入就是通过构造注入或者set进行注入。依赖查找（DL Dependency Lookup)这是通过名称和类型查找bean。AOP是面向切面编程，AOP分为五大部分：
  * Aspect(切面):通常是一个类，里面可以定义切入点和通知。
  * JointPoint（连接点）：程序执行中明确的点，一般是方法的调用。
  * Advice(通知)：AOP在特定的切入点上做出的增强处理，有before,after,afterRunning,afterThrowing,around;
  * Pointcut(切入点）：就是带有通知的连接点，在程序中主要体现为书写切入点表达式；
  * AOP代理：AOP框架创建的对象，代理就是目标对象的加强，Spring的AOP可以使用JDK代理，也可以使用CGLIB代理，前者基于接口，后者是基于子类。
* 通知类型：
  * Before:在目标方法被调用之前做增强处理,@Before只需要指定切入点表达式即可
  * AfterReturning:在目标方法正常完成后做增强,@AfterReturning除了指定切入点表达式后，还可以指定一个返回值形参名returning,代表目标方法的返回值
  * AfterThrowing:主要用来处理程序中未处理的异常,@AfterThrowing除了指定切入点表达式后，还可以指定一个throwing的返回值形参名,可以通过该形参名
来访问目标方法中所抛出的异常对象
  * After:在目标方法完成之后做增强，无论目标方法时候成功完成。@After可以指定一个切入点表达式
  * Around:环绕通知,在目标方法完成前后做增强处理,环绕通知是最重要的通知类型,像事务,日志等都是环绕通知,注意编程中核心是一个ProceedingJoinPoint
* springboot引入自动配置的概念，让项目配置变得更容易，Spring Boot本身并不提供Spring框架的核心特性以及扩展功能，只是用于快速、敏捷地开发新一代基于Spring框架的应用程序。也就是说，它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置(例如Jackson, JDBC, Mongo, Redis, Mail等等)，Spring Boot应用中这些第三方库几乎可以零配置的开箱即用(out-of-the-box)，大部分的SpringBoot应用都只需要非常少量的配置代码，开发者能够更加专注于业务逻辑。Spring Boot只是承载者，辅助开发者简化项目搭建过程的。如果承载的是WEB项目，使用Spring MVC作为MVC框架，那么工作流程和SpringMVC的是完全一样的，因为这部分工作是Spring MVC做的而不是Spring Boot。
springmvc与springboot的联系和区别：
联系：
* Spring最初利用工厂模式（DI)和代理模式解耦应用组件，为了解耦开发了springmvc；而实际开发过程中，经常会使用到注解，程序的样板很多，于是开发了starter，这套就是springboot。
### SpringMVC和SpringBoot区别：
* springboot是约定大于配置，可以简化spring的配置流程；springmvc是基于servlet的mvc框架，个人感觉少了model中的映射。
* 以前web应用要使用到tomat服务器启动，而springboot内置服务器容器，通过@SpringBootApplication中注解类中main函数启动即可。

## Spring和SpringBoot

### SpringBoot对比Spring的一些优点
  * 提供嵌入式容器支持
  * 使用命令java -jar独立运行jar
  * 在外部容器中部署时，可以选择排除依赖关系以避免潜在的jar冲突
  * 部署时灵活指定配置文件的选项
  * 用于集成测试的随机端口生成

## SpringSecurity
### Spring Security 的主要功能包括：
1. **认证（Authentication）**：验证用户的身份，通常是通过用户名和密码来完成的。Spring Security 支持多种认证机制，如表单登录、HTTP 基本认证、HTTP 摘要认证、OpenID、LDAP、OAuth2 等。
2. **授权（Authorization）**：决定用户是否有权访问特定的资源。这通常基于用户所拥有的角色或权限。Spring Security 支持基于角色的访问控制（RBAC）和基于属性的访问控制（ABAC）。
3. **攻击防护**：Spring Security 提供了多种机制来防止常见的安全攻击，如跨站脚本（XSS）、跨站请求伪造（CSRF）、SQL 注入等。
4. **会话管理**：管理用户的会话，包括会话的创建、维护和销毁。Spring Security 支持多种会话管理方式，如基于 HTTP 的会话、基于令牌的认证（如 JWT）等。
5. **密码管理**：提供强大的密码加密和散列功能，以保护存储在数据库中的用户密码。
6. **集成**：Spring Security 可以很容易地与 Spring 框架的其他部分集成，如 Spring MVC、Spring Data 等，同时也支持与其他框架和技术的集成，如 Hibernate、JPA、REST API 等。
### 使用 Spring Security 的基本步骤：
1. **添加依赖**：首先，需要在项目的构建文件（如 Maven 的 pom.xml 或 Gradle 的 build.gradle）中添加 Spring Security 的依赖。
2. **配置安全策略**：使用 Java 配置或 XML 配置来定义应用程序的安全策略，包括哪些 URL 需要认证、哪些角色可以访问哪些资源等。
3. **实现用户认证**：实现用户认证逻辑，通常是通过实现 `UserDetailsService` 接口来完成的。这个接口允许你定义如何从数据库中检索用户信息，并进行密码验证。
4. **保护资源**：使用 Spring Security 提供的注解（如 `@PreAuthorize`、`@Secured` 等）或表达式（如 `hasRole('ROLE_USER')`）来保护你的应用程序资源。
5. **测试和部署**：在开发过程中不断测试你的安全配置，确保它符合你的安全需求。最后，将你的应用程序部署到生产环境中。

## 数据调动流程
* 在一个典型的前后端分离的架构中，前端（React应用）通过HTTP请求与后端（Spring Boot应用）通信，后端再与数据库（在这个案例中是MySQL，通过MyBatis进行持久化）交互。当你使用axios从React前端向后端Spring Boot发送请求时，整个数据调动流程如下：
### 1. React前端
- **发起请求**：React前端使用axios库向Spring Boot后端发送HTTP请求（GET、POST、PUT、DELETE等）。请求的URL指向后端Spring Boot应用提供的API端点。
- **处理响应**：axios会处理HTTP响应，并将响应数据（如JSON格式）传递给React组件，组件根据这些数据更新UI。
### 2. Spring Boot后端
- **接收请求**：Spring Boot应用中的Controller层负责接收来自前端的HTTP请求。每个请求都会映射到一个特定的处理方法上。
- **业务逻辑处理**：在Controller层，你可能需要调用Service层来处理业务逻辑。Service层可能会进一步调用DAO层或Repository层与数据库交互。
- **数据持久化**：MyBatis在这里扮演了与数据库（MySQL）交互的角色。MyBatis的Mapper接口（或XML映射文件）定义了SQL语句，这些语句被用于查询、插入、更新或删除数据库中的数据。
- **返回响应**：处理完请求后，Spring Boot会将结果（可能是查询到的数据、操作成功的状态码或错误信息）封装成HTTP响应，并返回给前端React应用。
### 3. MySQL数据库
- **数据存储**：MySQL数据库存储了应用的数据。MyBatis通过执行预定义的SQL语句来从数据库中检索、更新或删除数据。
### 示例流程
假设React前端需要获取一个用户列表：
1. **React前端**：
   - 使用axios发送GET请求到`/api/users`。
   - 等待响应，并处理接收到的用户数据列表。
2. **Spring Boot后端**：
   - Controller层接收`/api/users`的GET请求，并调用Service层的一个方法。
   - Service层调用MyBatis的Mapper接口中的方法，该方法执行一个查询所有用户的SQL语句。
   - Mapper接口通过MyBatis执行SQL查询，并返回查询结果（用户列表）。
   - Service层将用户列表返回给Controller层。
   - Controller层将用户列表封装成JSON格式的响应，并发送给前端。
3. **MySQL数据库**：
   - 存储用户数据。
   - 响应MyBatis的查询请求，返回用户数据。
通过这种方式，React前端能够通过axios请求与Spring Boot后端交互，进而调动MySQL数据库中的数据。

## 聊天框功能
设计网上购物平台中的聊天框功能，涉及到数据存储、消息传输和界面展示等多个方面。下面我会先介绍如何设计数据库来存储聊天消息，包括文本和图片（通过URL存储），然后讨论一些实现这种功能的常见方法。
### 数据库设计
#### 1. 聊天消息表
首先，你需要一个聊天消息表来存储所有发送的消息。这个表可以包含以下字段：
- `id`（主键，唯一标识每条消息）
- `sender_id`（发送者的用户ID）
- `receiver_id`（接收者的用户ID，如果是一对多群聊，则可能需要其他设计）
- `message_type`（消息类型，例如 'text' 表示文本，'image' 表示图片）
- `content`（内容，对于文本消息直接存储文本，对于图片消息存储图片的URL）
- `timestamp`（消息发送的时间戳）
- `chat_room_id`（可选，如果支持群聊，则标识消息所属的聊天室）
#### 2. 用户表
确保你有一个用户表来存储用户信息，如用户ID、用户名、头像URL等。
#### 3. 聊天室表（如果支持群聊）
如果平台支持群聊，你还需要一个聊天室表来管理聊天室信息，包括聊天室ID、名称、创建者、成员列表等。
### 实现方法
#### 1. 前端实现
- 使用WebSocket或轮询HTTP请求来实现实时消息更新。
- 使用HTML和CSS来设计聊天界面，包括输入框、消息列表和发送按钮。
- 使用JavaScript来处理用户的输入、发送请求以及展示消息。
#### 2. 后端实现
- 使用Node.js、Spring Boot等框架来处理HTTP请求和WebSocket连接。
- 实现API接口来处理消息的发送、接收和查询。
- 使用数据库ORM（如Sequelize、MyBatis、Hibernate等）来操作数据库。
#### 3. 实时通信
- **WebSocket**：适用于需要实时通信的场景，如实时聊天应用。WebSocket可以保持服务器和客户端之间的持久连接，并允许双方实时发送和接收数据。
- **轮询**：对于不支持WebSocket的服务器或客户端，可以使用轮询（Polling）来实现近似的实时通信。客户端定期向服务器发送请求以获取新消息。
#### 4. 第三方服务
- **Firebase**：Google提供的实时数据库和云消息传递平台，非常适合构建实时聊天应用。
- **Twilio**：提供聊天API，可以方便地集成到应用中，支持多种消息类型，包括文本、图片和视频。
### 分辨图片和文本
在数据库中，通过`message_type`字段来区分消息是文本还是图片。在前端展示时，根据这个字段的值来决定是显示文本内容还是加载并显示图片。

# Redis

## Redis介绍

### Redis简介
* Redis是一个内存中的数据结构项目，实现了一个具有可选持久性的分布式内存 key-value 数据库。
* Redis是NoSQL，即Not Only SQL，指非关系型数据库。
* Redis支持不同类型的抽象数据结构，如字符串、列表、映射、集合、有序集合、超级日志、位图、流和空间索引。

### Redis使用场景
* 用例包括会话缓存、全页缓存、消息队列应用程序、排行榜和计数等等。
* AWS Azure Google Cloud等云供应商在其产品中提供了 Redis。

### 缓存
* 高性能：从用户角度来看，一个请求过来，操作 MySQL（IO操作），查出一个结果，耗时大概 600ms；用缓存速度提高300倍，将常用的数据放在缓存里，可以提高性能，提升用户体验。
* 高并发：从系统来看，数据库IO操作比如MySQL单机最高峰支持2000QPS，大概10000个请求就会挂掉，而用缓存可以支持最多十几万的并发量。

## Redis安装

### Install Redis on Windows

#### Windows Subsystem for Linux (WSL)
* [官方文档](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/install-redis-on-windows/)
* `Control Panel\Programs\Turn Windows features on or off`中同时打开`Virtual Machine Platform`和`Windows Subsystem for Linux`

![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240511195958.png)

#### Debian方式安装Redis
* `Microsoft Store/Debian`直接安装
```bash
Installing, this may take a few minutes...
Please create a default UNIX user account. The username does not need to match your Windows username.
For more information visit: https://aka.ms/wslusers
Enter new UNIX username: toubun
New password: 123456
Retype new password: 123456
passwd: password updated successfully
Installation successful!
```
* 开启管理员权限
```bash
sudo su
```
* 查看LSB和版本的相关信息工具
```bash
sudo apt install lsb-release
```
```bash
[sudo] password for toubun: 123456
Reading package lists... Done
Building dependency tree... Done
The following NEW packages will be installed:
  lsb-release
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 6,416 B of archives.
After this operation, 17.4 kB of additional disk space will be used.
Get:1 http://deb.debian.org/debian bookworm/main amd64 lsb-release all 12.0-1 [6,416 B]
Fetched 6,416 B in 1s (8,852 B/s)
Selecting previously unselected package lsb-release.
(Reading database ... 9548 files and directories currently installed.)
Preparing to unpack .../lsb-release_12.0-1_all.deb ...
Unpacking lsb-release (12.0-1) ...
Setting up lsb-release (12.0-1) ...
```
* 安装数字签名
```bash
curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/redis.list
```
* 执行安装
```bash
sudo apt-get update
sudo apt-get install redis
```
* 使用`systemctl enable`命令来启用Redis服务，以便在系统启动时自动运行
```bash
sudo systemctl enable redis-server.service
```
* 查看当前Redis情况
```bash
systemctl status redis-server
```
```bash
redis-server.service - Advanced key-value store
    Loaded: loaded (/usr/lib/systemd/system/redis-server.service, enabled)
    Active: inactive (dead)
```
* 连接Redis
```bash
redis-cli
```
* 测试
```bash
127.0.0.1:6379> SET mykey "Hello Redis!"
OK
127.0.0.1:6379> GET mykey
"Hello Redis!"
```
* 退出Redis
```bash
exit
```
* Redis配置文件
```bash
cd /etc/redis/
ls
cat redis.conf
```
* 卸载包管理工具所安装Redis
```bash
apt-get purge --auto-remove redis-server
cd /home/user/
ls
redis-cli
redis-server
```

#### 二进制方式安装Redis
```bash
gcc -v

# 官网下载最新Redis版本
wget https://download.redis.io/redis-stable.tar.gz

# 解压缩包 执行编译
tar -xzvf redis-stable.tar.gz
cd redis-stable
make

# 执行安装
make install

redis-server

/usr/local/bin/redis-cli

exit

# 卸载
cd redis-stable
ls
systemctl status redis-server # Unit redis-server.service could not be found.
make uninstall
cd ..
```

#### Docker方式安装Redis
* [官方文档](https://hub.docker.com/_/redis)
```bash
C:\Windows\System32>docker ps -a
CONTAINER ID   IMAGE             COMMAND                   CREATED        STATUS                            PORTS                               NAMES
0211e0409935   sonatype/nexus3   "/opt/sonatype/nexus…"   8 days ago     Exited (255) About a minute ago   0.0.0.0:8081->8081/tcp              nexus
c6471e03b8f8   mysql:latest      "docker-entrypoint.s…"   3 months ago   Exited (255) About a minute ago   0.0.0.0:3306->3306/tcp, 33060/tcp   mysql-mysql-1

C:\Windows\System32>docker run --name redis -d redis
Unable to find image 'redis:latest' locally
latest: Pulling from library/redis
b0a0cf830b12: Pull complete
214d0afb35ca: Pull complete
16a9d12e7a2c: Pull complete
cb9709829e8b: Pull complete
00e912971fa2: Pull complete
f7ebca356832: Pull complete
4f4fb700ef54: Pull complete
c16c264be546: Pull complete
Digest: sha256:f14f42fc7e824b93c0e2fe3cdf42f68197ee0311c3d2e0235be37480b2e208e6
Status: Downloaded newer image for redis:latest
260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4

C:\Windows\System32>docker ps -a
CONTAINER ID   IMAGE             COMMAND                   CREATED          STATUS                       PORTS                               NAMES
260541ddadb7   redis             "docker-entrypoint.s…"   16 seconds ago   Up 12 seconds                6379/tcp                            redis
0211e0409935   sonatype/nexus3   "/opt/sonatype/nexus…"   8 days ago       Exited (255) 3 minutes ago   0.0.0.0:8081->8081/tcp              nexus
c6471e03b8f8   mysql:latest      "docker-entrypoint.s…"   3 months ago     Exited (255) 3 minutes ago   0.0.0.0:3306->3306/tcp, 33060/tcp   mysql-mysql-1

C:\Windows\System32>docker images
REPOSITORY        TAG       IMAGE ID       CREATED        SIZE
sonatype/nexus3   latest    eaf32f10ff03   4 weeks ago    568MB
redis             latest    9509c4dd19fb   5 weeks ago    116MB
mysql             latest    56b21e040954   3 months ago   632MB

# 启动即可
docker run --name redis -d redis
```

### Redis配置

#### 配置参数获取
```bash
redis-cli
config get parameter [parameter ...]
```

## Redis基本数据类型

### redis-cli 连接到另一个服务器
```bash
redis-cli -h host -p port -a password
```

### Redis 字符串 (String)
* String 是 Redis 最基本的数据类型，一个 Redis 中字符串 value 最多可以是 512M.
* String 是二进制安全的。意味着 Redis 的 String 可以包含任何数据。
  * String 的数据结构是简单动态字符串(Simple Dynamic String)。
  * 内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。
* String常用命令：
  > SET 设置指定 key 的值 \
  > SETNX 在 key 不存在时设置 key 的值 \
  > SETEX 设置指定 key 的值并设过期时间 \
  > MSET 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在 \
  > GET 获取指定 key 的值 \
  > GETSET 设置新值同时获得旧值 \
  > INCR/DECR 对 key 的值进行加1或者减1操作 \
  > INCRBY/DECRBY 对 key 的值进行自定义加减 \
  > SETRANGE 用指定的字符串覆盖给定 key 所储存的字符串值，覆盖的位置从偏移量 offset 开始 \
  > GETRANGE 获取存储在指定 key 中字符串的子字符串。字符串的截取范围由 start 和 end 两个偏移量决定

### Redis 列表 (List)
* List是简单的字符串列表，按照插入顺序排序。
  * 底层是双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。
* List常用命令：
  > LPUSH 将一个或多个值插入到列表左端 \
  > RPUSH 将一个或多个值插入到列表右端 \
  > LPOP 移出并获取列表的第一个元素 \
  > BLPOP 移出并获取列表的第一个元素,如列表没有元素会阻塞列表直到超时或发现元素为止 \
  > RPOP 移除并获取列表的最后一个元素 \
  > BRPOP 移除并获取列表的最后一个元素,如列表没有元素会阻塞列表直到超时或发现元素为止 \
  > LRANGE 从左到右获取列表元素 \
  > LSET 通过索引来设置元素的值 \
  > LREM 根据参数 COUNT 的值，移除列表中与参数 VALUE 相等的元素
* List命令搭配：
  > LPUSH + LPOP = 栈 先进后出 \
  > RPUSH + RPOP = 栈 先进后出 \
  > LPUSH + RPOP = 队列 先进先出 \
  > RPUSH + LPOP = 队列 先进先出 \
  > LPUSH + BRPOP = 队列 阻塞效果 \
  > RPUSH + BLPOP = 队列 阻塞效果

### Redis 集合(Set)
* Set提供的功能与 List 类似。
* 特殊之处在于 Set 是可以自动排重，当需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择。
* Set 提供了判断某个成员是否在一个 Set 集合内的重要接口。
* Set 是 String 类型的无序集合。
* 底层是一个 value 为 null 的 哈希表和整型数组。
* Set常用命令：
  > SADD 向集合添加一个或多个成员 \
  > SREM 移除集合中一个或多个成员 \
  > SISMEMBER 判断 member 元素是否是集合 key 的成员 \
  > SMEMBERS 返回集合中的所有成员 \
  > SMOVE 将 member 元素从 源集合移动到 目标集合 \
  > SINTER 返回所有给定集合的交集 \
  > SUNION 返回所有给定集合的并集 \
  > SDIFF 返回第一个集合与其他集合之间的差异(注意比较的两个集合有顺序)

### Redis 有序集合 (ZSet)
* ZSet与 Set 非常类似。
* 特殊之处是ZSet的每个成员都关联了一个评分(score),这个评分被用来按照从最低分到最高分的方式排序集合中的成员。
* 集合的成员是唯一的，但是评分可以重复。
* 底层是压缩列表和跳跃列表。
* ZSet常用命令：
  > ZADD 向有序集合添加一个或多个成员，或者更新已存在成员的分数 \
  > ZREM 移除有序集合中的一个或多个成员 \
  > ZSCORE 返回有序集中，成员的分数值 \
  > ZRANGE 通过索引区间返回有序集合指定区间内的成员 \
  > ZRANK 返回有序集合中指定成员的排名，从小到大排序 \
  > ZREVRANK 返回有序集合中指定成员的排名，从大到小排序 \
  > ZCOUNT 计算在有序集合中指定区间分数的成员数

### Redis 哈希 (Hash)
* Hash是一个键值对集合。
* 特别适合用于存储对象。类似 Java 里面的 Map<String,Object>。
* 底层是压缩列表和哈希表。
* Hash常用命令：
  > HSET 将哈希表 key 中的字段 field 的值设为 value \
  > HGET 获取存储在哈希表中指定字段的值 \
  > HDEL 删除一个或多个哈希表字段 \
  > HMSET 同时将多个 field-value (域-值)对设置到哈希表 key 中 \
  > HMGET 获取所有给定字段的值 \
  > HVALS 获取哈希表中所有值

## Redis特殊数据类型

### 地理位置（GEO）
* Redis 3.2 版本中，新增了存储地理位置信息的功能。
* GEO，地理信息的缩写，该类型是元素的 2 维坐标，在地图上就是经纬度。
* 提供了经纬度设置，查询，范围查询，距离查询，经纬度 Hash 等常见操作。
* 它的底层通过 Redis 有序集合实现。不过 GEO 并没有与 Zset 共用一套的命令，而是拥有自己的一套命令。
* GEO常用命令：
  > GEOADD 将指定的地理空间位置（纬度、经度、名称）添加到指定的 key 中
  > GEOPOS 从 key 里返回所有给定位置元素的位置（即经度和纬度）
  > GEODIST 返回两个地理位置间的距离，如果两个位置之间的其中一个不存在，那么返回空值
  > GEORADIUSBYMEMBER 根据给定地理位置(具体的位置元素)获取指定范围内的地理位置集合

### 位图（Bitmaps）
* 位图（Bitmaps）同样属于 String 数据类型。Redis 中一个字符串类型的值最多能存储 512 MB 的内容。
* 位图适用于一些特定的应用场景，比如用户签到次数、或者登录次数等。
* 位图中的每一条记录仅占用一个 bit 位，大大降低了内存空间使用率。
* Bitmaps常用命令：
  > SETBIT 设置或者清除某一位上的值，其返回值是原来位上存储的值，key 在初始状态下所有的位都为 0
  > GETBIT 获取某一位上的值
  > BITCOUNT 统计指定位区间上，值为 1 的个数


### 基数统计（HyperLoglog）
* Redis 2.8.9 版本中，新增了HyperLogLog类型。
* HyperLoglog 是 Redis 重要的数据类型之一，它非常适用于海量数据的计算、统计，其特点是占用空间小，计算速度快。
* 基数：一个集合中不重复的元素个数，比如集合 {1,2,3,1,2} ，它的基数集合为 {1,2,3} ，基数为 3。
* 适用于统计网站用户月活量，或者网站页面的 UV(网站独立访客)数据等。
* HyperLoglog常用命令：
  > PFADD 添加指定元素到 HyperLogLog 中
  > PFMERGE 将多个 HyperLogLog 合并为一个 HyperLogLog
  > PFCOUNT 返回给定 HyperLogLog 的基数估算值

## Redis RDB持久化

### Redis持久化是什么?
* Redis 是基于内存的非关系型数据库，它将数据存储在内存中。
* 但 Redis 服务器出现意外情况，如宕机或者断电等，那么内存中的数据就会全部丢失。
* 因此须有一种机制能够保证 Redis 储存的数据不会因故障而丢失，这就是 Redis 的数据持久化机制。
* 数据持久化存储是 Redis 的重要特性之一，它能够将内存中的数据保存到本地磁盘中，实现对数据的持久存储。
* Redis 提供了两种持久化机制：RDB AOF。

### RDB是什么?
* RDB 即快照模式，它是 Redis 默认的数据持久化方式，它会将数据库的快照保存在 dump.rdb(默认名称可设置)这个二进制文件中。
* Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化操作。
* RDB 实际上是 Redis 内部的一个定时器事件，它每隔一段固定时间就去检查当前数据发生改变的次数和改变的时间频率，看它们是否满足配置文件中规定的持久化触发条件。
* 当满足条件时，Redis 就会通过操作系统调用 fork() 来创建一个子进程，该子进程与父进程享有相同的地址空间。
* Redis 通过子进程遍历整个内存空间来获取存储的数据，从而完成数据持久化操作。
* 注意，此时的主进程则仍然可以对外提供服务，父子进程之间通过操作系统的 COW 机制实现了数据段分离，从而保证了父子进程之间互不影响。

### RDB 手动命令
* 通过SAVE命令或者BGSAVE命令将内存数据保存到磁盘文件中。
* SAVE与BGSAVE区别:
  * SAVE:阻塞 Redis 服务器进程，直到 dump.rdb 文件创建完毕为止，在这个过程中，服务器不能处理任何的命令请求。
  * BGSAVE:非阻塞式，并不影响 Redis 服务器处理客户端的其他请求。
  * SAVE命令执行速度要略快于BGSAVE命令。

### RDB 优缺点
* 优点：适合于大规模的数据恢复，还原速度快，相对的节省磁盘空间等等。
* 缺点：最后一次持久化的数据可能会出现丢失的情况，二进制rdb文件无可读性等等。

## Redis AOF持久化

### AOF
* AOF 称为追加模式，或日志模式。是 Redis 提供的另一种持久化策略。
* 它能够存储 Redis 服务器已经执行过的的命令，并且只记录对内存有过修改的命令。
* 这种数据记录方法，叫做“增量复制”，其文件为appendonly.aof(默认名称可设置)。

### AOF与RDB同时开启
* AOF 和 RDB 同时开启时，系统默认读取 AOF 的数据（数据不会存在丢失）。

### 命令重演
* 每当有一个修改数据库的命令被执行时，服务器就将命令写入到 appendonly.aof 文件中。
* 该文件存储了服务器执行过的所有修改命令，因此只要服务器重新执行一次 .aof 文件，实现还原数据，此过程被形象地称为命令重演。

### AOF机制
* 写入机制：
  * Redis 在收到客户端修改命令后，先进行相应的校验，如没问题，就立即将该命令追加到 .aof 文件中。
  * 先写到磁盘中，然后服务器再执行命令。
  * 这样就算遇到了突发的宕机断电等等情况，也只需进行一次命令重演就可以恢复到宕机前的状态。
  * 写入是一个 IO 操作。
  * Redis 为了提升写入效率，它不会将内容直接写入到磁盘中。
  * 而是将其放到一个内存缓存区（buffer）中，等到缓存区被填满时才真正将缓存区中的内容写入到磁盘里。
* 重写机制：
  * Redis 在长期运行的过程中，aof 文件会越变越长。
  * 如果机器宕机重启，命令重演会非常耗时，导致长时间 Redis 无法对外提供服务。
  * 因此就存在重写机制对aof文件进行精简。
  * 手动命令是:BGREWRITEAOF。
  * 重写期间，服务器不会被阻塞，它可以正常处理客户端发送的命令。

### AOF 优缺点
* 优点：丢失数据概率更低，日志文本可读等等。
* 缺点：恢复备份速度稍慢，相对占用更多的磁盘空间等等。

## Redis 主从模式

### 主从模式
* 主从模式（Master-Slave）是使用较多的一种软件架构。
* 主（Master）和从（Slave）分别部署在不同的服务器上，当主节点服务器写入数据时，同时也会将数据同步至从节点服务器。
* 主从模式下，数据的同步是自动完成的，这个数据同步的过程，又称为全量复制。
* 通常情况下，主节点负责写入数据，而从节点负责读取数据。
* 这种读写分离的模式可以大大减轻 Redis 主机的数据读取压力，从而提高了Redis 的效率，并同时提供了多个数据备份。
* 主从模式是搭建 Redis Cluster 集群最简单的一种方式。

## Redis 哨兵模式

### 哨兵模式
* Redis 主从模式中，因为系统不具备自动恢复功能，所以当主机宕机后，需要手动把一台从机切换为主机。
* 这个过程需要人为干预，并且会造成一段时间内服务器不可用，同时数据安全性也得不到保障，因此主从模式的可用性较低，不适用于线上生产环境。
* Redis 官方推荐一种高可用方案，也就是Redis 哨兵模式，它弥补了主从模式的不足。
* 哨兵模式是一种特殊的模式，Redis 为其提供了专属的哨兵命令，它是一个独立的进程，能够独立运行。
* 哨兵通过监控的方式获取主机的工作状态是否正常，当主机发生故障时会自动进行故障转移操作。
* 并将其监控的从机提升主机，保证系统的高可用性。
* 实际生产情况中，为避免哨兵发生意外，它一般是由 3～5 个节点组成，这样就算挂了个别节点，该集群仍然可以正常运转。

### 哨兵模式原理

#### 主观下线
* 主观下线，适用于主机和从机。如果在规定的时间内哨兵节点没有收到目标服务器的有效回复，则判定该服务器为“主观下线”。

#### 客观下线
* 客观下线，只适用于主机。哨兵节点发现主服务器出现了故障，它会通过相应的命令，询问其它哨兵节点对主服务器的状态判断。
* 如果超过半数以上的哨兵节点认为主机宕机，则判定主机为“客观下线”。

#### 投票选举
* 所有哨兵节点会通过投票机制，按照谁发现谁去处理的原则，选举发现故障的哨兵节点为领头节点去做故障转移操作。
* 领头节点则按照一定的规则在所有从节点中选择一个最优的作为主机，然后通过发布订阅功能通知其余的从节点更改配置文件，跟随新上任的主机。
* 完成主从切换的操作。

## Redis 集群

### Redis集群
* 主从模式实现了数据的多备份，哨兵模式实现了Redis的高可用。
* 但是还有问题没有解决，这两种模式都只有一个主节点负责写操作，在高并发的写操作场景，主节点存在写请求性能瓶颈与单机Redis容量有限的问题。
* 而Redis的集群模式中可以实现多个节点同时提供写操作，采用无中心结构，每个节点都保存数据，节点之间互相连接从而知道整个集群状态。
* 集群模式其实就是多个主从复制的结构组合起来的。

## Redis 集群分片

### 哈希槽?
* Redis 引入了哈希槽的概念。
* Redis Cluster 采用虚拟哈希槽分区，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内。
* 每个key通过CRC16校验后对16384取模来决定放置哪个槽(Slot)。
* 每一个节点负责维护一部分槽以及槽所映射的键值数据。
* 在Redis Cluster中，只有Master才拥有槽的所有权
* 如果是某个Master的Slave，那么这个Slave只有使用权，没有所有权。
* 计算公式：slot = CRC16(key) % 16384

### 集群分片机制
* 主节点的数量为3，16384除以3，那么每个节点大约得到5460个槽。
* 存储数据时，对要存储的键进行CRC16哈希运算，得到一个值，并取模16384，判断这个值在哪个节点的范围区间。
  * 如键key中包含"{}"，且"{}"中至少包含1个字符，"{}"中的部分是CRC16哈希运算部分。
  * 如键中不包含"{}"，那么整个键都是CRC16哈希运算部分。
* 查询数据时，对要查询的键进行CRC16哈希运算，得到一个值，并取模16384，判断这个值在哪个节点的范围区间。
  * 如键key中包含"{}"，且"{}"中至少包含1个字符，"{}"中的部分是CRC16哈希运算部分。
  * 如键中不包含"{}"，那么整个键都是CRC16哈希运算部分。
* 这样的结构很容易添加或者删除节点，并且无论是添加删除或者修改节点，都不会造成集群不可用。
  * 需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点即可。
  * 需要删除节点时，只需要把移除节点上的哈希槽挪到其他节点即可。

### 添加新Node至集群
```bash
# 添加Node
redis-cli --cluster add-node new_host:new_port existing_host:existing_port
# 集群重新分片
redis-cli --cluster reshard <host:port> or <host> <port>
```

### 删除集群中Node
```bash
# 集群重新分片
redis-cli --cluster reshard <host:port> or <host> <port>
# 添加Node
redis-cli --cluster del-node host:port node_id
```

### 集群故障恢复
* 如果主节点宕机，默认15秒后，从节点能自动升为主节点。
* 如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage为 yes，那么整个集群都挂掉。
* cluster-require-full-coverage为no，那么该节点对应的插槽数据全都不能使用，也无法存储。
```bash
# cluster-require-full-coverage默认值为yes
127.0.0.1:9000> config get cluster-require-full-coverage
1) "cluster-require-full-coverage"
2) "yes
```
* 手动主从切换：可进入从节点使用CLUSTER FAILOVER命令进行切换

## Redis集成Springboot

### Spring-Data-Redis
* Spring-Data-Redis是Spring-Data模块的一部分,专门用来支持在Spring管理项目对Redis的操作。
* 使用Java操作Redis最常用的是使用Jedis,但并不是只有Jedis可以使用。
* Spring-Data-Redis提供了Redis的Java客户端的抽象,和Spring原生集成。
* 比起单纯的使用Redis其他推荐客户端,例如Jedis,会更加稳定、管理起来更加自动化。

### Spring-Data-Redis功能
1. 提供了一个高度封装的“RedisTemplate”类，里面封装了对Redis的数据结构的各种操作
2. RedisTemplate采用是lettuce(基于netty采用异步非阻塞式lO)进行通信，大并发下比Jedis效率更高。
3. RedisTemplate使用序列化器操作Redis数据
> `JdkSerializationRedisSerializer` 默认的Key序列化器，POJO类通过ObjectInputstream/ObjectOutputstream进行序列化操作，最终redis-server中将存储字节序列 \
> `StringRedisSerializer` 适用于Key或者Value为字符串的场景,最轻量级和高效的策略 \
> `GenericJackson2JsonRedisSerializer` jackson-json提供JavaBean与JSON之间的转换能力，能将POJO实例序列化成JSON格式存储在Redis中，也可以将JSON格式的数据转换成POJO实例

### Spring-Data-Redis快速入门
1. 创建项目，导入Maven坐标引入依赖
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240516151002.png)
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```
2. SpringBoot配置文件添加Redis配置
```yml
# Redis/Spring-Data-Redis/src/main/resources/application.yml
spring:
  data:
    redis:
      host: localhost # 本地IP 或是 虚拟机IP
      port: 6379
      password: 123456
      database: 0 # 默认使用 0号 db
```
3. 可按需求配置RedisTemplate序列化器
```java
// Redis/Spring-Data-Redis/src/main/java/config/RedisConfig.java
@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) {

        RedisTemplate<Object, Object> redisTemplate = new RedisTemplate<>();

        //默认的Key序列化器为：JdkSerializationRedisSerializer
        redisTemplate.setKeySerializer(new StringRedisSerializer());
        redisTemplate.setValueSerializer(new StringRedisSerializer());

        redisTemplate.setHashKeySerializer(new StringRedisSerializer());
        redisTemplate.setHashValueSerializer(new StringRedisSerializer());

        redisTemplate.setConnectionFactory(redisConnectionFactory);

        return redisTemplate;
    }
}
```

4. 测试
```java
@SpringBootTest
class SpringDataRedisApplicationTests {

	@Autowired
	private RedisTemplate<Object,Object> redisTemplate;

	@Test
	public void contextLoads(){
		redisTemplate.opsForValue().set("name","zhangsan");
		System.out.println(redisTemplate.opsForValue().get("name")); // zhangsan
	}

	@Test
	public void contextLoads2(){
		redisTemplate.opsForList().leftPushAll("nameList","zhangsan","lisi","wangwu");
		System.out.println(redisTemplate.opsForList().range("nameList",0,-1)); // [wangwu, lisi, zhangsan]
	}

}
```

## 代码附录

### Redis 基本数据类型 (Docker方式)

#### Redis 字符串数据类型
```bash
C:\Windows\System32>docker ps -a
CONTAINER ID   IMAGE             COMMAND                   CREATED        STATUS                       PORTS                               NAMES
260541ddadb7   redis             "docker-entrypoint.s…"   20 hours ago   Exited (255) 5 seconds ago   6379/tcp                            redis
0211e0409935   sonatype/nexus3   "/opt/sonatype/nexus…"   9 days ago     Exited (255) 20 hours ago    0.0.0.0:8081->8081/tcp              nexus
c6471e03b8f8   mysql:latest      "docker-entrypoint.s…"   3 months ago   Exited (255) 20 hours ago    0.0.0.0:3306->3306/tcp, 33060/tcp   mysql-mysql-1
```

```bash
C:\Windows\System32>docker start 260541ddadb7
260541ddadb7
```

```bash
C:\Windows\System32>docker exec -it 260541ddadb7 redis-cli
# SET 设置指定 key 的值
127.0.0.1:6379> set name zhangsan
OK
# GET 获取指定 key 的值
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> set age 18
OK
127.0.0.1:6379> get age
"18"
# SETNX 在 key 不存在时设置 key 的值
127.0.0.1:6379> setnx name lisi # setnx不会顶替
(integer) 0
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> ttl name
(integer) -1 # 永不过期
127.0.0.1:6379> expire name 5 # 5s过期
(integer) 1
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> get name
(nil)
127.0.0.1:6379> set name zhangsan EX 5
OK
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> get name
(nil)
# SETEX 设置指定 key 的值并设过期时间
127.0.0.1:6379> setex name zhangsan 5
(error) ERR value is not an integer or out of range
127.0.0.1:6379> flushdb
OK
127.0.0.1:6379> setex name 5 zhangsan
OK
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> get name
(nil)
# MSET 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在
127.0.0.1:6379> mset name zhangsan name1 lisi name2 wangwu
OK
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> get name1
"lisi"
127.0.0.1:6379> get name2
"wangwu"
# GETSET 设置新值同时获得旧值
127.0.0.1:6379> getset name2 zhangsan
"wangwu"
127.0.0.1:6379> get name2
"zhangsan"
127.0.0.1:6379> set age 18
OK
# INCR/DECR 对 key 的值进行加1或者减1操作
127.0.0.1:6379> incr age
(integer) 19
127.0.0.1:6379> decr age
(integer) 18
# INCRBY/DECRBY 对 key 的值进行自定义加减
127.0.0.1:6379> incrby age 20
(integer) 38
127.0.0.1:6379> decrby age 20
(integer) 18
# SETRANGE 用指定的字符串覆盖给定 key 所储存的字符串值，覆盖的位置从偏移量 offset 开始
127.0.0.1:6379> setrange age 0 5
(integer) 2
127.0.0.1:6379> get age
"58"
# GETRANGE 获取存储在指定 key 中字符串的子字符串。字符串的截取范围由 start 和 end 两个偏移量决定
127.0.0.1:6379> getrange age 0 0
"5"
```

#### Redis 列表数据类型
```bash
127.0.0.1:6379> flushdb
OK
# LPUSH 将一个或多个值插入到列表左端
127.0.0.1:6379> lpush name zhangsan lisi wangwu
(integer) 3
127.0.0.1:6379> lrange name 0 -1
1) "wangwu"
2) "lisi"
3) "zhangsan"
127.0.0.1:6379> flush db
(error) ERR unknown command 'flush', with args beginning with: 'db'
127.0.0.1:6379> flushdb
OK
# RPUSH 将一个或多个值插入到列表右端
127.0.0.1:6379> rpush name zhangsan lisi wangwu
(integer) 3
127.0.0.1:6379> lrange name 0 -1
1) "zhangsan"
2) "lisi"
3) "wangwu"
# LPOP 移出并获取列表的第一个元素
127.0.0.1:6379> lpop name
"zhangsan"
127.0.0.1:6379> lpop name
"lisi"
127.0.0.1:6379> lpop name
"wangwu"
127.0.0.1:6379> lpop name
(nil)
127.0.0.1:6379> rpush name zhangsan lisi wangwu
(integer) 3
# BLPOP 移出并获取列表的第一个元素,如列表没有元素会阻塞列表直到超时或发现元素为止
127.0.0.1:6379> blpop name 5
1) "name"
2) "zhangsan"
127.0.0.1:6379> blpop name 5
1) "name"
2) "lisi"
127.0.0.1:6379> blpop name 5
1) "name"
2) "wangwu"
127.0.0.1:6379> blpop name 5
(nil)
(5.00s)
127.0.0.1:6379> rpush name zhangsan lisi wangwu
(integer) 3
# RPOP 移除并获取列表的最后一个元素
127.0.0.1:6379> rpop name
"wangwu"
127.0.0.1:6379> rpop name 2
1) "lisi"
2) "zhangsan"
127.0.0.1:6379> rpop name 2
(nil)
127.0.0.1:6379> flushdb
OK
127.0.0.1:6379> rpush name zhangsan lisi wangwu
(integer) 3
127.0.0.1:6379> rpush name wangwu wangwu wangwu
(integer) 6
# LRANGE 从左到右获取列表元素
127.0.0.1:6379> lrange name 0 -1
1) "zhangsan"
2) "lisi"
3) "wangwu"
4) "wangwu"
5) "wangwu"
6) "wangwu"
# LREM 根据参数 COUNT 的值，移除列表中与参数 VALUE 相等的元素
127.0.0.1:6379> lrem name 4 wangwu
(integer) 4
127.0.0.1:6379> lrange name 0 -1
1) "zhangsan"
2) "lisi"
```

#### Redis List命令搭配
```bash
127.0.0.1:6379> flushdb
OK
# LPUSH + LPOP = 栈 先进后出
127.0.0.1:6379> lpush name zhangsan lisi wangwu
(integer) 3
127.0.0.1:6379> lpop name
"wangwu"
127.0.0.1:6379> lpop name
"lisi"
127.0.0.1:6379> lpop name
"zhangsan"
# LPUSH + RPOP = 队列 先进先出
127.0.0.1:6379> lpush name zhangsan lisi wangwu
(integer) 3
127.0.0.1:6379> rpop name
"zhangsan"
127.0.0.1:6379> rpop name
"lisi"
127.0.0.1:6379> rpop name
"wangwu"
# LPUSH + BRPOP = 队列 阻塞效果
127.0.0.1:6379> lpush name zhangsan lisi wangwu
(integer) 3
127.0.0.1:6379> brpop name 2
1) "name"
2) "zhangsan"
127.0.0.1:6379> brpop name 2
1) "name"
2) "lisi"
127.0.0.1:6379> brpop name 2
1) "name"
2) "wangwu"
127.0.0.1:6379> brpop name 2
(nil)
(2.00s)
```

#### Redis Set集合
```bash
# SADD 向集合添加一个或多个成员
127.0.0.1:6379> sadd name zhangsan lisi wangwu
(integer) 3
# SMEMBERS 返回集合中的所有成员
127.0.0.1:6379> smembers name
1) "zhangsan"
2) "lisi"
3) "wangwu"
# SISMEMBER 判断 member 元素是否是集合 key 的成员
127.0.0.1:6379> sismember name lisi
(integer) 1
127.0.0.1:6379> sismember name lisi2
(integer) 0
# SREM 移除集合中一个或多个成员
127.0.0.1:6379> srem name wangwu
(integer) 1
127.0.0.1:6379> smembers name
1) "zhangsan"
2) "lisi"
127.0.0.1:6379> flushdb
OK
127.0.0.1:6379> sadd name zhangsan zhangsan lisi lisi wangwu
(integer) 3
127.0.0.1:6379> smembers name
1) "zhangsan"
2) "lisi"
3) "wangwu"
127.0.0.1:6379> sadd name1 zhangsan wangwu
(integer) 2
# SMOVE 将 member 元素从 源集合移动到 目标集合
127.0.0.1:6379> smove name name1 lisi
(integer) 1
127.0.0.1:6379> smembers name1
1) "zhangsan"
2) "wangwu"
3) "lisi"
127.0.0.1:6379> smembers name
1) "zhangsan"
2) "wangwu"
# SINTER 返回所有给定集合的交集
127.0.0.1:6379> sinter name name1
1) "zhangsan"
2) "wangwu"
# SUNION 返回所有给定集合的并集
127.0.0.1:6379> sunion name name1
1) "zhangsan"
2) "wangwu"
3) "lisi"
# SDIFF 返回第一个集合与其他集合之间的差异(注意比较的两个集合有顺序)
127.0.0.1:6379> sdiff name name1
(empty array)
127.0.0.1:6379> sadd name laoliu
(integer) 1
127.0.0.1:6379> sdiff name name1
1) "laoliu"
127.0.0.1:6379> sdiff name1 name
1) "lisi"
127.0.0.1:6379> smembers name
1) "zhangsan"
2) "wangwu"
3) "laoliu"
127.0.0.1:6379> smembers name1
1) "zhangsan"
2) "wangwu"
3) "lisi"
```

#### Redis ZSet有序集合
```bash
127.0.0.1:6379> flushdb
OK
# ZADD 向有序集合添加一个或多个成员，或者更新已存在成员的分数
127.0.0.1:6379> zadd name 100 zhangsan 200 lisi 300 wangwu
(integer) 3
# ZSCORE 返回有序集中，成员的分数值
127.0.0.1:6379> zscore name wangwu
"300"
# ZRANGE 通过索引区间返回有序集合指定区间内的成员
127.0.0.1:6379> zrange name 0 -1
1) "zhangsan"
2) "lisi"
3) "wangwu"
# ZREM 移除有序集合中的一个或多个成员
127.0.0.1:6379> zrem name lisi
(integer) 1
127.0.0.1:6379> zrange name 0 -1
1) "zhangsan"
2) "wangwu"
# ZRANK 返回有序集合中指定成员的排名，从小到大排序
127.0.0.1:6379> zrank name zhangsan
(integer) 0
127.0.0.1:6379> zrank name wangwu
(integer) 1
# ZREVRANK 返回有序集合中指定成员的排名，从大到小排序
127.0.0.1:6379> zrevrank name wangwu
(integer) 0
127.0.0.1:6379> zrevrank name zhangsan
(integer) 1
# ZCOUNT 计算在有序集合中指定区间分数的成员数
127.0.0.1:6379> zcount name 100 300
(integer) 2
127.0.0.1:6379> zcount name 200 300
(integer) 1
127.0.0.1:6379>
```

#### Redis Hash哈希
```bash
127.0.0.1:6379> flushdb
OK
# HSET 将哈希表 key 中的字段 field 的值设为 value
127.0.0.1:6379> hset name name1 zhangsan
(integer) 1
# HGET 获取存储在哈希表中指定字段的值
127.0.0.1:6379> hget name
(error) ERR wrong number of arguments for 'hget' command
127.0.0.1:6379> hget name name1
"zhangsan"
# HDEL 删除一个或多个哈希表字段
127.0.0.1:6379> hdel name
(error) ERR wrong number of arguments for 'hdel' command
127.0.0.1:6379> hdel name name1
(integer) 1
# HMSET 同时将多个 field-value (域-值)对设置到哈希表 key 中
127.0.0.1:6379> hmset name name1 zhangsan name2 lisi name3 wangwu
OK
# HMGET 获取所有给定字段的值
127.0.0.1:6379> hmget name name1 name2 name3
1) "zhangsan"
2) "lisi"
3) "wangwu"
127.0.0.1:6379> hgetall name
1) "name1"
2) "zhangsan"
3) "name2"
4) "lisi"
5) "name3"
6) "wangwu"
# HVALS 获取哈希表中所有值
127.0.0.1:6379> hvals name
1) "zhangsan"
2) "lisi"
3) "wangwu"
```

#### Redis GEO地理位置
```bash
127.0.0.1:6379> flushdb
OK
# GEOADD 将指定的地理空间位置（纬度、经度、名称）添加到指定的 key 中
127.0.0.1:6379> geoadd chinacity 116.0 39.0 beijing 120.0 30.0 shanghai
(integer) 2
# GEOPOS 从 key 里返回所有给定位置元素的位置（即经度和纬度）
127.0.0.1:6379> geopos chinacity beijing shanghai
1) 1) "116.00000113248825073"
   2) "38.99999918434559731"
2) 1) "120.00000089406967163"
   2) "30.00000024997701331"
# GEODIST 返回两个地理位置间的距离，如果两个位置之间的其中一个不存在，那么返回空值
127.0.0.1:6379> geodist chinacity beijing shanghai
"1065751.2416"
127.0.0.1:6379> geodist chinacity beijing shanghai km
"1065.7512"
# GEORADIUSBYMEMBER 根据给定地理位置(具体的位置元素)获取指定范围内的地理位置集合
127.0.0.1:6379> georadiusbymember chinacity beijing 200 km
1) "beijing"
127.0.0.1:6379> georadiusbymember chinacity beijing 2000 km
1) "shanghai"
2) "beijing"
```

#### Redis Bitmap位图
```bash
127.0.0.1:6379> flushdb
OK
# SETBIT 设置或者清除某一位上的值，其返回值是原来位上存储的值，key 在初始状态下所有的位都为 0
127.0.0.1:6379> setbit 2024login 13 1
(integer) 0
127.0.0.1:6379> setbit 2024login 12 0
(integer) 0
127.0.0.1:6379> setbit 2024login 11 0
(integer) 0
127.0.0.1:6379> setbit 2024login 10 1
(integer) 0
# GETBIT 获取某一位上的值
127.0.0.1:6379> getbit 2024login 13
(integer) 1
127.0.0.1:6379> getbit 2024login 12
(integer) 0
127.0.0.1:6379> getbit 2024login 11
(integer) 0
127.0.0.1:6379> getbit 2024login 10
(integer) 1
# BITCOUNT 统计指定位区间上，值为 1 的个数
127.0.0.1:6379> bitcount 2024login
(integer) 2
```

#### Redis HyperLoglog基数统计
```bash
127.0.0.1:6379> flushdb
OK
# PFADD 添加指定元素到 HyperLogLog 中
127.0.0.1:6379> pfadd webview u1 u2 u3
(integer) 1
# PFCOUNT 返回给定 HyperLogLog 的基数估算值
127.0.0.1:6379> pfcount webview
(integer) 3
127.0.0.1:6379> pfadd webview u1 u2 u3 u4 u4
(integer) 1
127.0.0.1:6379> pfcount webview
(integer) 4
127.0.0.1:6379> pfadd weblogin u1 u2 u3 u4 u5
(integer) 1
127.0.0.1:6379> pfcount weblogin
(integer) 5
# PFMERGE 将多个 HyperLogLog 合并为一个 HyperLogLog
127.0.0.1:6379> pfmerge webtoday webview weblogin
OK
127.0.0.1:6379> pfcount webtoday
(integer) 5
```

### Redis RDB持久化
```bash
C:\Windows\System32>docker ps -a
CONTAINER ID   IMAGE             COMMAND                   CREATED        STATUS                        PORTS                               NAMES
260541ddadb7   redis             "docker-entrypoint.s…"   38 hours ago   Exited (255) 11 seconds ago   6379/tcp                            redis
0211e0409935   sonatype/nexus3   "/opt/sonatype/nexus…"   10 days ago    Exited (255) 38 hours ago     0.0.0.0:8081->8081/tcp              nexus
c6471e03b8f8   mysql:latest      "docker-entrypoint.s…"   3 months ago   Exited (255) 38 hours ago     0.0.0.0:3306->3306/tcp, 33060/tcp   mysql-mysql-1

C:\Windows\System32>docker start 260541ddadb7
260541ddadb7

C:\Windows\System32>docker exec -it 260541ddadb7 redis-cli
127.0.0.1:6379> lastsave
(integer) 1715672679
127.0.0.1:6379> save
OK
127.0.0.1:6379> lastsave
(integer) 1715672749
127.0.0.1:6379> bgsave
Background saving started
127.0.0.1:6379> lastsave
(integer) 1715672771
# XX秒一次key值改变进行持久化 空值为关闭RDB
127.0.0.1:6379> config get save
1) "save"
2) "3600 1 300 100 60 10000"
127.0.0.1:6379> config set save ""
OK
127.0.0.1:6379> config get save
1) "save"
2) ""
127.0.0.1:6379> config set save "3600 1 300 100 60 10000"
OK
127.0.0.1:6379> config get save
1) "save"
2) "3600 1 300 100 60 10000"
127.0.0.1:6379> exit

C:\Windows\System32>docker ps
CONTAINER ID   IMAGE     COMMAND                   CREATED        STATUS         PORTS      NAMES
260541ddadb7   redis     "docker-entrypoint.s…"   39 hours ago   Up 5 minutes   6379/tcp   redis

C:\Windows\System32>docker inspect 260541ddadb7
[
    {
        "Id": "260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4",
        "Created": "2024-05-12T17:19:11.337594962Z",
        "Path": "docker-entrypoint.sh",
        "Args": [
            "redis-server"
        ],
        "State": {
            "Status": "running",
            "Running": true,
            "Paused": false,
            "Restarting": false,
            "OOMKilled": false,
            "Dead": false,
            "Pid": 808,
            "ExitCode": 0,
            "Error": "",
            "StartedAt": "2024-05-14T07:44:39.478021771Z",
            "FinishedAt": "2024-05-14T07:44:09.845541718Z"
        },
        "Image": "sha256:9509c4dd19fbb2a8abe044ab2edba261139c141ef4ebba4dcb9e0d9295431288",
        "ResolvConfPath": "/var/lib/docker/containers/260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4/resolv.conf",
        "HostnamePath": "/var/lib/docker/containers/260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4/hostname",
        "HostsPath": "/var/lib/docker/containers/260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4/hosts",
        "LogPath": "/var/lib/docker/containers/260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4/260541ddadb78c81506b4f3af65012a499a06beb5bb0917684b27a96c7e781f4-json.log",
        "Name": "/redis",
        "RestartCount": 0,
        "Driver": "overlay2",
        "Platform": "linux",
        "MountLabel": "",
        "ProcessLabel": "",
        "AppArmorProfile": "",
        "ExecIDs": null,
        "HostConfig": {
            "Binds": null,
            "ContainerIDFile": "",
            "LogConfig": {
                "Type": "json-file",
                "Config": {}
            },
            "NetworkMode": "default",
            "PortBindings": {},
            "RestartPolicy": {
                "Name": "no",
                "MaximumRetryCount": 0
            },
            "AutoRemove": false,
            "VolumeDriver": "",
            "VolumesFrom": null,
            "ConsoleSize": [
                30,
                174
            ],
            "CapAdd": null,
            "CapDrop": null,
            "CgroupnsMode": "host",
            "Dns": [],
            "DnsOptions": [],
            "DnsSearch": [],
            "ExtraHosts": null,
            "GroupAdd": null,
            "IpcMode": "private",
            "Cgroup": "",
            "Links": null,
            "OomScoreAdj": 0,
            "PidMode": "",
            "Privileged": false,
            "PublishAllPorts": false,
            "ReadonlyRootfs": false,
            "SecurityOpt": null,
            "UTSMode": "",
            "UsernsMode": "",
            "ShmSize": 67108864,
            "Runtime": "runc",
            "Isolation": "",
            "CpuShares": 0,
            "Memory": 0,
            "NanoCpus": 0,
            "CgroupParent": "",
            "BlkioWeight": 0,
            "BlkioWeightDevice": [],
            "BlkioDeviceReadBps": [],
            "BlkioDeviceWriteBps": [],
            "BlkioDeviceReadIOps": [],
            "BlkioDeviceWriteIOps": [],
            "CpuPeriod": 0,
            "CpuQuota": 0,
            "CpuRealtimePeriod": 0,
            "CpuRealtimeRuntime": 0,
            "CpusetCpus": "",
            "CpusetMems": "",
            "Devices": [],
            "DeviceCgroupRules": null,
            "DeviceRequests": null,
            "MemoryReservation": 0,
            "MemorySwap": 0,
            "MemorySwappiness": null,
            "OomKillDisable": false,
            "PidsLimit": null,
            "Ulimits": null,
            "CpuCount": 0,
            "CpuPercent": 0,
            "IOMaximumIOps": 0,
            "IOMaximumBandwidth": 0,
            "MaskedPaths": [
                "/proc/asound",
                "/proc/acpi",
                "/proc/kcore",
                "/proc/keys",
                "/proc/latency_stats",
                "/proc/timer_list",
                "/proc/timer_stats",
                "/proc/sched_debug",
                "/proc/scsi",
                "/sys/firmware",
                "/sys/devices/virtual/powercap"
            ],
            "ReadonlyPaths": [
                "/proc/bus",
                "/proc/fs",
                "/proc/irq",
                "/proc/sys",
                "/proc/sysrq-trigger"
            ]
        },
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/21f8e0463b7a2a509c15c860b9621e7b1afb5bacba15c2afa58861182034aa7e-init/diff:/var/lib/docker/overlay2/4b7bf46ede5158fff0653d1a386c307645cd0a8b1383369c54b90a4adf0569e1/diff:/var/lib/docker/overlay2/21aa07359d2ebaf7b2478dbca882205c7a4dec3843870a0aa2b81b9e090a0ad0/diff:/var/lib/docker/overlay2/ac7ea050ef71107c4e9890dcb17c35f15ee86c2c1c150a2c402dc6332be3ee69/diff:/var/lib/docker/overlay2/2293d6f059dee682c889fbb97de0bcfe394d62d16f3489b02bd157bc0cce0f04/diff:/var/lib/docker/overlay2/d425416f7c2f85a33d510901421afc60e8b252ac2e6753f925d24910ff093a38/diff:/var/lib/docker/overlay2/9be94e2fe18c3490aa4c009798fe2ac35c9683fe7302873b6c0217b4b726ef86/diff:/var/lib/docker/overlay2/25903f18c1129f8179da81e4f367f92bf6314c6847719ed816a7aabb9ac3b570/diff:/var/lib/docker/overlay2/9701640e8deee6319fb61f95ded93111ba5678c5130707338e2b96136fbf0713/diff",
                "MergedDir": "/var/lib/docker/overlay2/21f8e0463b7a2a509c15c860b9621e7b1afb5bacba15c2afa58861182034aa7e/merged",
                "UpperDir": "/var/lib/docker/overlay2/21f8e0463b7a2a509c15c860b9621e7b1afb5bacba15c2afa58861182034aa7e/diff",
                "WorkDir": "/var/lib/docker/overlay2/21f8e0463b7a2a509c15c860b9621e7b1afb5bacba15c2afa58861182034aa7e/work"
            },
            "Name": "overlay2"
        },
        "Mounts": [
            {
                "Type": "volume",
                "Name": "e42f0b4b1433be821630317e1586afe93d2714ca0409d2b24117ecb9c49e4d0b",
                "Source": "/var/lib/docker/volumes/e42f0b4b1433be821630317e1586afe93d2714ca0409d2b24117ecb9c49e4d0b/_data",
                "Destination": "/data",
                "Driver": "local",
                "Mode": "",
                "RW": true,
                "Propagation": ""
            }
        ],
        "Config": {
            "Hostname": "260541ddadb7",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "6379/tcp": {}
            },
            "Tty": false,
            "OpenStdin": false,
            "StdinOnce": false,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "GOSU_VERSION=1.17",
                "REDIS_VERSION=7.2.4",
                "REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-7.2.4.tar.gz",
                "REDIS_DOWNLOAD_SHA=8d104c26a154b29fd67d6568b4f375212212ad41e0c2caa3d66480e78dbd3b59"
            ],
            "Cmd": [
                "redis-server"
            ],
            "Image": "redis",
            "Volumes": {
                "/data": {}
            },
            "WorkingDir": "/data",
            "Entrypoint": [
                "docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {}
        },
        "NetworkSettings": {
            "Bridge": "",
            "SandboxID": "8dd8f94d97108d161c2319d3bfe858a2343ad31d7c4b25c4474b22a91bca5aed",
            "HairpinMode": false,
            "LinkLocalIPv6Address": "",
            "LinkLocalIPv6PrefixLen": 0,
            "Ports": {
                "6379/tcp": null
            },
            "SandboxKey": "/var/run/docker/netns/8dd8f94d9710",
            "SecondaryIPAddresses": null,
            "SecondaryIPv6Addresses": null,
            "EndpointID": "2d07c0b58aca5c33adfebf5e4181c1d90529f3972fabadda57a51e5b54ed9f64",
            "Gateway": "172.17.0.1",
            "GlobalIPv6Address": "",
            "GlobalIPv6PrefixLen": 0,
            "IPAddress": "172.17.0.2",
            "IPPrefixLen": 16,
            "IPv6Gateway": "",
            "MacAddress": "02:42:ac:11:00:02",
            "Networks": {
                "bridge": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "MacAddress": "02:42:ac:11:00:02",
                    "NetworkID": "723799a55daa18520eb1abc474c8d03f2ba4dd30cd6f56f875b4fac0afb60e7b",
                    "EndpointID": "2d07c0b58aca5c33adfebf5e4181c1d90529f3972fabadda57a51e5b54ed9f64",
                    "Gateway": "172.17.0.1",
                    "IPAddress": "172.17.0.2",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "DriverOpts": null
                }
            }
        }
    }
]

C:\Windows\System32>docker exec -it 260541ddadb7 redis-cli
127.0.0.1:6379> auth 123456
(error) ERR AUTH <password> called without any password configured for the default user. Are you sure your configuration is correct?
```

```bash
127.0.0.1:6379> clear
# 持久化操作失败，Redis则会停止提供接受操作
127.0.0.1:6379> config get stop-writes-on-bgsave-error
1) "stop-writes-on-bgsave-error"
2) "yes"
# 持久化操作的时候采用LZF压缩字符串和对象
127.0.0.1:6379> config get rdbcompression
1) "rdbcompression"
2) "yes"
# 完整性检查，存储或者加载持久化文件的时候会有性能下降
127.0.0.1:6379> config get rdbchecksum
1) "rdbchecksum"
2) "yes"
# 持久化文件名称设置
127.0.0.1:6379> config get dbfilename
1) "dbfilename"
2) "dump.rdb"
# 持久化文件保存目录设置
127.0.0.1:6379> config get dir
1) "dir"
2) "/data"
127.0.0.1:6379> keys '*'
1) "chinacity"
127.0.0.1:6379> set name zhangsan
OK
127.0.0.1:6379> keys '*'
1) "chinacity"
2) "name"
127.0.0.1:6379> bgsave
Background saving started
127.0.0.1:6379> exit

C:\Windows\System32>docker ps
CONTAINER ID   IMAGE     COMMAND                   CREATED        STATUS          PORTS      NAMES
260541ddadb7   redis     "docker-entrypoint.s…"   39 hours ago   Up 24 minutes   6379/tcp   redis

C:\Windows\System32>docker restart 260541ddadb7
260541ddadb7

C:\Windows\System32>docker start 260541ddadb7
260541ddadb7

C:\Windows\System32>docker exec -it 260541ddadb7 redis-cli
127.0.0.1:6379> auth 123456
(error) ERR AUTH <password> called without any password configured for the default user. Are you sure your configuration is correct?
127.0.0.1:6379> keys '*'
1) "name"
2) "chinacity"
127.0.0.1:6379> get name
"zhangsan"
127.0.0.1:6379> exit

C:\Windows\System32>docker exec -it 260541ddadb7 bash
root@260541ddadb7:/data# ls
dump.rdb
root@260541ddadb7:/data# cat dump.rdb
REDIS0011�     redis-ver7.2.4�
redis-bits�@�ctime�>Cf�used-mem�h��aof-base���     chinacity..�shanghai  �3vbc2g       �beijin���4 ��t  �namzhangsan�������
```

### Redis AOF持久化
```bash
root@260541ddadb7:/data# exit
exit

C:\Windows\System32>docker exec -it 260541ddadb7 redis-cli
# 默认AOF为关闭状态
127.0.0.1:6379> config get appendonly
1) "appendonly"
2) "no"
127.0.0.1:6379> config set appendonly yes
OK
127.0.0.1:6379> config get appendonly
1) "appendonly"
2) "yes"
# 默认AOF文件名
127.0.0.1:6379> config get appendfilename
1) "appendfilename"
2) "appendonly.aof"
# 默认AOF文件存储目录
127.0.0.1:6379> config get appenddirname
1) "appenddirname"
2) "appendonlydir"
# 默认值为everysec(每秒同步) 可设置为always(每一次修改操作都进行同步)/no(操作系统控制同步操作 性能最好)
127.0.0.1:6379> config get appendfsync
1) "appendfsync"
2) "everysec"
# 默认为关闭状态，意思是同时在执行重写操作和写AOF文件时不会丢失数据，但是要忍受可能出现的阻塞与高延迟
127.0.0.1:6379> config get no-appendfsync-on-rewrite
1) "no-appendfsync-on-rewrite"
2) "no"
# 文件超过最小基准值的百分比时进行重写操作，默认百分比为100
127.0.0.1:6379> config get auto-aof-rewrite-percentage
1) "auto-aof-rewrite-percentage"
2) "100"
# 触发重写条件的文件基准值，默认为64M
127.0.0.1:6379> config get auto-aof-rewrite-min-size
1) "auto-aof-rewrite-min-size"
2) "67108864"
127.0.0.1:6379> flushdb
OK
127.0.0.1:6379> keys '*'
(empty array)
127.0.0.1:6379> lpush name zhangsan lisi wangwu laoliu
(integer) 4
127.0.0.1:6379> keys '*'
1) "name"
127.0.0.1:6379> exit

C:\Windows\System32>docker exec -it 260541ddadb7 bash
root@260541ddadb7:/data# ls
appendonlydir  dump.rdb
root@260541ddadb7:/data# cd appendonlydir/
root@260541ddadb7:/data/appendonlydir# ls
appendonly.aof.1.base.rdb  appendonly.aof.1.incr.aof  appendonly.aof.manifest
root@260541ddadb7:/data/appendonlydir# cat appendonly.aof.1.incr.aof
*2
$6
SELECT
$1
0
*1
$7
flushdb
*6
$5
lpush
$4
name
$8
zhangsan
$4
lisi
$6
wangwu
$6
laoliu
```

### Redis 主从模式搭建

#### 命令搭建
```bash
root@DESKTOP-9MBCA87:/home/toubun# ps -ef | grep redis
toubun     409   407  0 18:12 pts/2    00:00:00 redis-server *:6379
root       421    34  0 18:17 pts/1    00:00:00 grep redis
# 命令搭建主从模式
root@DESKTOP-9MBCA87:/home/toubun# redis-server --port 6380 --slaveof 127.0.0.1 6379 --daemonize yes
422:C 14 May 2024 18:18:54.844 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
root@DESKTOP-9MBCA87:/home/toubun# sysctl vm.overcommit_memory=1
vm.overcommit_memory = 1
# 命令启动从机 主机为6379的redis
root@DESKTOP-9MBCA87:/home/toubun# redis-server --port 6380 --slaveof 127.0.0.1 6379 --daemonize yes
# 查看redis进程
root@DESKTOP-9MBCA87:/home/toubun# ps -ef | grep redis
toubun     409   407  0 18:12 pts/2    00:00:00 redis-server *:6379
root       423    26  0 18:18 ?        00:00:00 redis-server *:6380
root       434    34  0 18:19 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/home/toubun# redis-cli -p 6380
# 从机不能写入操作
127.0.0.1:6380> set name zhangsan
(error) READONLY You can't write against a read only replica.
```
```bash
# 从机信息
127.0.0.1:6380> info replication
# Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:8
master_sync_in_progress:0
slave_read_repl_offset:266
slave_repl_offset:266
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:076e4252fa539f17a04b2d8eafc05292cb4424f1
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:266
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:15
repl_backlog_histlen:252
# 启动进入新redis-server
127.0.0.1:6380> slaveof no one
OK
127.0.0.1:6380> set name zhangsan
OK
127.0.0.1:6380> get name
"zhangsan"
127.0.0.1:6380> info replication
# Replication
role:master
connected_slaves:0
master_failover_state:no-failover
master_replid:be5e74e3a248be28d78a2d219957186046a551eb
master_replid2:076e4252fa539f17a04b2d8eafc05292cb4424f1
master_repl_offset:480
second_repl_offset:421
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:15
repl_backlog_histlen:466
127.0.0.1:6380> flushdb
OK
# 连接主机查看信息
127.0.0.1:6380> slaveof 127.0.0.1 6379
OK
127.0.0.1:6380> info replication
# Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_read_repl_offset:434
slave_repl_offset:434
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:076e4252fa539f17a04b2d8eafc05292cb4424f1
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:434
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:435
repl_backlog_histlen:0
# 写操作
127.0.0.1:6380> set name zhangsan
(error) READONLY You can't write against a read only replica.
```
```bash
127.0.0.1:6380> keys '*'
(empty array)
127.0.0.1:6380> exit
root@DESKTOP-9MBCA87:/home/toubun# redis-cli -p 6379
127.0.0.1:6379> info replication
# Replication
role:master
connected_slaves:1
slave0:ip=127.0.0.1,port=6380,state=online,offset=490,lag=1
master_failover_state:no-failover
master_replid:076e4252fa539f17a04b2d8eafc05292cb4424f1
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:490
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:490
127.0.0.1:6379> keys '*'
(empty array)
127.0.0.1:6379> set name zhangsan
OK
127.0.0.1:6379> keys '*'
1) "name"
127.0.0.1:6379> exit
# 验证主从复制
root@DESKTOP-9MBCA87:/home/toubun# redis-cli -p 6380
127.0.0.1:6380> keys '*'
1) "name"
127.0.0.1:6380> get name
"zhangsan"
127.0.0.1:6380> exit
root@DESKTOP-9MBCA87:/home/toubun# ps -ef | grep redis
toubun     409   407  0 18:12 pts/2    00:00:01 redis-server *:6379
root       423    26  0 18:18 ?        00:00:00 redis-server *:6380
root       440    34  0 18:27 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/home/toubun# kill 423
root@DESKTOP-9MBCA87:/home/toubun# ps -ef | grep redis
toubun     409   407  0 18:12 pts/2    00:00:01 redis-server *:6379
root       442    34  0 18:27 pts/1    00:00:00 grep redis
```

```bash
toubun@DESKTOP-9MBCA87:~$ redis-server
409:C 14 May 2024 18:12:15.741 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
409:C 14 May 2024 18:12:15.741 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
409:C 14 May 2024 18:12:15.741 * Redis version=7.2.4, bits=64, commit=00000000, modified=0, pid=409, just started
409:C 14 May 2024 18:12:15.741 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
409:M 14 May 2024 18:12:15.741 * Increased maximum number of open files to 10032 (it was originally set to 1024).
409:M 14 May 2024 18:12:15.741 * monotonic clock: POSIX clock_gettime
                _._
           _.-``__ ''-._
      _.-``    `.  `_.  ''-._           Redis 7.2.4 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._
 (    '      ,       .-`  | `,    )     Running in standalone mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379
 |    `-._   `._    /     _.-'    |     PID: 409
  `-._    `-._  `-./  _.-'    _.-'
 |`-._`-._    `-.__.-'    _.-'_.-'|
 |    `-._`-._        _.-'_.-'    |           https://redis.io
  `-._    `-._`-.__.-'_.-'    _.-'
 |`-._`-._    `-.__.-'    _.-'_.-'|
 |    `-._`-._        _.-'_.-'    |
  `-._    `-._`-.__.-'_.-'    _.-'
      `-._    `-.__.-'    _.-'
          `-._        _.-'
              `-.__.-'

409:M 14 May 2024 18:12:15.742 * Server initialized
409:M 14 May 2024 18:12:15.742 * Loading RDB produced by version 7.2.4
409:M 14 May 2024 18:12:15.742 * RDB age 13 seconds
409:M 14 May 2024 18:12:15.742 * RDB memory usage when created 0.83 Mb
409:M 14 May 2024 18:12:15.742 * Done loading RDB, keys loaded: 0, keys expired: 0.
409:M 14 May 2024 18:12:15.742 * DB loaded from disk: 0.000 seconds
409:M 14 May 2024 18:12:15.742 * Ready to accept connections tcp
409:M 14 May 2024 18:18:54.846 * Replica 127.0.0.1:6380 asks for synchronization
409:M 14 May 2024 18:18:54.846 * Full resync requested by replica 127.0.0.1:6380
409:M 14 May 2024 18:18:54.846 * Replication backlog created, my new replication IDs are '076e4252fa539f17a04b2d8eafc05292cb4424f1' and '0000000000000000000000000000000000000000'
409:M 14 May 2024 18:18:54.846 * Delay next BGSAVE for diskless SYNC
409:M 14 May 2024 18:18:59.802 * Starting BGSAVE for SYNC with target: replicas sockets
409:M 14 May 2024 18:18:59.802 * Background RDB transfer started by pid 429
429:C 14 May 2024 18:18:59.802 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
409:M 14 May 2024 18:18:59.803 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
409:M 14 May 2024 18:18:59.805 * Background RDB transfer terminated with success
409:M 14 May 2024 18:18:59.805 * Streamed RDB transfer with replica 127.0.0.1:6380 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
409:M 14 May 2024 18:18:59.805 * Synchronization with replica 127.0.0.1:6380 succeeded
409:M 14 May 2024 18:23:52.966 * Connection with replica 127.0.0.1:6380 lost.
409:M 14 May 2024 18:24:33.902 * Replica 127.0.0.1:6380 asks for synchronization
409:M 14 May 2024 18:24:33.902 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for 'be5e74e3a248be28d78a2d219957186046a551eb', my replication IDs are '076e4252fa539f17a04b2d8eafc05292cb4424f1' and '0000000000000000000000000000000000000000')
409:M 14 May 2024 18:24:33.902 * Delay next BGSAVE for diskless SYNC
409:M 14 May 2024 18:24:38.779 * Starting BGSAVE for SYNC with target: replicas sockets
409:M 14 May 2024 18:24:38.779 * Background RDB transfer started by pid 436
436:C 14 May 2024 18:24:38.780 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
409:M 14 May 2024 18:24:38.780 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
409:M 14 May 2024 18:24:38.782 * Background RDB transfer terminated with success
409:M 14 May 2024 18:24:38.782 * Streamed RDB transfer with replica 127.0.0.1:6380 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
409:M 14 May 2024 18:24:38.782 * Synchronization with replica 127.0.0.1:6380 succeeded
409:M 14 May 2024 18:27:34.161 * Connection with replica 127.0.0.1:6380 lost.
```

#### 修改配置文件搭建
```bash
root@DESKTOP-9MBCA87:/home/toubun# cd /etc/redis/
root@DESKTOP-9MBCA87:/etc/redis# ls
dump.rdb  redis.conf
root@DESKTOP-9MBCA87:/etc/redis# vim
root@DESKTOP-9MBCA87:/etc/redis# vim redis_6380.conf
```
```bash
# i
slaveof 127.0.0.1 6379
port 6380
daemonize yes
# ESC
# :wq
# ENTER
```
```bash
root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_6380.conf
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
toubun     409   407  0 18:12 pts/2    00:00:03 redis-server *:6379
root       450    26  0 18:55 ?        00:00:00 redis-server *:6380
root       458    34  0 18:55 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 6380
127.0.0.1:6380> info replication
# Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:6
master_sync_in_progress:0
slave_read_repl_offset:774
slave_repl_offset:774
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:076e4252fa539f17a04b2d8eafc05292cb4424f1
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:774
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:747
repl_backlog_histlen:28
127.0.0.1:6380> set name zhangsan
(error) READONLY You can't write against a read only replica.
```

### Redis 哨兵模式搭建
```bash
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
toubun     409   406  0 19:44 ?        00:00:04 redis-server *:6379
root       450    26  0 20:27 ?        00:00:01 redis-server *:6380
root       463    34  0 20:45 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/etc/redis# redis-server --port 6381 --slaveof 127.0.0.1 6379 --daemonize yes
# 1主2从
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
toubun     409   406  0 19:44 ?        00:00:04 redis-server *:6379
root       450    26  0 20:27 ?        00:00:01 redis-server *:6380
root       465    26  0 20:46 ?        00:00:00 redis-server *:6381
root       472    34  0 20:46 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/etc/redis# vim sentinel_1.conf
```
```bash
port 9100
sentinel monitor smaster 127.0.0.1 6379 2
daemonize yes
```
```bash
root@DESKTOP-9MBCA87:/etc/redis# vim sentinel_2.conf
```
```bash
port 9101
sentinel monitor smaster 127.0.0.1 6379 2
daemonize yes
```
```bash
root@DESKTOP-9MBCA87:/etc/redis# vim sentinel_3.conf
```
```bash
port 9102
sentinel monitor smaster 127.0.0.1 6379 2
daemonize yes
```
```bash
root@DESKTOP-9MBCA87:/etc/redis# ls
dump.rdb  redis.conf  redis_6380.conf  sentinel_1.conf  sentinel_2.conf  sentinel_3.conf
root@DESKTOP-9MBCA87:/etc/redis# redis-server sentinel_1.conf --sentinel
root@DESKTOP-9MBCA87:/etc/redis# redis-server sentinel_2.conf --sentinel
root@DESKTOP-9MBCA87:/etc/redis# redis-server sentinel_3.conf --sentinel
root@DESKTOP-9MBCA87:/etc/redis# systemctl stop redis-server # 关闭主机失败
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
toubun     409   406  0 19:44 ?        00:00:06 redis-server *:6379 # 主机依然存在
root       450    26  0 20:27 ?        00:00:03 redis-server *:6380
root       465    26  0 20:46 ?        00:00:02 redis-server *:6381
root       499    26  0 21:07 ?        00:00:00 redis-server *:9100 [sentinel]
root       505    26  0 21:07 ?        00:00:00 redis-server *:9101 [sentinel]
root       511    26  0 21:08 ?        00:00:00 redis-server *:9102 [sentinel]
root       526    34  0 21:11 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/etc/redis# systemctl list-units --type=service | grep redis
redis-server.service    loaded inactive dead    Advanced key-value store
root@DESKTOP-9MBCA87:/etc/redis# sudo kill 409 # 解决方法
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root       450    26  0 20:27 ?        00:00:04 redis-server *:6380
root       465    26  0 20:46 ?        00:00:02 redis-server *:6381
root       499    26  0 21:07 ?        00:00:01 redis-server *:9100 [sentinel]
root       505    26  0 21:07 ?        00:00:01 redis-server *:9101 [sentinel]
root       511    26  0 21:08 ?        00:00:01 redis-server *:9102 [sentinel]
root       533    34  0 21:16 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 9100
127.0.0.1:9100> info sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_tilt_since_seconds:-1
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=smaster,status=ok,address=127.0.0.1:6381,slaves=2,sentinels=3
127.0.0.1:9100> exit
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 6381 # 新的主机号
127.0.0.1:6381> info replication
# Replication
role:master # 成为master
connected_slaves:1
slave0:ip=127.0.0.1,port=6380,state=online,offset=142471,lag=1
master_failover_state:no-failover
master_replid:fe6502c50752a4c3eacefb9eaf3e0140de58c57e
master_replid2:076e4252fa539f17a04b2d8eafc05292cb4424f1
master_repl_offset:142616
second_repl_offset:102345
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:747
repl_backlog_histlen:141870
127.0.0.1:6381> exit
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 6380
127.0.0.1:6380> config get slaveof
1) "slaveof"
2) "127.0.0.1 6381"
127.0.0.1:6380> exit
root@DESKTOP-9MBCA87:/etc/redis# systemctl start redis-server # 启动命令
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root       450    26  0 20:27 ?        00:00:04 redis-server *:6380
root       465    26  0 20:46 ?        00:00:03 redis-server *:6381
root       499    26  0 21:07 ?        00:00:02 redis-server *:9100 [sentinel]
root       505    26  0 21:07 ?        00:00:02 redis-server *:9101 [sentinel]
root       511    26  0 21:08 ?        00:00:02 redis-server *:9102 [sentinel]
redis      539    26  0 21:22 ?        00:00:00 /usr/bin/redis-server 127.0.0.1:6379 # 重新启动原主机
root       545    34  0 21:22 pts/1    00:00:00 grep redis
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 6379
127.0.0.1:6379> info replication
# Replication
role:slave # 主机=>从属
master_host:127.0.0.1
master_port:6381 # 新主机
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_read_repl_offset:204643
slave_repl_offset:204643
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:fe6502c50752a4c3eacefb9eaf3e0140de58c57e
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:204643
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:174936
repl_backlog_histlen:29708
127.0.0.1:6379> config get slaveof
1) "slaveof"
2) "127.0.0.1 6381" # 新主机
127.0.0.1:6379> exit
root@DESKTOP-9MBCA87:/etc/redis# ls
dump.rdb  redis.conf  redis_6380.conf  sentinel_1.conf  sentinel_2.conf  sentinel_3.conf
root@DESKTOP-9MBCA87:/etc/redis# cat redis.conf
# Redis configuration file example.
#
# Note that in order to read the configuration file, Redis must be
# started with the file path as first argument:
#
# ./redis-server /path/to/redis.conf

# 此处省略...

# Generated by CONFIG REWRITE
save 3600 1
save 300 100
save 60 10000
replicaof 127.0.0.1 6381 # 新主机号
latency-tracking-info-percentiles 50 99 99.9
user default on nopass sanitize-payload ~* &* +@all
```

### Redis 集群搭建
```bash
toubun@DESKTOP-9MBCA87:~$ sudo su
[sudo] password for toubun: 123456

root@DESKTOP-9MBCA87:/home/toubun# cd /etc/redis

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9000.conf
# 新建 redis_9000.conf 文件,并添加以下配置信息
port 9000
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9000.pid
cluster-enabled yes
cluster-config-file nodes-9000.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9001.conf
# 新建 redis_9001.conf 文件,并添加以下配置信息
port 9001
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9001.pid
cluster-enabled yes
cluster-config-file nodes-9001.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9002.conf
# 新建 redis_9002.conf 文件,并添加以下配置信息
port 9002
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9002.pid
cluster-enabled yes
cluster-config-file nodes-9002.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9003.conf
# 新建 redis_9003.conf 文件,并添加以下配置信息
port 9003
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9003.pid
cluster-enabled yes
cluster-config-file nodes-9003.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9004.conf
# 新建 redis_9004.conf 文件,并添加以下配置信息
port 9004
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9004.pid
cluster-enabled yes
cluster-config-file nodes-9004.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9005.conf
# 新建 redis_9005.conf 文件,并添加以下配置信息
port 9005
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9005.pid
cluster-enabled yes
cluster-config-file nodes-9005.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# ls
dump.rdb  redis.conf       redis_9000.conf  redis_9002.conf  redis_9004.conf  sentinel_1.conf  sentinel_3.conf
exit      redis_6380.conf  redis_9001.conf  redis_9003.conf  redis_9005.conf  sentinel_2.conf

root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root        22    20  0 16:22 pts/1    00:00:00 vim redis_9000.conf # 需关闭
root        54    20  0 16:46 pts/1    00:00:00 grep redis
# root@DESKTOP-9MBCA87:/etc/redis# sudo rm .redis_9000.conf.swp # 但依然存在
# root@DESKTOP-9MBCA87:/etc/redis# kill 22 # 但依然存在
# 重启Debian后发现已成功清除

root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root        85    83  0 16:57 pts/1    00:00:00 grep redis

root@DESKTOP-9MBCA87:/etc/redis# rm -rf /var/run/redis_*

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9000.conf
86:C 15 May 2024 17:07:52.281 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
86:C 15 May 2024 17:07:52.281 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.

root@DESKTOP-9MBCA87:/etc/redis# sysctl vm.overcommit_memory=1
vm.overcommit_memory = 1

# 启动redis-server
root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9000.conf
93:C 15 May 2024 17:08:17.794 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9001.conf
95:C 15 May 2024 17:09:02.891 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9002.conf
101:C 15 May 2024 17:09:06.170 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9003.conf
107:C 15 May 2024 17:09:09.859 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9004.conf
113:C 15 May 2024 17:09:12.188 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9005.conf
119:C 15 May 2024 17:09:15.258 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

# 验证进程
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root        87    77  0 17:07 ?        00:00:00 redis-server *:9000 [cluster]
root        96    77  0 17:09 ?        00:00:00 redis-server *:9001 [cluster]
root       102    77  0 17:09 ?        00:00:00 redis-server *:9002 [cluster]
root       108    77  0 17:09 ?        00:00:00 redis-server *:9003 [cluster]
root       114    77  0 17:09 ?        00:00:00 redis-server *:9004 [cluster]
root       120    77  0 17:09 ?        00:00:00 redis-server *:9005 [cluster]
root       126    83  0 17:10 pts/1    00:00:00 grep redis

# 验证现在集群还未搭建完成
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 9000
127.0.0.1:9000> CLUSTER INFO
cluster_state:fail
cluster_slots_assigned:0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:0
cluster_current_epoch:0
cluster_my_epoch:0
cluster_stats_messages_sent:0
cluster_stats_messages_received:0
total_cluster_links_buffer_limit_exceeded:0
127.0.0.1:9000> exit

# 一主一从的方式搭建集群
root@DESKTOP-9MBCA87:/etc/redis# redis-cli --cluster create --cluster-replicas 1 127.0.0.1:9000 127.0.0.1:9001 127.0.0.1:9002 127.0.0.1:9003 127.0.0.1:9004 127.0.0.1:9005 # 注意ip地址，可参考【问题22.5】
>>> Performing hash slots allocation on 6 nodes...
Master[0] -> Slots 0 - 5460
Master[1] -> Slots 5461 - 10922
Master[2] -> Slots 10923 - 16383
Adding replica 127.0.0.1:9004 to 127.0.0.1:9000
Adding replica 127.0.0.1:9005 to 127.0.0.1:9001
Adding replica 127.0.0.1:9003 to 127.0.0.1:9002
>>> Trying to optimize slaves allocation for anti-affinity
[WARNING] Some slaves are in the same host as their master # 提醒是在同一台机器上所做操作
M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
   slots:[0-5460] (5461 slots) master
M: 8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001
   slots:[5461-10922] (5462 slots) master
M: 34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002
   slots:[10923-16383] (5461 slots) master
S: 44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003
   replicates ca650cf3796e78fa346b96d1b8fef040a570e1ed
S: 03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004
   replicates 8aeb37884db4ee8568c7fc3cbfef6be14003581f
S: 8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005
   replicates 34c1ea22a04c30d7e28223d0a21716a2325ce6af
Can I set the above configuration? (type 'yes' to accept): yes # yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
.
>>> Performing Cluster Check (using node 127.0.0.1:9000)
M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
M: 8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004
   slots: (0 slots) slave
   replicates 8aeb37884db4ee8568c7fc3cbfef6be14003581f
S: 44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003
   slots: (0 slots) slave
   replicates ca650cf3796e78fa346b96d1b8fef040a570e1ed
S: 8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005
   slots: (0 slots) slave
   replicates 34c1ea22a04c30d7e28223d0a21716a2325ce6af
M: 34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered. # 哈希槽分配

# 验证集群搭建完成
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -p 9000
127.0.0.1:9000> CLUSTER INFO
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:1
cluster_stats_messages_ping_sent:61
cluster_stats_messages_pong_sent:65
cluster_stats_messages_sent:126
cluster_stats_messages_ping_received:60
cluster_stats_messages_pong_received:61
cluster_stats_messages_meet_received:5
cluster_stats_messages_received:126
total_cluster_links_buffer_limit_exceeded:0

127.0.0.1:9000> CLUSTER NODES
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 master - 0 1715776781089 2 connected 5461-10922
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715776780086 2 connected
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715776781000 1 connected
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715776783095 3 connected
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 myself,master - 0 1715776780000 1 connected 0-5460
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715776782092 3 connected 10923-16383

127.0.0.1:9000> exit
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9000

127.0.0.1:9000> set name zhangsan
-> Redirected to slot [5798] located at 127.0.0.1:9001
OK

127.0.0.1:9001> get name
"zhangsan"
```

### Redis 集群分片机制
```bash
127.0.0.1:9001> CLUSTER KEYSLOT name
(integer) 5798 # 9001 slots:[5461-10922] (5462 slots) master
```

### Redis 集群分片操作

#### 添加新Node至集群
```bash
root@DESKTOP-9MBCA87:/etc/redis# ls
appendonlydir  nodes-9000.conf  nodes-9003.conf  redis.conf       redis_9001.conf  redis_9004.conf  sentinel_2.conf
dump.rdb       nodes-9001.conf  nodes-9004.conf  redis_6380.conf  redis_9002.conf  redis_9005.conf  sentinel_3.conf
exit           nodes-9002.conf  nodes-9005.conf  redis_9000.conf  redis_9003.conf  sentinel_1.conf

root@DESKTOP-9MBCA87:/etc/redis# cp redis_9005.conf redis_9006.conf

root@DESKTOP-9MBCA87:/etc/redis# ls
appendonlydir  nodes-9000.conf  nodes-9003.conf  redis.conf       redis_9001.conf  redis_9004.conf  sentinel_1.conf
dump.rdb       nodes-9001.conf  nodes-9004.conf  redis_6380.conf  redis_9002.conf  redis_9005.conf  sentinel_2.conf
exit           nodes-9002.conf  nodes-9005.conf  redis_9000.conf  redis_9003.conf  redis_9006.conf  sentinel_3.conf

root@DESKTOP-9MBCA87:/etc/redis# vim redis_9006.conf
port 9006
daemonize yes
protected-mode no
appendonly yes
pidfile /var/run/redis_9006.pid
cluster-enabled yes
cluster-config-file nodes-9006.conf
cluster-node-timeout 15000

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9006.conf
26:C 15 May 2024 23:02:33.349 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
26:C 15 May 2024 23:02:33.349 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.

root@DESKTOP-9MBCA87:/etc/redis# sysctl vm.overcommit_memory=1
vm.overcommit_memory = 1

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9006.conf
33:C 15 May 2024 23:02:47.801 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root        27    14  0 23:02 ?        00:00:00 redis-server *:9006 [cluster]
root        37    20  0 23:03 pts/1    00:00:00 grep redis

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9000.conf
45:C 15 May 2024 23:05:53.754 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9001.conf
51:C 15 May 2024 23:05:57.713 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9002.conf
57:C 15 May 2024 23:06:01.410 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9003.conf
63:C 15 May 2024 23:06:05.113 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9004.conf
69:C 15 May 2024 23:06:08.689 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9005.conf
81:C 15 May 2024 23:06:13.801 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root        27    14  0 23:02 ?        00:00:00 redis-server *:9006 [cluster]
root        46    14  0 23:05 ?        00:00:00 redis-server *:9000 [cluster]
root        52    14  0 23:05 ?        00:00:00 redis-server *:9001 [cluster]
root        58    14  0 23:06 ?        00:00:00 redis-server *:9002 [cluster]
root        64    14  0 23:06 ?        00:00:00 redis-server *:9003 [cluster]
root        70    14  0 23:06 ?        00:00:00 redis-server *:9004 [cluster]
root        82    14  0 23:06 ?        00:00:00 redis-server *:9005 [cluster]
root        91    20  0 23:06 pts/1    00:00:00 grep redis
# 经验证，此时9000-9005集群状态正常

root@DESKTOP-9MBCA87:/etc/redis# redis-cli --cluster help
Cluster Manager Commands:
  create         host1:port1 ... hostN:portN
                 --cluster-replicas <arg>
  check          <host:port> or <host> <port> - separated by either colon or space
                 --cluster-search-multiple-owners
  info           <host:port> or <host> <port> - separated by either colon or space
  fix            <host:port> or <host> <port> - separated by either colon or space
                 --cluster-search-multiple-owners
                 --cluster-fix-with-unreachable-masters
  reshard        <host:port> or <host> <port> - separated by either colon or space
                 --cluster-from <arg>
                 --cluster-to <arg>
                 --cluster-slots <arg>
                 --cluster-yes
                 --cluster-timeout <arg>
                 --cluster-pipeline <arg>
                 --cluster-replace
  rebalance      <host:port> or <host> <port> - separated by either colon or space
                 --cluster-weight <node1=w1...nodeN=wN>
                 --cluster-use-empty-masters
                 --cluster-timeout <arg>
                 --cluster-simulate
                 --cluster-pipeline <arg>
                 --cluster-threshold <arg>
                 --cluster-replace
  add-node       new_host:new_port existing_host:existing_port
                 --cluster-slave
                 --cluster-master-id <arg>
  del-node       host:port node_id
  call           host:port command arg arg .. arg
                 --cluster-only-masters
                 --cluster-only-replicas
  set-timeout    host:port milliseconds
  import         host:port
                 --cluster-from <arg>
                 --cluster-from-user <arg>
                 --cluster-from-pass <arg>
                 --cluster-from-askpass
                 --cluster-copy
                 --cluster-replace
  backup         host:port backup_directory
  help

For check, fix, reshard, del-node, set-timeout, info, rebalance, call, import, backup you can specify the host and port of any working node in the cluster.

Cluster Manager Options:
  --cluster-yes  Automatic yes to cluster commands prompts

# 添加Node
root@DESKTOP-9MBCA87:/etc/redis# redis-cli --cluster add-node 127.0.0.1:9006 127.0.0.1:9000
>>> Adding node 127.0.0.1:9006 to cluster 127.0.0.1:9000
>>> Performing Cluster Check (using node 127.0.0.1:9000)
M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003
   slots: (0 slots) slave
   replicates ca650cf3796e78fa346b96d1b8fef040a570e1ed
M: 34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004
   slots: (0 slots) slave
   replicates 8aeb37884db4ee8568c7fc3cbfef6be14003581f
M: 8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005
   slots: (0 slots) slave
   replicates 34c1ea22a04c30d7e28223d0a21716a2325ce6af
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Getting functions from cluster
>>> Send FUNCTION LIST to 127.0.0.1:9006 to verify there is no functions in it
>>> Send FUNCTION RESTORE to 127.0.0.1:9006
>>> Send CLUSTER MEET to node 127.0.0.1:9006 to make it join the cluster.
[OK] New node added correctly.

root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9000

127.0.0.1:9000> CLUSTER INFO
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:7
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:1
cluster_stats_messages_ping_sent:501
cluster_stats_messages_pong_sent:507
cluster_stats_messages_sent:1008
cluster_stats_messages_ping_received:506
cluster_stats_messages_pong_received:497
cluster_stats_messages_meet_received:1
cluster_stats_messages_received:1004
total_cluster_links_buffer_limit_exceeded:0

127.0.0.1:9000> CLUSTER NODES
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 myself,master - 0 1715786054000 1 connected 0-5460
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715786055123 1 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715786057000 3 connected 10923-16383
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715786057129 2 connected
e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006@19006 master - 0 1715786055000 0 connected # master
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 master - 0 1715786058132 2 connected 5461-10922
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715786056125 3 connected

127.0.0.1:9000> exit

# 集群重新分片
root@DESKTOP-9MBCA87:/etc/redis# redis-cli --cluster reshard 127.0.0.1 9000
>>> Performing Cluster Check (using node 127.0.0.1:9000)
M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003
   slots: (0 slots) slave
   replicates ca650cf3796e78fa346b96d1b8fef040a570e1ed
M: 34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004
   slots: (0 slots) slave
   replicates 8aeb37884db4ee8568c7fc3cbfef6be14003581f
M: e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006
   slots: (0 slots) master
M: 8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005
   slots: (0 slots) slave
   replicates 34c1ea22a04c30d7e28223d0a21716a2325ce6af
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
How many slots do you want to move (from 1 to 16384)? 2000
What is the receiving node ID? e57e1427b7045d8469c8fafcca7540c656b8cdc3
Please enter all the source node IDs.
  Type 'all' to use all the nodes as source nodes for the hash slots.
  Type 'done' once you entered all the source nodes IDs.
Source node #1: ca650cf3796e78fa346b96d1b8fef040a570e1ed
Source node #2: done

Ready to move 2000 slots.
  Source nodes:
    M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
       slots:[0-5460] (5461 slots) master
       1 additional replica(s)
  Destination node:
    M: e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006
       slots: (0 slots) master
  Resharding plan:
    Moving slot 0 from ca650cf3796e78fa346b96d1b8fef040a570e1ed
    ...
    Moving slot 1999 from ca650cf3796e78fa346b96d1b8fef040a570e1ed
Do you want to proceed with the proposed reshard plan (yes/no)? yes
    Moving slot 0 from 127.0.0.1:9000 to 127.0.0.1:9006:
    ...
    Moving slot 1999 from 127.0.0.1:9000 to 127.0.0.1:9006:

# 验证
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9000

127.0.0.1:9000> CLUSTER NODES
# redis-cli -p 9000 cluster nodes
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 myself,master - 0 1715786324000 1 connected 2000-5460
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715786323000 1 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715786323908 3 connected 10923-16383
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715786324910 2 connected
e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006@19006 master - 0 1715786323000 7 connected 0-1999
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 master - 0 1715786324000 2 connected 5461-10922
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715786325913 3 connected

127.0.0.1:9000> exit
```

#### 删除集群中Node
```bash
# 集群重新分片
root@DESKTOP-9MBCA87:/etc/redis# redis-cli --cluster reshard 127.0.0.1 9000
>>> Performing Cluster Check (using node 127.0.0.1:9000)
M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
   slots:[2000-5460] (3461 slots) master
   1 additional replica(s)
S: 44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003
   slots: (0 slots) slave
   replicates ca650cf3796e78fa346b96d1b8fef040a570e1ed
M: 34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004
   slots: (0 slots) slave
   replicates 8aeb37884db4ee8568c7fc3cbfef6be14003581f
M: e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006
   slots:[0-1999] (2000 slots) master
M: 8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: 8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005
   slots: (0 slots) slave
   replicates 34c1ea22a04c30d7e28223d0a21716a2325ce6af
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
How many slots do you want to move (from 1 to 16384)? 2000
What is the receiving node ID? ca650cf3796e78fa346b96d1b8fef040a570e1ed
Please enter all the source node IDs.
  Type 'all' to use all the nodes as source nodes for the hash slots.
  Type 'done' once you entered all the source nodes IDs.
Source node #1: e57e1427b7045d8469c8fafcca7540c656b8cdc3
Source node #2: done

Ready to move 2000 slots.
  Source nodes:
    M: e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006
       slots:[0-1999] (2000 slots) master
  Destination node:
    M: ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000
       slots:[2000-5460] (3461 slots) master
       1 additional replica(s)
  Resharding plan:
    Moving slot 0 from e57e1427b7045d8469c8fafcca7540c656b8cdc3
    ...
    Moving slot 1 from e57e1427b7045d8469c8fafcca7540c656b8cdc3
Do you want to proceed with the proposed reshard plan (yes/no)? yes
Moving slot 0 from 127.0.0.1:9006 to 127.0.0.1:9000:
...
Moving slot 1999 from 127.0.0.1:9006 to 127.0.0.1:9000:

root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9000

127.0.0.1:9000> CLUSTER NODES
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 myself,master - 0 1715786708000 8 connected 0-5460
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715786713079 8 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715786714082 3 connected 10923-16383
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715786713000 2 connected
e57e1427b7045d8469c8fafcca7540c656b8cdc3 127.0.0.1:9006@19006 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715786714000 8 connected # slave
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 master - 0 1715786715085 2 connected 5461-10922
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715786713000 3 connected

127.0.0.1:9000> exit

# 删除Node
root@DESKTOP-9MBCA87:/etc/redis# redis-cli --cluster del-node 127.0.0.1:9006@19006 e57e1427b7045d8469c8fafcca7540c656b8cdc3
>>> Removing node e57e1427b7045d8469c8fafcca7540c656b8cdc3 from cluster 127.0.0.1:9006
>>> Sending CLUSTER FORGET messages to the cluster...
>>> Sending CLUSTER RESET SOFT to the deleted node.

# 验证
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9000

127.0.0.1:9000> CLUSTER NODES
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 myself,master - 0 1715786893000 8 connected 0-5460
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715786893643 8 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715786894000 3 connected 10923-16383
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715786893000 2 connected
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 master - 0 1715786892000 2 connected 5461-10922
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715786894645 3 connected

127.0.0.1:9000> exit
```

#### 集群故障恢复
```bash
root@DESKTOP-9MBCA87:/etc/redis# ps -ef | grep redis
root        27    14  0 23:02 ?        00:00:02 redis-server *:9006 [cluster]
root        46    14  0 23:05 ?        00:00:02 redis-server *:9000 [cluster]
root        52    14  0 23:05 ?        00:00:01 redis-server *:9001 [cluster]
root        58    14  0 23:06 ?        00:00:02 redis-server *:9002 [cluster]
root        64    14  0 23:06 ?        00:00:01 redis-server *:9003 [cluster]
root        70    14  0 23:06 ?        00:00:01 redis-server *:9004 [cluster]
root        82    14  0 23:06 ?        00:00:01 redis-server *:9005 [cluster]
root       108    20  0 23:29 pts/1    00:00:00 grep redis

root@DESKTOP-9MBCA87:/etc/redis# kill 27 # 9006

root@DESKTOP-9MBCA87:/etc/redis# kill 46 # 9000

root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9001

127.0.0.1:9001> CLUSTER NODES
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715787130987 3 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715787133996 3 connected 10923-16383
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 master - 1715787124969 1715787121000 8 disconnected 0-5460 # master
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 myself,master - 0 1715787132000 2 connected 5461-10922
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715787132993 2 connected
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715787132000 8 connected # slave

127.0.0.1:9001> CLUSTER NODES
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715787140014 3 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715787138008 3 connected 10923-16383
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 master,fail? - 1715787124969 1715787121000 8 disconnected 0-5460 # fail?
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 myself,master - 0 1715787139000 2 connected 5461-10922
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715787138000 2 connected
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715787139011 8 connected # slave

127.0.0.1:9001> CLUSTER NODES
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715787254375 3 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715787255378 3 connected 10923-16383
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 master,fail - 1715787124969 1715787121000 8 disconnected # fail
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 myself,master - 0 1715787253000 2 connected 5461-10922
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715787256381 2 connected
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 master - 0 1715787255000 9 connected 0-5460 # master

127.0.0.1:9001> exit

# 重新启动9000
root@DESKTOP-9MBCA87:/etc/redis# redis-server redis_9000.conf
111:C 15 May 2024 23:39:09.001 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode

root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9001
127.0.0.1:9001> CLUSTER NODES
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715787565000 3 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715787564301 3 connected 10923-16383
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 slave 44117b0656484f9f847a7bdd33201ee9fcfeacdb 0 1715787565000 9 connected # slave
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 myself,master - 0 1715787564000 2 connected 5461-10922
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715787565304 2 connected
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 master - 0 1715787566307 9 connected 0-5460 # master

127.0.0.1:9001> exit
root@DESKTOP-9MBCA87:/etc/redis# redis-cli -c -p 9000

# 手动主从切换：可进入从节点使用CLUSTER FAILOVER命令进行切换
127.0.0.1:9000> CLUSTER FAILOVER
OK

127.0.0.1:9000> CLUSTER NODES
8aeb37884db4ee8568c7fc3cbfef6be14003581f 127.0.0.1:9001@19001 master - 0 1715787675279 2 connected 5461-10922
44117b0656484f9f847a7bdd33201ee9fcfeacdb 127.0.0.1:9003@19003 slave ca650cf3796e78fa346b96d1b8fef040a570e1ed 0 1715787675000 10 connected # slave
8faa96c289095cdc0853a3581352f781b5350a7d 127.0.0.1:9005@19005 slave 34c1ea22a04c30d7e28223d0a21716a2325ce6af 0 1715787676282 3 connected
34c1ea22a04c30d7e28223d0a21716a2325ce6af 127.0.0.1:9002@19002 master - 0 1715787677285 3 connected 10923-16383
03a84f1035f268f74074ae8cc3f939fa3f8ef2bd 127.0.0.1:9004@19004 slave 8aeb37884db4ee8568c7fc3cbfef6be14003581f 0 1715787675000 2 connected
ca650cf3796e78fa346b96d1b8fef040a570e1ed 127.0.0.1:9000@19000 myself,master - 0 1715787673000 10 connected 0-5460 # master
```

### Redis与MySQL

#### Redis与MySQL基本概念

* **Redis**：
  - 类型：Redis是一个开源的、使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。
  - 特点：Redis是一个高性能的键值对数据库，它基于内存运行，并支持数据持久化。Redis的读写速度非常快，且支持丰富的数据类型，如字符串、哈希、列表、集合、有序集合等。

* **MySQL**：
  - 类型：MySQL是一个关系型数据库管理系统（RDBMS），使用SQL语言进行数据库管理。
  - 特点：MySQL将数据保存在磁盘中，具有较高的可靠性和稳定性。它支持复杂的数据查询和链接操作，适用于存储结构化数据。

#### Redis与MySQL主要区别

1. **数据存储方式**：
   - Redis：基于内存，数据存储在内存中，读写速度极快，但内存空间有限。
   - MySQL：基于磁盘，数据存储在硬盘上，读写速度相对较慢，但不受空间容量限制。

2. **数据结构**：
   - Redis：支持多种数据结构，如字符串、哈希、列表、集合、有序集合等，可以满足不同类型的数据存储需求。
   - MySQL：使用表格的形式组织数据，每个表包含多个行和列，支持复杂的数据查询和链接操作。

3. **性能**：
   - Redis：读写速度非常快，适用于需要高速数据处理的场景。
   - MySQL：在处理大量数据查询时较为高效，但在写入和更新操作时相对较慢。

4. **持久化**：
   - Redis：提供了RDB和AOF两种持久化方式，可以将数据存储在硬盘上，以便在重启后恢复。
   - MySQL：数据默认存储在磁盘上，可以通过备份和恢复方式保证数据的安全。

5. **事务支持**：
   - Redis：支持简单的事务机制，但不支持回滚点等高级特性。
   - MySQL：支持ACID事务，具有原子性、一致性、隔离性和持久性，支持回滚点和部分回滚。

6. **应用场景**：
   - Redis：常用于缓存、消息队列、计数器、分布式锁、实时数据分析等场景。
   - MySQL：常用于Web应用程序、企业应用程序、数据仓库和报告系统等场景，需要处理大量结构化数据。

#### Redis与MySQL结合使用

Redis和MySQL可以结合使用，以利用它们各自的优势。例如，可以使用Redis作为MySQL的缓存，减少对MySQL数据库的查询次数，提高应用程序的性能。同时，Redis还可以用于存储用户会话信息、排行榜和队列等数据，以减轻MySQL数据库的负担。在分布式系统中，Redis还可以实现分布式锁和消息队列等功能。

#### Redis与MySQL总结

Redis和MySQL是两种不同类型的数据库系统，它们各自具有独特的特性和使用场景。Redis基于内存运行，读写速度极快，适用于缓存、消息队列等场景；而MySQL则基于磁盘运行，具有较高的可靠性和稳定性，适用于存储结构化数据。在实际应用中，可以根据具体需求选择适合的数据库系统，或者结合使用Redis和MySQL来构建更强大的数据管理解决方案。

# RabbitMQ

## RabbitMQ介绍

### MQ消息总线(Message Queue)
* 消息总线(Message Queue)，是一种跨进程、异步的通信机制，用于上下游传递消息。由消息系统来确保消息的可靠传递。

### RabbitMQ简介
* RabbitMQ是一个Erlang开发的高级消息队列协议（Advanced Message Queuing Protocol）的开源实现。
* AMQP 是在 2006 年的 6 月，由 Cisco 、Red Hat、iMatix 等联合制定的公开标准。
* RabbitMQ由RabbitMQ科技有限公司开发并且提供商业支持的。该公司在2010年4月被SpringSource收购。在2013年5月被并入Pivotal。

### RabbitMQ使用场景
* 对于一个大型的软件系统来说，它会有很多的组件或者说模块，又或者说子系统。
* 那么不同的模块可以部署到不同的机器上，那这些模块又如何通信？会有很多问题需要解决。如：
  * 信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据的丢失问题？
  * 如何降低发送者和接收者的耦合度？
  * 如何做到可扩展？
  * 如何保证接收者接收到了完整，正确的数据？…​
* AMQP协议解决了以上的问题，而RabbitMQ实现了AMQP。

### 常见几种MQ的比较

#### ActiveMQ：
* 单机吞吐量万级，时效性毫秒ms级，可用性高，基于主从架构实现高可用性，较低的概率丢失数据
* 官方社区现在对 ActiveMQ 的维护越来越少，高吞吐量场景较少使用。

#### RocketMQ：
* 单机吞吐量十万级，可用性非常高。分布式架构，消息可以做到0丢失。MQ 功能较为完善，而且分布式结构扩展性好。支持 10 亿级别的消息堆积，不会因为堆积导致性能下降。
* 支持的客户端语言不多。社区活跃度一般。

#### RabbitMQ：
* 由于 Erlang 语言的高并发特性，性能较好。吞吐量万级，MQ 功能比较备，健壮、稳定、易用、跨平台、支持多种语言。
* 社区活跃度高，更新频率高。

#### Kafka：
* 单机吞吐量约百万条/秒。时效性毫秒ms级，分布式架构，在日志领域比较成熟。支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用
* 消息消费失败不支持重试。支持消息顺序， 但是一台代理宕机后，就会产生消息乱序。

#### 总结：
* RocketMQ适用于金融互联网领域对于可靠性要求很高的场景，比如电商里面的订单扣款。
* RabbitMQ结合 Erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度高，管理界面方便，中小型公司优先选择功能比较完备的 RabbitMQ。
* Kafka适用于大数据，如有日志采集需求，首选Kafka。

### RabbitMQ安装

#### RabbitMQ Linux Debian安装
```bash
# 安装一些必需的依赖项
root@DESKTOP-9MBCA87:/home/toubun# sudo apt-get install software-properties-common curl gnupg2 apt-transport-https -y
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
software-properties-common is already the newest version (0.99.30-4).
curl is already the newest version (7.88.1-10+deb12u5).
gnupg2 is already the newest version (2.2.40-1.1).
apt-transport-https is already the newest version (2.6.1).
The following packages were automatically installed and are no longer required:
  initscripts insserv orphan-sysvinit-scripts startpar sysv-rc ucf
Use 'sudo apt autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.
```
```bash
# 自动添加存储库(Debian环境)
root@DESKTOP-9MBCA87:/home/toubun# curl -1sLf 'https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-erlang/setup.deb.sh' | sudo -E bash
Executing the  setup script for the 'rabbitmq/rabbitmq-erlang' repository ...

   OK: Checking for required executable 'curl' ...
   OK: Checking for required executable 'apt-get' ...
   OK: Detecting your OS distribution and release using system methods ...
 ^^^^: ... Detected/provided for your OS/distribution, version and architecture:
 >>>>:
 >>>>: ... distro=debian  version=12  codename=bookworm  arch=x86_64
 >>>>:
   OK: Checking for apt dependency 'apt-transport-https' ...
   OK: Checking for apt dependency 'ca-certificates' ...
   OK: Checking for apt dependency 'gnupg' ...
   OK: Checking for apt signed-by key support ...
   OK: Importing 'rabbitmq/rabbitmq-erlang' repository GPG keys ...
   OK: Checking if upstream install config is OK ...
   OK: Installing 'rabbitmq/rabbitmq-erlang' repository via apt ...
   OK: Updating apt repository metadata cache ...
   OK: The repository has been installed successfully - You're ready to rock!
```
```bash
# 执行安装Erlang与RabbitMQ
root@DESKTOP-9MBCA87:/home/toubun# apt-get update
...
Fetched 298 kB in 38s (7824 B/s)
Reading package lists... Done
```
```bash
root@DESKTOP-9MBCA87:/home/toubun# apt-get install erlang erlang-nox
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
curl is already the newest version (7.88.1-10+deb12u5).
The following packages were automatically installed and are no longer required:
  initscripts insserv orphan-sysvinit-scripts startpar sysv-rc ucf
Use 'sudo apt autoremove' to remove them.
...
0 upgraded, 63 newly installed, 2 to remove and 15 not upgraded.
Need to get 27.5 MB of archives.
After this operation, 118 MB of additional disk space will be used.
...
Processing triggers for libc-bin (2.36-9+deb12u4) ...
ldconfig: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link
Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.10+dfsg-1+b1) ...
```
```bash
root@DESKTOP-9MBCA87:/home/toubun# apt-get install rabbitmq-server -y
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
...
0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.
Need to get 15.4 MB of archives.
After this operation, 25.0 MB of additional disk space will be used.
...
Adding system user `rabbitmq' (UID 103) ...
Adding new user `rabbitmq' (UID 103) with group `rabbitmq' ...
Not creating home directory `/var/lib/rabbitmq'.
Created symlink /etc/systemd/system/multi-user.target.wants/rabbitmq-server.service -> /lib/systemd/system/rabbitmq-server.service.
invoke-rc.d: could not determine current runlevel
Processing triggers for libc-bin (2.36-9+deb12u4) ...
ldconfig: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link
```
```bash
# 启动RabbitMQ与验证
root@DESKTOP-9MBCA87:/home/toubun# erl -v
Erlang/OTP 26 [erts-14.2.5] [source] [64-bit] [smp:12:12] [ds:12:12:10] [async-threads:1] [jit:ns]
Eshell V14.2.5 (press Ctrl+G to abort, type help(). for help)
1> # Ctrl+C Ctrl+C
BREAK: (a)bort (A)bort with dump (c)ontinue (p)roc info (i)nfo
       (l)oaded (v)ersion (k)ill (D)b-tables (d)istribution
```
```bash
# 启动RabbitMQ与验证【问题22.8】
root@DESKTOP-9MBCA87:/home/toubun# systemctl start rabbitmq-server
System has not been booted with systemd as init system (PID 1). Can't operate.
Failed to connect to bus: Host is down
```
```bash
# 启动RabbitMQ与验证【问题22.8】
root@DESKTOP-9MBCA87:/home/toubun# systemctl status rabbitmq-server
System has not been booted with systemd as init system (PID 1). Can't operate.
Failed to connect to bus: Host is down
```
```bash
# 手动方式启动RabbitMQ【问题22.8】
root@DESKTOP-9MBCA87:/home/toubun# /usr/sbin/rabbitmq-server start
2024-05-17 20:04:21.568252+08:00 [info] <0.228.0> Feature flags: list of feature flags found:
2024-05-17 20:04:21.578855+08:00 [info] <0.228.0> Feature flags:   [ ] classic_mirrored_queue_version
2024-05-17 20:04:21.578933+08:00 [info] <0.228.0> Feature flags:   [ ] implicit_default_bindings
2024-05-17 20:04:21.578995+08:00 [info] <0.228.0> Feature flags:   [ ] maintenance_mode_status
2024-05-17 20:04:21.579011+08:00 [info] <0.228.0> Feature flags:   [ ] quorum_queue
2024-05-17 20:04:21.579042+08:00 [info] <0.228.0> Feature flags:   [ ] stream_queue
2024-05-17 20:04:21.579060+08:00 [info] <0.228.0> Feature flags:   [ ] user_limits
2024-05-17 20:04:21.579097+08:00 [info] <0.228.0> Feature flags:   [ ] virtual_host_metadata
2024-05-17 20:04:21.579125+08:00 [info] <0.228.0> Feature flags: feature flag states written to disk: yes
2024-05-17 20:04:21.818128+08:00 [notice] <0.44.0> Application syslog exited with reason: stopped
2024-05-17 20:04:21.818220+08:00 [notice] <0.228.0> Logging: switching to configured handler(s); following messages may not be visible in this log output

  ##  ##      RabbitMQ 3.10.8
  ##  ##
  ##########  Copyright (c) 2007-2022 VMware, Inc. or its affiliates.
  ######  ##
  ##########  Licensed under the MPL 2.0. Website: https://rabbitmq.com

  Erlang:      26.2.5 [jit]
  TLS Library: OpenSSL - OpenSSL 3.0.11 19 Sep 2023
  Release series support status: supported

  Doc guides:  https://rabbitmq.com/documentation.html
  Support:     https://rabbitmq.com/contact.html
  Tutorials:   https://rabbitmq.com/getstarted.html
  Monitoring:  https://rabbitmq.com/monitoring.html

  Logs: /var/log/rabbitmq/rabbit@DESKTOP-9MBCA87.log
        /var/log/rabbitmq/rabbit@DESKTOP-9MBCA87_upgrade.log
        <stdout>

  Config file(s): (none)

  Starting broker... completed with 0 plugins.
```
```bash
# 创建 RabbitMQ 管理员帐户
root@DESKTOP-9MBCA87:/home/toubun# rabbitmqctl add_user admin admin
Adding user "admin" ...
Done. Don't forget to grant the user permissions to some virtual hosts! See 'rabbitmqctl help set_permissions' to learn more.
```
```bash
# 在管理员帐户上设置管理员Tag
root@DESKTOP-9MBCA87:/home/toubun# rabbitmqctl set_user_tags admin administrator
Setting tags for user "admin" to [administrator] ...
```
```bash
# 在管理员帐户上设置所需的权限
root@DESKTOP-9MBCA87:/home/toubun# rabbitmqctl set_permissions -p / admin ".*" ".*" ".*"
Setting permissions for user "admin" in vhost "/" ...
```
```bash
# 列出所有权限
root@DESKTOP-9MBCA87:/home/toubun# rabbitmqctl list_permissions -p /
Listing permissions for vhost "/" ...
user    configure       write   read
guest   .*      .*      .*
admin   .*      .*      .*
```
```bash
# 开启 RabbitMQ 管理仪表板
root@DESKTOP-9MBCA87:/home/toubun# rabbitmq-plugins enable rabbitmq_management
Enabling plugins on node rabbit@DESKTOP-9MBCA87:
rabbitmq_management
The following plugins have been configured:
  rabbitmq_management
  rabbitmq_management_agent
  rabbitmq_web_dispatch
Applying plugin configuration to rabbit@DESKTOP-9MBCA87...
The following plugins have been enabled:
  rabbitmq_management
  rabbitmq_management_agent
  rabbitmq_web_dispatch

started 3 plugins.
```
```bash
# RabbitMQ 管理仪表板默认端口15672进行检查
root@DESKTOP-9MBCA87:/home/toubun# ss -tunelp | grep 15672
tcp   LISTEN 0      1024         0.0.0.0:15672      0.0.0.0:*    users:(("beam.smp",pid=1091,fd=36)) uid:103 ino:28883 sk:5 cgroup:/ <->
# http://127.0.0.1:15672/
# Username: admin
# Password: admin
```
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240517235558.png)
```bash
# bash: wget: command not found
sudo apt update
sudo apt install wget
```
```bash
# 下载 RabbitMQ 提供的 rabbitmqadmin
root@DESKTOP-9MBCA87:/home/toubun# wget http://127.0.0.1:15672/cli/rabbitmqadmin
--2024-05-18 00:04:45--  http://127.0.0.1:15672/cli/rabbitmqadmin
Connecting to 127.0.0.1:15672... connected.
HTTP request sent, awaiting response... 200 OK
Length: 42416 (41K) [application/octet-stream]
Saving to: 'rabbitmqadmin'

rabbitmqadmin                100%[==============================================>]  41.42K  --.-KB/s    in 0.001s

2024-05-18 00:04:45 (67.2 MB/s) - 'rabbitmqadmin' saved [42416/42416]
```
```bash
# 复制到系统位置
root@DESKTOP-9MBCA87:/home/toubun# ls
dump.rdb  rabbitmqadmin

root@DESKTOP-9MBCA87:/home/toubun# mv rabbitmqadmin /usr/bin/
```
```bash
# 设置权限
root@DESKTOP-9MBCA87:/home/toubun# chmod 775 /usr/bin/rabbitmqadmin
```
```bash
# 验证 rabbitmqadmin
root@DESKTOP-9MBCA87:/home/toubun# rabbitmqadmin --version
rabbitmqadmin 3.10.8
```
```bash
# RabbitMQ 配置备份
root@DESKTOP-9MBCA87:/home/toubun# rabbitmqadmin export rabbitmq-backup-config.json
Exported definitions for localhost to "rabbitmq-backup-config.json"

root@DESKTOP-9MBCA87:/home/toubun# ls
dump.rdb  rabbitmq-backup-config.json
```
```bash
# RabbitMQ 备份恢复
root@DESKTOP-9MBCA87:/home/toubun# cat rabbitmq-backup-config.json
{"rabbit_version":"3.10.8","rabbitmq_version":"3.10.8","product_name":"RabbitMQ","product_version":"3.10.8","users":[{"name":"admin","password_hash":"z6ee5hlHzOf4op2CaMpoMMy7rdAZ7xIQjUHpEz0ePXcF7MbG","hashing_algorithm":"rabbit_password_hashing_sha256","tags":["administrator"],"limits":{}},{"name":"guest","password_hash":"N5bvdJUyMqLc6ha/TpXWeBzzgOv4aR8sKnyIBj6mH8lvNqP2","hashing_algorithm":"rabbit_password_hashing_sha256","tags":["administrator"],"limits":{}}],"vhosts":[{"name":"/"}],"permissions":[{"user":"guest","vhost":"/","configure":".*","write":".*","read":".*"},{"user":"admin","vhost":"/","configure":".*","write":".*","read":".*"}],"topic_permissions":[],"parameters":[],"global_parameters":[{"name":"internal_cluster_id","value":"rabbitmq-cluster-id-OB0QC4LHcunGsaFfKQHWBw"}],"policies":[],"queues":[],"exchanges":[],"bindings":[]}
```

#### RabbitMQ Docker安装
```bash
C:\Windows\System32>docker run -it --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.13.2-management
Unable to find image 'rabbitmq:3.13.2-management' locally
3.13.2-management: Pulling from library/rabbitmq
a8b1c5f80c2d: Pull complete
4dedb6d843e5: Pull complete
5c1196c9f92f: Pull complete
89aa66202de9: Pull complete
7482e2b5f1fd: Pull complete
cae0f9147f71: Pull complete
5e8608f82ef5: Pull complete
76a071de98b9: Pull complete
140f907150d0: Pull complete
53c7a9878ba6: Pull complete
Digest: sha256:eee9afbc17c32424ba6309dfd2d9efc9b9b1863ffe231b3d2be2815758b0d649
Status: Downloaded newer image for rabbitmq:3.13.2-management
...

  ##  ##      RabbitMQ 3.13.2
  ##  ##
  ##########  Copyright (c) 2007-2024 Broadcom Inc and/or its subsidiaries
  ######  ##
  ##########  Licensed under the MPL 2.0. Website: https://rabbitmq.com

  Erlang:      26.2.5 [jit]
  TLS Library: OpenSSL - OpenSSL 3.1.5 30 Jan 2024
  Release series support status: supported

  Doc guides:  https://www.rabbitmq.com/docs
  Support:     https://www.rabbitmq.com/docs/contact
  Tutorials:   https://www.rabbitmq.com/tutorials
  Monitoring:  https://www.rabbitmq.com/docs/monitoring
  Upgrading:   https://www.rabbitmq.com/docs/upgrade

  Logs: <stdout>

  Config file(s): /etc/rabbitmq/conf.d/10-defaults.conf

  Starting broker...2024-05-16 15:37:44.527576+00:00 [info] <0.254.0>
```
```bash
localhost:15672
Username: guest
Password: guest
```
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240516234358.png)

#### RabbitMQ Docker yaml安装
```yml
version: "3.8"

services:
  queue:
    image: rabbitmq:3.13.2-management
    container_name: rabbitmq-yaml
    ports:
      - '5672:5672'
      - '15672:15672'
```
```bash
G:\NiHon-IT-Training-Plan\RabbitMQ>docker-compose -f .\docker-compose.yaml up -d
[+] Running 1/0
[+] Running 1/1abbitmq-yaml  Created                                                                                0.0s
 ✔ Container rabbitmq-yaml  Created                                                                                0.0s
Error response from daemon: driver failed programming external connectivity on endpoint rabbitmq-yaml (33f9cbc54615ed299b57011db6269d770ce247fb7df25684923b646e3afa1d9e): Bind for 0.0.0.0:15672 failed: port is already allocated
```
* 此处安装失败应该是因为15672端口先前docker方式安装的RabbitMQ还正在运行，就不再重复安装了

## RabbitMQ概念定义

### RabbitMQ Server
* 也叫Broker Server，是一种传输服务。它的任务是维护一条从Producer(生产者)到Consumer(消费者)的路线，保证数据能够按照指定的方式进行传输。
* 简单说就是消息队列服务器实体。
* 虽然这个保证不是100%的保证，但是对于普通的应用来说已经足够了。
* 当然对于商业系统来说，可以再做一层数据一致性的guard，彻底保证系统的一致性。

### Producer(生产者)
* 数据发送方。
* 一个Message有两个部分：payload(有效载荷)和label(标签)
* payload是传输的数据。label是exchange的名字或者说是一个tag，它描述了payload。
* 而且RabbitMQ也是通过这个label来决定把这个Message发给哪个Consumer(消费者)。
* AMQP仅仅描述了label，而RabbitMQ决定了如何使用这个label的规则。

### Consumer(消费者)
* 数据接收方。
* 可以把queue比作一个邮箱。当有Message到达某个邮箱后，RabbitMQ把它发送给它的某个消费者即Consumer。
* 当然可能会把同一个Message发送给很多的Consumer。
* 对于消费者来说，它是不知道谁发送的这个信息的。
* 当然如果Message本身包含了生产者的信息就另当别论了。

### Connection(连接)
* 一个TCP连接。Producer和Consumer都通过TCP连接到RabbitMQ Server。

### Channel(通道)
* 虚拟连接。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。
* 也就是说，一般情况是程序起始建立TCP连接，第二步就是建立Channel。
* 在客户端的每个连接里，可建立多个Channel，每个Channel代表一个会话任务。

### Queue
* 消息队列，每个消息都会被投入到一个或多个队列。

### Exchange(消息交换机)
* 指定消息按什么规则，路由到哪个队列。

### Routing Key
* 路由关键字，Exchange根据这个关键字进行消息投递。

### Binding
* 绑定，它的作用就是把Exchange和Queue按照路由规则绑定起来。

### VHost
* 虚拟主机，一个Broker里可以开设多个VHost，用作不同用户的权限分离。
* `http://localhost:15672/#/users/guest - Admin - Users / Virtual Hosts`

## RabbitMQ简单队列

### Hello World简单队列
* 最简单的队列模式，一个消息生产者来发送消息、一个消息消费者来消费消息。
* 先进先出，公平调度。

#### `Run 'HelloProducer.main()'`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521001319.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521001458.png)
* 点击`http://localhost:15672/#/queues`中的`HelloWorldQueue`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521002224.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521002254.png)
* 运行`HelloConsumer.main()`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521002405.png)
* 关闭终端中正在运行的`HelloProducer.main()`和`HelloConsumer.main()`后，将
```java
channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -> {});
```
修改为
```java
channel.basicConsume(QUEUE_NAME, false, deliverCallback, consumerTag -> {});
```
随后重新分别运行一次`HelloProducer.main()`和`HelloConsumer.main()`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521002952.png)
发现终端中可以得到消息`Hello World`，但队列中并未被签收，注意`Unacked`状态
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240521003146.png)

## RabbitMQ工作队列

### Work Queues工作队列
* 在前面的Hello World简单队列模式，因其公平调度机制，如有多个消费者，其中一个消费者的速度较慢，将会拖累整个队列消息处理速度。
* 在Work Queues工作队列模式中，可以为速度快的消费者提供更多消息，从而提高任务处理速度。
* 不需要设置交换机，需要指定唯一的消息队列来进行消息传递，可以有多个消费者。
* 消费者必须要等消费完一条消息后才可以准备接收下一条消息。
* 操作方式:关闭自动应答即可，进行手动应答。

## RabbitMQ发布订阅

### Publish/Subscribe发布订阅模式
* 消息生产者把消息发送给Broker Server,然后Broker Server中的交换机把消息转发到绑定此交换机的每个队列，每个绑定交换机的队列将接收到来自交换机消息。
* 根据交换机的具体定义,发布订阅模式可实现一条消息同时被多个消费者消费。

### 交换机类型
* Direct:直连，routingKey与交换机绑定，相同的routingKey会获得相同的消息。
* Fanout:扇出，与routingKey无关，将消息交给所有绑定到交换机的队列。
* Topic:主题，队列通过消息主题与交换机绑定，把消息交给符合routing pattern(路由模式)的队列。
* Headers:头，与routingKey无关，匹配消息头中的属性信息。

### Run `_03_PubSubQueue`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240523222127.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240523222238.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240523222315.png)

## RabbitMQ路由模式

### Routing路由模式
* 路由模式和发布订阅模式类似，只是在发布订阅模式的基础上改变了交换机的类型(fanout ⇒ direct)。
* 路由模式下，交换机根据routingKey进行完全匹配。如果匹配上则消费者收到消息。

### Run `_04_Routing`

#### `_04_Routing/RoutingProducer.java`
```java
channel.basicPublish(EXCHANGE_NAME, "orange", null, message.getBytes(StandardCharsets.UTF_8));
```

#### `_04_Routing/RoutingConsumer.java`
```java
channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,"orange");
```
由于路由对应正确，`RoutingConsumer`将接收到`RoutingProducer`的所有消息
* 随后尝试修改该路由名称
```java
channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,"orang");
```
发现依然能接收到所有消息
* 在`http://localhost:15672/#/queues/%2F/RoutingQueue`中查看
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240524212441.png)
发现原先的路由也还在绑定状态，`Unbind`后重试运行（甚至可能需要重启Docker中的RabbitMQ，见**【问题23.5】**），不再能收到消息

## RabbitMQ主题模式

### Topics主题模式
* 主题模式和路由模式类似，只是在路由模式的基础上改变了交换机的类型(direct ⇒ topic)。
* 主题模式下，生产者向交换机发送消息后，消费者可以使用匹配字符进行匹配。
* 提供两种匹配字符， `*` 和 `#` ，`*` 匹配单层级，`#` 可匹配多层级或无层级。

### Run `_05_Topic`

#### `_05_Topic/TopicConsumer.java`
```java
channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,"orange.*");
```

#### `_05_Topic/TopicConsumer1.java`
```java
channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,"orange.#");
```

#### `_05_Topic/TopicProducer.java`
```java
channel.basicPublish(EXCHANGE_NAME, "orange.to", null, message.getBytes(StandardCharsets.UTF_8));
```
此时`TopicConsumer`和`TopicConsumer1`均可收到全部消息
```java
channel.basicPublish(EXCHANGE_NAME, "orange.to.black", null, message.getBytes(StandardCharsets.UTF_8)); // 【问题23.5】
```
此时`TopicConsumer`不再能收到消息，而`TopicConsumer1`仍可收到全部消息（依旧需要注意**【问题23.5】**）

## RabbitMQ持久化

### 持久化
* RabbitMQ的持久化主要在三个方面，交换机持久化，队列持久化，消息持久化。

### 队列持久化
* 队列持久化：声明队列有一个参数durable，代表RabbitMQ服务器重启时，是否自动创建队列。
```java
/**
* 声明队列
* 参数1.queue:队列名称
* 参数2.durable:队列是否持久化，默认false存储在内存中
* 参数3.exclusive:是否排他.如果一个队列声明为排他队列，该队列对首次声明它的连接可见，并在连接断开时自动删除
* 参数4.autoDelete:是否自动删除 最后一个消费者断开连接以后 该队列是否自动删除
* 参数5.arguments:封装描述队列的其他信息
*/
channel.queueDeclare(QUEUE_NAME, true, false, false, null);
```

### 交换机持久化
* 交换机持久化：声明交换机有一个参数durable，代表RabbitMQ服务器重启时，是否自动创建交换机。
```java
/**
* 声明交换机
* 参数1.exchange:交换机名称
* 参数2.type:交换机类型
* 参数3.durable:交换机是否持久化
*/
channel.exchangeDeclare(EXCHANGE_NAME, "topic", true);
```

### 消息持久化
* 消息持久化：前提条件需要队列持久化。
* 消息持久化与之前的持久化操作有所不同，消息持久化在于创建消息的时候，需要添加一个持久化消息的属性。
* 发送消息时有参数：BasicProperties，里面可以封装消息的各种属性，如持久化，优先级等属性。
```java
String contentType 消息的内容类型
String contentEncoding 消息内容编码
Map<String, Object> headers 消息的header
Integer deliveryMode 持久化
Integer priority 优先级
String correlationId 关联ID
String replyTo 指定回复的队列的名称
String expiration 消息的失效时间
String messageId 消息ID
Date timestamp 消息时间戳
String type 类型
String userId 用户ID
String appId 应用程序ID
String clusterId 集群ID
```
* 持久化的key值为"deliveryMode"，当"deliveryMode"为1时表示消息不持久化，为2时表示消息持久化
```java
//BasicProperties构建器
AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();
//设置消息持久化属性，还可以设置其他BasicProperties属性等等
builder.deliveryMode(2).headers(xxx);
AMQP.BasicProperties properties = builder.build();
channel.basicPublish(EXCHANGE_NAME, "orange.to", properties, message.getBytes());
```

### 基于`_05_Topic`进行持久化测试

#### `_05_Topic/TopicConsumer.java`
* 首先重启Docker中的RabbitMQ，回到初始状态
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525005650.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525005739.png)
* 修改代码并运行
```java
// channel.exchangeDeclare(EXCHANGE_NAME,"topic"); // 主题模式
channel.exchangeDeclare(EXCHANGE_NAME,"topic", false); // 持久化测试false
```
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525005935.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525005829.png)
* 断开`_05_Topic/TopicConsumer.java`后再次重启Docker中的RabbitMQ
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525010149.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525010213.png)
* 对代码进行修改，开启持久化
```java
// channel.exchangeDeclare(EXCHANGE_NAME,"topic", false); // 持久化false
channel.exchangeDeclare(EXCHANGE_NAME,"topic", true); // 持久化true
// channel.queueDeclare(QUEUE_NAME,false,false,false,null);
channel.queueDeclare(QUEUE_NAME,true,false,false,null); // 持久化true
```
* 运行`_05_Topic/TopicConsumer.java`后断开，重启Docker中的RabbitMQ，此时交换机和队列依然存在，且`durable:	true`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525010603.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525010743.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525010803.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525010828.png)

#### `_05_Topic/TopicProducer.java`
```java
// channel.exchangeDeclare(EXCHANGE_NAME, "topic");
channel.exchangeDeclare(EXCHANGE_NAME, "topic", true); // 消息持久化
AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder(); // 消息持久化
builder.deliveryMode(2); // 消息持久化
AMQP.BasicProperties properties = builder.build(); // 消息持久化
for (int i = 0; i < 50; i++) {
    // ...
    // channel.basicPublish(EXCHANGE_NAME, "orange.to", null, message.getBytes(StandardCharsets.UTF_8));
    channel.basicPublish(EXCHANGE_NAME, "orange.to", properties, message.getBytes(StandardCharsets.UTF_8)); // 消息持久化
}
```
* 运行`TopicProducer.java`（此时没有正在运行的`Consumer`）
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525011758.png)
* 关闭`TopicProducer.java`后，重启Docker中的RabbitMQ，消息依然存在，同时尝试`Get messages`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525012206.png)

## RabbitMQ消息拒绝

### 消息拒绝
* RabbitMQ的消息拒绝：前提条件需要手动ACK。消费者可以根据信息的内容，拒绝消费这个消息。
* 提供两种方式，分别是 Reject 和 Nack。

### `_06_Reject/RejectConsumer1.java`
```java
// channel.basicReject(delivery.getEnvelope().getDeliveryTag(),true); // reject方式 // RejectMessage RejectMessage RejectMessage ...
// channel.basicNack(delivery.getEnvelope().getDeliveryTag(),false,true); // nack方式, 重回队列false // RejectMessage RejectMessage RejectMessage ...
channel.basicNack(delivery.getEnvelope().getDeliveryTag(),false,false); // nack方式, 重回队列true // RejectMessage
```
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525212441.png)

## RabbitMQ死信队列

### 死信
* 消息成为死信一般是以下三种情况：
  * 消息被消费者拒绝，并且设置 requeue 参数为 false。
  * 消息过期(默认情况下 RabbitMQ 中的消息不过期，但是可以设置消息过期时间)
  * 消息队列达到最大长度(如消息队列设置了最大队列长度或大小并且达到最大值时)
* 当满足上面三种情况时，消息会成为死信消息,并通过死信交换机投递到相应的死信队列中。
* 我们只需要监听相应的死信队列,就可以对死信消息进行最后的处理。

### `_07_Dead`

#### 先停留在普通队列几秒后再进入死信队列
* 注意先`delete``http://127.0.0.1:15672/#/exchanges`中先前设置的持久化交换机，防止与当前测试的非持久化参数同名交换机设置产生冲突；随后运行`DeadConsumer.java`，运行成功后**关闭**`DeadConsumer.java`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525220834.png)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525220904.png)
* 确认**关闭**`DeadConsumer.java`后，启动`DeadProducer.java`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525222301.png)
* 几秒后
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525222336.png)

#### 直接进入死信队列
* 先在`DeadConsumer.java`中添加一句`channel.basicReject(delivery.getEnvelope().getDeliveryTag(),false);`
```java
DeliverCallback deliverCallback = (consumerTag, delivery) -> {
    System.out.println(new String(delivery.getBody()));
    // channel.basicReject(delivery.getEnvelope().getDeliveryTag(),true); // 消息拒绝
    // // 先停留在普通队列几秒后再进入死信队列
    channel.basicReject(delivery.getEnvelope().getDeliveryTag(),false); // 直接进入死信队列
};
```
* 先启动`DeadConsumer.java`（这次保持运行状态，不关闭），随后启动`DeadProducer.java`，`DeadQueue`直接从上一步的`101`变为`202`
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525223310.png)

#### 队列最大长度测试
* 相关代码
```java
// DeadConsumer.java
params.put("x-max-length", 5);
```
* 在`DeadProducer.java`中将
```java
// String message = "RejectMessage"; // 消息拒绝
String message = "DeadMessage";
// channel.basicPublish(EXCHANGE_NAME, "orange.to", null, message.getBytes(StandardCharsets.UTF_8)); // 消息拒绝
channel.basicPublish(EXCHANGE_NAME, "orange.to", properties, message.getBytes(StandardCharsets.UTF_8));
```
改为
```java
for (int i = 0; i < 10; i++) { // 队列最大长度测试
    // String message = "DeadMessage"; // new
    String message = "DeadMessage"+i; // 队列最大长度测试
    channel.basicPublish(EXCHANGE_NAME, "orange.to", properties, message.getBytes(StandardCharsets.UTF_8));
} // 队列最大长度测试
```
* 在`DeadConsumer.java`中也进行调整
```java
//        channel.basicConsume(QUEUE_NAME, false, deliverCallback, consumerTag -> {
channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -> { // 队列最大长度测试
});
```
* 首先重启Docker中的RabbitMQ以清除队列消息数据，启动`DeadConsumer.java`后**中断**，再启动`DeadProducer.java`，
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525224908.png)
* 几秒后
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525224943.png)

#### 死信消费者
* 运行`DeadConsumer1.java`，便将先前死信队列`DeadQueue`积攒的消息全部消费掉了
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240525225457.png)

## Rabbit集成Springboot

### Spring AMQP
Spring AMQP 是对 Spring 基于 AMQP 的消息收发解决方案，不依赖于特定的 AMQP Broker 实现和客户端的抽象。

提供模板化的发送和接收消息的抽象层，提供基于消息驱动的 POJO。

### Spring AMQP核心组件
ConnectionFactory：Spring AMQP 的连接工厂接口，用于创建连接。

RabbitAdmin：AmqpAdmin 的实现，封装了对 RabbitMQ 的基础管理操作。

Message：Spring AMQP 对消息的封装。

RabbitTemplate：AmqpTemplate 的一个实现，用来简化消息的收发。

Messager Listener：Spring AMQP 异步消息投递的监听器接口，用于处理消息队列推送来的消息。

### Spring AMQP快速入门
1. [Spring Initializr](https://start.spring.io/)
![](https://github.com/toubun24/NiHon-IT-Training-Plan/blob/main/imgStorage/QQ20240526180410.png)
2. SpringBoot配置文件添加RabbitMQ配置
  * 删除默认生成的`RabbitMQ/_02_SpringBootRabbitMQ/src/main/resources/application.propertiesc`，创建`RabbitMQ/_02_SpringBootRabbitMQ/src/main/resources/application.yml`
```yml
spring:
rabbitmq:
    host: 127.0.0.1
    port: 5672
    username: guest
    password: guest
    virtual-host: /
    listener:
    simple:
        acknowledge-mode: manual # manual代表手动Ack
```
3. 配置RabbitMQ(这里使用RabbitAdmin 声明交换机、队列和绑定)
4. 创建消费者
5. 消息生产者

### Run `RabbitMQ/_02_SpringBootRabbitMQ/src/test/java/com/example/ApplicationTests.java`

#### `rabbitTemplate.convertAndSend()`
```java
@Test
	void contextLoads() {
		MessageProperties messageProperties = new MessageProperties();
		messageProperties.getHeaders().put("name","zhangsan");
		messageProperties.getHeaders().put("age","18");
		String mess = "hello world";
		Message message = new Message(mess.getBytes(),messageProperties);// import org.springframework.amqp.core.Message;
    rabbitTemplate.convertAndSend(EXCHANGE_NAME, "aaa.bbb",message); // 路由#随便写
	}
```
```bash
hello world
2024-05-26T20:10:24.999+08:00  INFO 8588 --- [_02_SpringBootRabbitMQ] [ntContainer#0-2] o.s.a.r.l.SimpleMessageListenerContainer : Waiting for workers to finish.
(Body:'[B@73cbabfd(byte[11])' MessageProperties [headers={name=zhangsan, age=18}, contentType=application/octet-stream, contentLength=0, receivedDeliveryMode=PERSISTENT, priority=0, redelivered=false, receivedExchange=spring_topic_exchange, receivedRoutingKey=aaa.bbb, deliveryTag=1, consumerTag=amq.ctag-2_pol4zFd4Ky75D4GFjXtA, consumerQueue=topic_queue])
2024-05-26T20:10:25.011+08:00  INFO 8588 --- [_02_SpringBootRabbitMQ] [ntContainer#0-2] o.s.a.r.l.SimpleMessageListenerContainer : Successfully waited for workers to finish.
```

#### `rabbitTemplate.convertAndSend()`带`messagePostProcessor`参数
```java
@Test
	void contextLoads() {
		// ...
//		rabbitTemplate.convertAndSend(EXCHANGE_NAME, "aaa.bbb",message);
		rabbitTemplate.convertAndSend(EXCHANGE_NAME, "aaa.bbb",message, message1 -> {
			message1.getMessageProperties().getHeaders().put("test","test1");
			message1.getMessageProperties().setExpiration("10000");
			return message1;
		});
	}
```
```bash
hello world
(Body:'[B@f0026bd(byte[11])' MessageProperties [headers={test=test1, name=zhangsan, age=18}, contentType=application/octet-stream, contentLength=0, receivedDeliveryMode=PERSISTENT, expiration=10000, priority=0, redelivered=false, receivedExchange=spring_topic_exchange, receivedRoutingKey=aaa.bbb, deliveryTag=1, consumerTag=amq.ctag-zTYJ3VipjbGdlqIUEpsoLw, consumerQueue=topic_queue])
2024-05-26T20:15:21.600+08:00  INFO 17064 --- [_02_SpringBootRabbitMQ] [ntContainer#0-2] o.s.a.r.l.SimpleMessageListenerContainer : Waiting for workers to finish.
2024-05-26T20:15:21.610+08:00  INFO 17064 --- [_02_SpringBootRabbitMQ] [ntContainer#0-2] o.s.a.r.l.SimpleMessageListenerContainer : Successfully waited for workers to finish.
```

#### `rabbitTemplate.send()`
```java
@Test
void contextLoads() {
    // ...
//		rabbitTemplate.convertAndSend(EXCHANGE_NAME, "aaa.bbb",message, message1 -> {
//			message1.getMessageProperties().getHeaders().put("test","test1");
//			message1.getMessageProperties().setExpiration("10000");
//			return message1;
//		});
  rabbitTemplate.send(EXCHANGE_NAME,"aaa.bbb",message);
}
```
```bash
hello world
2024-05-26T20:18:33.702+08:00  INFO 2832 --- [_02_SpringBootRabbitMQ] [ntContainer#0-2] o.s.a.r.l.SimpleMessageListenerContainer : Waiting for workers to finish.
(Body:'[B@4dabccd(byte[11])' MessageProperties [headers={name=zhangsan, age=18}, contentType=application/octet-stream, contentLength=0, receivedDeliveryMode=PERSISTENT, priority=0, redelivered=false, receivedExchange=spring_topic_exchange, receivedRoutingKey=aaa.bbb, deliveryTag=1, consumerTag=amq.ctag-JPfcql0V0vLpo523rM8_1Q, consumerQueue=topic_queue])
2024-05-26T20:18:33.714+08:00  INFO 2832 --- [_02_SpringBootRabbitMQ] [ntContainer#0-2] o.s.a.r.l.SimpleMessageListenerContainer : Successfully waited for workers to finish.
```

## RabbitMQ在在线商城平台中的应用

### 1. 订单处理
* **订单消息队列**：用户下单后，商城系统会将订单信息发送到RabbitMQ的订单消息队列中。后台的消费者服务会异步地从队列中取出订单信息进行处理，如库存扣减、支付验证、订单状态更新等。这种方式将订单处理与前端业务逻辑解耦，提高了系统的响应速度和可靠性。
* **异常处理**：在订单处理过程中，如果遇到异常情况（如库存不足、支付失败等），RabbitMQ可以将这些异常信息发送到专门的异常处理队列中，由专门的消费者服务进行处理，确保订单流程的完整性和用户体验。

### 2. 秒杀活动
* **秒杀消息队列**：在秒杀活动中，由于用户请求量巨大，直接将请求发送到数据库或后端服务可能会导致系统崩溃。通过将秒杀请求发送到RabbitMQ的秒杀消息队列中，后台的消费者服务可以异步地处理这些请求，有效地分散系统压力，提高系统的稳定性和并发性能。
* **流量削峰**：RabbitMQ的队列机制可以起到流量削峰的作用，将高峰期的请求平滑地分散到各个时间段进行处理，避免系统因瞬间流量过大而崩溃。

### 3. 库存管理
* **库存消息队列**：在商品售罄或库存变动时，商城系统可以将库存信息发送到RabbitMQ的库存消息队列中。后台的消费者服务会异步地更新库存信息，确保库存数据的准确性和实时性。
* **库存预警**：通过设置库存阈值，当库存低于某个水平时，RabbitMQ可以触发库存预警消息，通知相关人员及时补货或调整销售策略。

### 4. 消息广播与通知
* **实时通知**：RabbitMQ支持发布/订阅模式，商城系统可以利用这一特性实现实时通知功能，如订单状态变更通知、促销信息推送等。
* **广告推送**：在商城平台上，广告推送是一个重要的营销手段。RabbitMQ可以将广告信息发送到指定的队列中，由消费者服务负责将广告推送给目标用户。

### 5. 异步任务处理
* **耗时任务**：商城系统中可能存在一些耗时较长的任务，如发送电子邮件、生成报表等。这些任务可以通过RabbitMQ进行异步处理，避免阻塞主线程，提高系统的响应性能。

### 6. 分布式系统通信
* **服务解耦**：在分布式商城系统中，不同的服务或模块之间需要进行通信和协作。RabbitMQ可以作为消息代理，实现服务之间的解耦和异步通信，提高系统的可扩展性和灵活性。

## RabbitMQ和axios的关系
### RabbitMQ
**定义与功能**：
* RabbitMQ是一个开源的消息代理软件，实现了高级消息队列协议（AMQP）。它是一个应用程序对应用程序的通信方法，基于消费-生产者模型。在RabbitMQ中，消息的生产者将消息发布到队列中，而消息的消费者则从队列中获取并处理这些消息。
* RabbitMQ支持多种编程语言，包括Java、Python、Ruby等，并提供了多种编程语言的客户端库，使得开发人员可以使用自己熟悉的语言来与RabbitMQ进行交互。
* RabbitMQ具有可靠性、灵活性、可扩展性、多语言支持、异步通信、解耦服务、削峰等特性。
**应用场景**：
* RabbitMQ常用于实现系统间的解耦、异步通信、流量削峰等场景。例如，在电商系统中，订单系统可以将订单生成的消息发送到RabbitMQ，库存系统、支付系统等作为消费者从RabbitMQ中获取订单消息并进行处理，从而实现系统间的解耦和异步通信。

### axios
**定义与功能**：
* Axios是一个基于Promise的HTTP客户端，用于浏览器和node.js。它提供了简单易用的API，用于发送异步HTTP请求到REST端点，并处理响应。
* Axios提供了多种请求方法，如GET、POST、PUT、DELETE等，并支持请求和响应的拦截、转换请求数据和响应数据等高级功能。
**应用场景**：
* Axios常用于前端与后端之间的通信。在Web应用中，前端页面可以通过axios发送HTTP请求到后端服务器，获取数据或提交表单等。

### RabbitMQ和axios的协同工作
* 在一个典型的Web应用中，前端页面（使用React等框架）通过axios发送HTTP请求到后端服务器（使用SpringBoot等框架）。
* 后端服务器接收到请求后，可以将需要异步处理的任务（如发送邮件、生成报表等）的消息发送到RabbitMQ。
* 消息消费者（可以是另一个后端服务或微服务）从RabbitMQ中获取消息并进行处理。
* 处理完成后，消费者可以将结果通过RabbitMQ或其他方式返回给原始请求者（如果需要的话）。

### RabbitMQ和axios总结：
RabbitMQ和axios在Web应用中各司其职，共同实现高效、可扩展、解耦的架构。RabbitMQ负责系统间的异步通信和消息传递，而axios则负责前端与后端之间的HTTP请求和响应。两者协同工作，使得整个应用架构更加灵活、健壮和易于维护。

## 在Spring应用程序中集成MyBatis和MySQL协同工作
1. **配置数据源**：在 Spring 配置文件中（XML、Java Config 或基于注解的配置），你需要配置数据源（DataSource），它包含了连接 MySQL 数据库所需的信息（如 URL、用户名、密码等）。
2. **配置 MyBatis**：你需要配置 MyBatis 的 SqlSessionFactoryBean，并指定 MyBatis 的配置文件位置（通常是 XML 文件），该文件中包含了 SQL 映射语句和配置信息。
3. **映射器接口**：在 MyBatis 中，你通常会定义一些映射器接口，这些接口中的方法对应于 SQL 语句。MyBatis 会通过动态代理来实现这些接口，并自动处理 SQL 语句的执行。
4. **服务层和控制器**：在 Spring MVC 应用程序中，你可以在服务层使用 MyBatis 映射器来执行数据库操作，并在控制器中处理 HTTP 请求和响应。
5. **事务管理**：你可以使用 Spring 的声明式事务管理来管理数据库事务，确保数据的一致性和完整性。

# 后端实战

## pom.xml中打包方式jar和war
在Maven项目中，`pom.xml`文件是项目的核心配置文件，用于定义项目的构建配置、依赖管理等信息。在`pom.xml`中，可以通过`<packaging>`元素来指定项目的打包方式。Maven支持多种打包方式，其中最常见的两种是`jar`和`war`。
### JAR打包
当项目是一个可执行的Java应用程序或库时，通常会使用`jar`打包方式。`jar`（Java ARchive）是一种文件格式，用于将多个Java类文件、相关元数据和资源（如文本、图片等）打包成一个文件，以便分发、部署和查找。
### WAR打包
当项目是一个Web应用程序时，通常会使用`war`打包方式。`war`（Web Application ARchive）是一种文件格式，用于将Web应用程序打包成一个文件，这个文件包含了所有的Servlet类、JSP文件、HTML页面、图片、标签库和配置文件等。WAR文件可以直接部署到支持Servlet的Web服务器上。
### 注意点
- 对于`war`打包，Maven会默认将`src/main/webapp`目录下的内容作为Web应用的根目录，并打包进WAR文件中。如果你使用的是Spring Boot等框架，并且想要生成可执行的WAR文件，可能还需要进行一些额外的配置，如排除Spring Boot自带的Tomcat服务器依赖等。
- 在`pom.xml`中指定打包方式后，Maven会根据这个设置来执行相应的打包命令（如`mvn package`），并生成相应格式的包文件。

